This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter), security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  scripts/
    cleanup_branch.py
    overwrite_branch.py
    update_sdk_version.py
    wait_for_checks.py
  workflows/
    bump_sdk_version.yml
    docs_cron.yml
    docs_on_pr.yml
    promote_to_production.yml
docs/
  _lib/
    _root-intro.mdx
    _tool-intro-local-mcp.mdx
    _tool-intro-microsoft.mdx
    _tool-intro-oauth.mdx
    _tool-intro-open-source.mdx
    _tool-intro-remote-mcp.mdx
    _tool-intro-slack.mdx
    _tool-intro-zendesk.mdx
  portia-tools/
    local-mcp/
      aws-cost-analysis.mdx
      aws-documentation.mdx
      basic-memory.mdx
      biomcp.mdx
      bright-data.mdx
      browserbase.mdx
      chargebee.mdx
      chroma.mdx
      dbhub.mdx
      elevenlabs.mdx
      gcp-cloud-run.mdx
      github.mdx
      grafana.mdx
      hubspot.mdx
      hyperbrowser.mdx
      index.mdx
      jetbrains-ide.mdx
      minimax.mdx
      monday.com.mdx
      mongodb.mdx
      netlify.mdx
      notion.mdx
      perplexity.mdx
      playwright.mdx
      qdrant.mdx
      shopify-dev.mdx
      supabase.mdx
      twilio.mdx
      xero.mdx
    open-source/
      browser-for-url.mdx
      browser.mdx
      crawl.mdx
      extract.mdx
      file-reader.mdx
      file-writer.mdx
      image-understanding.mdx
      index.mdx
      llm.mdx
      map-website.mdx
      pdf-reader.mdx
      search.mdx
      weather.mdx
    portia-cloud/
      github/
        index.mdx
        list-repo-issues.mdx
        list-repos.mdx
        search-repos.mdx
        star-repo.mdx
      google-calendar/
        calendar-check-availability.mdx
        calendar-create-event.mdx
        calendar-delete-event.mdx
        calendar-get-event-details.mdx
        calendar-get-events-by-properties.mdx
        calendar-modify-event.mdx
        index.mdx
      google-docs/
        docs-get-document.mdx
        docs-get-structured-document.mdx
        index.mdx
      google-drive/
        drive-search.mdx
        index.mdx
      google-gmail/
        gmail-draft-email.mdx
        gmail-search-email.mdx
        gmail-send-draft-email.mdx
        gmail-send-email.mdx
        index.mdx
      google-sheets/
        index.mdx
        sheets-get-spreadsheet.mdx
      microsoft-outlook/
        index.mdx
        outlook-draft-email.mdx
        outlook-search-email.mdx
        outlook-send-draft-email.mdx
        outlook-send-email.mdx
      slack/
        find-message.mdx
        get-conversation.mdx
        index.mdx
        list-conversations.mdx
        list-users.mdx
        send-message.mdx
      zendesk/
        article-search.mdx
        count-ticket-comments.mdx
        count-tickets.mdx
        create-article-comments.mdx
        create-ticket.mdx
        index.mdx
        list-article-comments.mdx
        list-articles-by-section.mdx
        list-articles.mdx
        list-groups-for-user.mdx
        list-post-comments.mdx
        list-request-comments.mdx
        list-ticket-comments.mdx
        list-users-for-group.mdx
        search-groups.mdx
        search-organizations.mdx
        search-requests.mdx
        search-tickets.mdx
        search-users.mdx
        show-article.mdx
        show-group.mdx
        show-organization.mdx
        show-post.mdx
        show-request-comment.mdx
        show-request.mdx
        show-section.mdx
        show-ticket-metrics.mdx
        show-ticket.mdx
        show-user.mdx
        update-ticket.mdx
      index.mdx
    remote-mcp/
      apify.mdx
      asana.mdx
      cloudflare.mdx
      deepwiki.mdx
      firecrawl.mdx
      hugging-face.mdx
      index.mdx
      intercom.mdx
      invideo.mdx
      linear.mdx
      make.mdx
      posthog.mdx
      semgrep.mdx
      sentry.mdx
      shopify.mdx
      square.mdx
      stripe.mdx
      supermemory.mdx
      webflow.mdx
      wix.mdx
      yepcode.mdx
    index.mdx
    sidebar.json
  product/
    Evals and SteelThread/
      Evals/
        _category_.json
        Eval_results.md
        Evals_custom_evaluators.md
        Evals_tool_stubbing.md
        Evals.md
      Streams/
        _category_.json
        Stream_custom_evaluators.md
        Stream_results.md
        Streams.md
      _category_.json
      Custom_backend.md
      Introducing Steel Thread.md
      Quickstart.md
    Extend and run tools/
      _category_.json
      Adding custom tools.md
      Browser based tools.md
      Cloud Tool Registry.md
      Integrating tools.md
      Intro to tools.md
      MCP servers.md
      Use clarifications in tools.md
    Get started/
      _category_.json
      A tour of our SDK.md
      index.mdx
      install.md
      Manage config options.md
      Set up your account.md
    Handle auth and clarifications/
      _category_.json
      Run Portia tools with authentication.md
      Understand clarifications.md
    Plan and run workflows/
      _category_.json
      Build a plan.md
      Generate a plan.md
      Inputs and Outputs.md
      Manage plan run states on Portia cloud.md
      Run a plan.md
    Running in production/
      _category_.json
      Agent memory.md
      Agent observability.md
      Execution Hooks.md
      Manage end users.md
    Security/
      _category_.json
      Security Overview.md
    Telemetry/
      _category_.json
      Telemetry Overview.md
  SDK/
    portia/
      builder/
        conditionals.md
        plan_builder_v2.md
        plan_v2.md
        reference.md
        step_v2.md
      execution_agents/
        utils/
          final_output_summarizer.md
          step_summarizer.md
        base_execution_agent.md
        clarification_tool.md
        conditional_evaluation_agent.md
        context.md
        default_execution_agent.md
        execution_utils.md
        memory_extraction.md
        one_shot_agent.md
        output.md
      introspection_agents/
        default_introspection_agent.md
        introspection_agent.md
      open_source_tools/
        browser_tool.md
        calculator_tool.md
        crawl_tool.md
        extract_tool.md
        image_understanding_tool.md
        llm_tool.md
        local_file_reader_tool.md
        local_file_writer_tool.md
        map_tool.md
        pdf_reader_tool.md
        search_tool.md
        weather.md
      planning_agents/
        base_planning_agent.md
        context.md
        default_planning_agent.md
      telemetry/
        telemetry_service.md
        views.md
      clarification_handler.md
      clarification.md
      cloud.md
      config.md
      end_user.md
      errors.md
      execution_hooks.md
      gemini_langsmith_wrapper.md
      logger.md
      mcp_session.md
      model.md
      plan_run.md
      plan.md
      portia.md
      storage.md
      token_check.md
      tool_call.md
      tool_decorator.md
      tool_registry.md
      tool_wrapper.md
      tool.md
      version.md
    example_builder.md
    sidebar.json
  .spelling
src/
  clientModules/
    posthog.ts
  components/
    ItemList.tsx
    ToolRoot.tsx
  css/
    custom.css
  lib/
    tools.ts
  pages/
    examples/
      redoc.jsx
  theme/
    DocCard/
      index.tsx
      styles.module.css
    DocCardList/
      index.js
    NotFound/
      Content/
        index.js
      index.js
static/
  api/
    swagger.yaml
tests/
  test_code_examples.py
.env.example
.gitignore
babel.config.js
docusaurus.config.js
package.json
pyproject.toml
README.md
sidebars.js
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/scripts/cleanup_branch.py">
def check_and_cleanup_existing(repo_name: str, title_pattern: str, branch_pattern: str, delete: bool = False, token: str = None) -> bool
⋮----
github = Github(token)
repo = github.get_repo(repo_name)
found_existing = False
open_prs = repo.get_pulls(state='open')
⋮----
found_existing = True
⋮----
branches = repo.get_branches()
⋮----
def main()
⋮----
parser = argparse.ArgumentParser(description="Check for existing PRs with title pattern and optionally clean up")
⋮----
args = parser.parse_args()
⋮----
exists = check_and_cleanup_existing(
</file>

<file path=".github/scripts/overwrite_branch.py">
def overwrite_branch(repo_name: str, push: bool, target_branch: str, source_branch: str, token: str) -> None
⋮----
github = Github(token)
repo = github.get_repo(repo_name)
source_ref = repo.get_branch(source_branch)
⋮----
target_ref = repo.get_git_ref(f"heads/{target_branch}")
⋮----
def main()
⋮----
parser = argparse.ArgumentParser(description="Deploy")
⋮----
args = parser.parse_args()
</file>

<file path=".github/scripts/update_sdk_version.py">
def get_latest_commit()
⋮----
response = requests.get(
⋮----
def update_pyproject_toml(commit_hash, pyproject_path="pyproject.toml")
⋮----
pyproject_file = Path(pyproject_path)
⋮----
content = f.read()
lines = content.split('\n')
updated_lines = []
found = False
⋮----
current_match = re.search(r'rev = "([a-f0-9]+)"', line)
⋮----
current_hash = current_match.group(1)
updated_line = line.replace(f'rev = "{current_hash}"', f'rev = "{commit_hash}"')
⋮----
found = True
⋮----
updated_content = '\n'.join(updated_lines)
⋮----
lines = updated_content.split('\n')
⋮----
def main()
⋮----
parser = argparse.ArgumentParser(
⋮----
args = parser.parse_args()
⋮----
commit_hash = get_latest_commit()
⋮----
commit_hash = args.commit_hash
</file>

<file path=".github/scripts/wait_for_checks.py">
ignore_checks = []
github = Github(token)
repo = github.get_repo(repo_name)
pr = repo.get_pull(pr_number)
⋮----
max_attempts = (timeout_minutes * 60) // wait_seconds
⋮----
pr_head_sha = pr.head.sha
# Get status checks (external checks like Vercel)
status_response = repo.get_commit(pr_head_sha).get_statuses()
status_checks = list(status_response)
# Get GitHub Actions check runs
check_runs = repo.get_commit(pr_head_sha).get_check_runs()
# Filter out ignored checks
status_checks = [check for check in status_checks if check.context.lower() not in ignore_checks]
check_runs = [run for run in check_runs if run.name.lower() not in ignore_checks]
# Count status checks by state
status_total = len(status_checks)
status_success = len([c for c in status_checks if c.state == "success"])
status_pending = len([c for c in status_checks if c.state == "pending"])
status_failure = len([c for c in status_checks if c.state in ["failure", "error"]])
# Count GitHub Actions checks by status
checks_total = len(check_runs)
checks_success = len([r for r in check_runs if r.conclusion == "success"])
checks_pending = len([r for r in check_runs if r.status in ["in_progress", "queued"]])
checks_failure = len([r for r in check_runs if r.conclusion in ["failure", "cancelled", "timed_out"]])
# Combined totals
total_checks = status_total + checks_total
total_success = status_success + checks_success
total_pending = status_pending + checks_pending
total_failure = status_failure + checks_failure
⋮----
# Show pending external checks for debugging
⋮----
# Show pending GitHub Actions checks for debugging
⋮----
# Check PR's mergeable state
⋮----
mergeable_state = pr.mergeable_state
⋮----
def main()
⋮----
parser = argparse.ArgumentParser(description="Wait for PR checks to complete")
⋮----
args = parser.parse_args()
⋮----
result = wait_for_checks(
</file>

<file path=".github/workflows/bump_sdk_version.yml">
name: Bump SDK Version
on:
  workflow_dispatch:
  repository_dispatch:
    types: [bump-sdk-version]
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
jobs:
  bump-sdk-version:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.DEPLOY_PAT_TOKEN }}
          fetch-depth: 0
      - name: Install uv
        uses: astral-sh/setup-uv@v5
      - name: Get latest commit hash from portia-sdk-python
        id: get-latest-commit
        run: |
          LATEST_COMMIT=$(curl -s https://api.github.com/repos/portiaAI/portia-sdk-python/commits/main | jq -r '.sha')
          echo "latest_commit=$LATEST_COMMIT" >> $GITHUB_OUTPUT
          echo "Latest commit hash: $LATEST_COMMIT"
      - name: Check and cleanup existing SDK bump PRs
        id: check-existing-pr
        run: |
          uv run .github/scripts/cleanup_branch.py \
            --repo-name ${{ github.repository }} \
            --title-pattern "🤖 Automated: Bump SDK version" \
            --branch-pattern "automated/bump-sdk-version" \
            --delete \
            --token ${{ secrets.DEPLOY_PAT_TOKEN }}
          echo "existing_pr=false" >> $GITHUB_OUTPUT
          echo "Any existing SDK bump PRs have been cleaned up"
      - name: Update pyproject.toml with latest commit hash
        run: |
          uv run .github/scripts/update_sdk_version.py "${{ steps.get-latest-commit.outputs.latest_commit }}"
      - name: Create Pull Request
        id: create-pr
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ secrets.DEPLOY_PAT_TOKEN }}
          branch: automated/bump-sdk-version-${{ steps.get-latest-commit.outputs.latest_commit }}
          title: "🤖 Automated: Bump SDK version to latest commit"
          body: |
            This PR updates the portia-sdk-python dependency to the latest commit hash.
            **Latest commit:** `${{ steps.get-latest-commit.outputs.latest_commit }}`
            **Changes:**
            - Updated `pyproject.toml` to use the latest commit hash from portiaAI/portia-sdk-python
            ---
            *This PR was automatically generated by the bump-sdk-version workflow.*
          commit-message: "🤖 Bump SDK version to ${{ steps.get-latest-commit.outputs.latest_commit }}"
          delete-branch: false
          labels: |
            automated
            sdk-update
      - name: Wait for PR checks to complete
        id: wait-for-checks
        run: |
          if uv run .github/scripts/wait_for_checks.py \
            --repo-name ${{ github.repository }} \
            --pr-number ${{ steps.create-pr.outputs.pull-request-number }} \
            --timeout-minutes 10 \
            --wait-seconds 30 \
            --ignore-checks "vercel" \
            --token ${{ secrets.DEPLOY_PAT_TOKEN }}; then
            echo "status=success" >> $GITHUB_OUTPUT
          else
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 1 ]; then
              echo "status=failure" >> $GITHUB_OUTPUT
            elif [ $EXIT_CODE -eq 2 ]; then
              echo "status=timeout" >> $GITHUB_OUTPUT
            else
              echo "status=failure" >> $GITHUB_OUTPUT
            fi
          fi
      - name: Auto-merge PR if checks pass
        if: steps.wait-for-checks.outputs.status == 'success'
        run: |
          PR_NUMBER="${{ steps.create-pr.outputs.pull-request-number }}"
          if [ -z "$PR_NUMBER" ]; then
            echo "Error: PR number is empty. Cannot merge PR."
            exit 1
          fi
          gh pr merge $PR_NUMBER \
            --squash \
            --delete-branch \
            --admin \
            --subject "🤖 Merge: Bump SDK version to ${{ steps.get-latest-commit.outputs.latest_commit }}" \
            --body "Automated merge of SDK version bump"
            echo "PR #$PR_NUMBER merged successfully!"
        env:
          GH_TOKEN: ${{ secrets.DEPLOY_PAT_TOKEN }}
      - name: Close PR and notify Slack on failure
        if: steps.wait-for-checks.outputs.status == 'failure' || steps.wait-for-checks.outputs.status == 'timeout'
        run: |
          PR_NUMBER="${{ steps.create-pr.outputs.pull-request-number }}"
          if [ -z "$PR_NUMBER" ]; then
            echo "Error: PR number is empty. Cannot close PR."
            exit 1
          fi
          echo "Closing failed PR #$PR_NUMBER..."
          gh pr close $PR_NUMBER \
            --delete-branch \
            --comment "This PR was automatically closed because the checks failed. Status: ${{ steps.wait-for-checks.outputs.status }}"
          echo "PR #$PR_NUMBER closed successfully"
        env:
          GH_TOKEN: ${{ secrets.DEPLOY_PAT_TOKEN }}
      - name: Notify Slack on failure
        if: steps.wait-for-checks.outputs.status == 'failure' || steps.wait-for-checks.outputs.status == 'timeout'
        uses: slackapi/slack-github-action@v1.24.0
        with:
          channel-id: '${{ vars.SLACK_GITHUB_ALERTS_CHANNEL }}'
          slack-message: |
            🚨 *Docs SDK Version Bump Failed*
            *Failing Checks:* <https://github.com/${{ github.repository }}/pull/${{ steps.create-pr.outputs.pull-request-number }}/checks|
            *Triggering Workflow:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
</file>

<file path=".github/workflows/docs_cron.yml">
name: Daily Test Code Examples
on:
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:
jobs:
  test-staging:
    name: Main branch test (Staging)
    runs-on: ubuntu-latest
    timeout-minutes: 20
    concurrency:
      group: ${{ github.workflow }}-staging
      cancel-in-progress: true
    steps:
    - uses: actions/checkout@v4
    - name: Install uv
      uses: astral-sh/setup-uv@v5
    - name: Install dependencies
      run: uv sync --all-extras --all-groups
    - name: Run tests
      run: uv run pytest -n 10 -s
      env:
        PORTIA_API_KEY: ${{ secrets.PORTIA_STAGING_API_KEY }}
        PORTIA_API_ENDPOINT: ${{ secrets.PORTIA_STAGING_API_ENDPOINT }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        OPENWEATHERMAP_API_KEY: ${{ secrets.OPENWEATHERMAP_API_KEY }}
        TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
        AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
        LANGCHAIN_API_KEY: ${{ secrets.LANGCHAIN_API_KEY }}
        LANGCHAIN_TRACING_V2: true
        LANGCHAIN_ENDPOINT: https://api.smith.langchain.com
        LANGCHAIN_PROJECT: docs-testing
    - name: Notify Slack on failure
      if: failure()
      uses: slackapi/slack-github-action@v1.27.0
      env:
        SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
      with:
        slack-message: "Docs testing against staging failed! See https://github.com/portiaAI/docs/actions/runs/${{ github.run_id }} for more details."
        channel-id: C07V8NK09RC
  test-production:
    name: Production branch test
    runs-on: ubuntu-latest
    timeout-minutes: 20
    concurrency:
      group: ${{ github.workflow }}-production
      cancel-in-progress: true
    steps:
    - uses: actions/checkout@v4
      with:
        ref: production
    - name: Install uv
      uses: astral-sh/setup-uv@v5
    - name: Install dependencies
      run: uv sync --all-extras --all-groups
    - name: Run tests
      run: uv run pytest -n 10 -s
      env:
        PORTIA_API_KEY: ${{ secrets.PORTIA_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        OPENWEATHERMAP_API_KEY: ${{ secrets.OPENWEATHERMAP_API_KEY }}
        TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
        AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
        LANGCHAIN_API_KEY: ${{ secrets.LANGCHAIN_API_KEY }}
        LANGCHAIN_TRACING_V2: true
        LANGCHAIN_ENDPOINT: https://api.smith.langchain.com
        LANGCHAIN_PROJECT: docs-testing
    - name: Notify Slack on failure
      if: failure()
      uses: slackapi/slack-github-action@v1.27.0
      env:
        SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
      with:
        slack-message: "Docs testing against production failed! See https://github.com/portiaAI/docs/actions/runs/${{ github.run_id }} for more details."
        channel-id: C07V8NK09RC
</file>

<file path=".github/workflows/docs_on_pr.yml">
name: PR Test Code Examples
on:
  workflow_dispatch:
  pull_request:
jobs:
  test:
    name: Check code examples in docs
    runs-on: ubuntu-latest
    timeout-minutes: 20
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}
      cancel-in-progress: true
    steps:
      - uses: actions/checkout@v4
      - name: Install uv
        uses: astral-sh/setup-uv@v5
      - name: Install dependencies
        run: uv sync --all-extras --all-groups
      - name: Run tests
        run: uv run pytest -n 10 -s
        env:
          PORTIA_API_KEY: ${{ secrets.PORTIA_STAGING_API_KEY }}
          PORTIA_API_ENDPOINT: ${{ secrets.PORTIA_STAGING_API_ENDPOINT }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
          OPENWEATHERMAP_API_KEY: ${{ secrets.OPENWEATHERMAP_API_KEY }}
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          LANGCHAIN_API_KEY: ${{ secrets.LANGCHAIN_API_KEY }}
          LANGCHAIN_TRACING_V2: true
          LANGCHAIN_ENDPOINT: https://api.smith.langchain.com
          LANGCHAIN_PROJECT: docs-testing
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
</file>

<file path=".github/workflows/promote_to_production.yml">
name: Promote to Production
on:
  workflow_dispatch:
  repository_dispatch:
    types: [promote-to-production]
jobs:
  promote-to-production:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.DEPLOY_PAT_TOKEN }}
          fetch-depth: 0
      - name: Install uv
        uses: astral-sh/setup-uv@v5
      - name: Promote main to production
        id: promote
        run: |
          uv run .github/scripts/overwrite_branch.py \
            --repo-name "${{ github.repository }}" \
            --push \
            --target-branch "production" \
            --source-branch "main" \
            --token ${{ secrets.DEPLOY_PAT_TOKEN }}
      - name: Notify Slack on failure
        if: failure()
        uses: slackapi/slack-github-action@v1.27.0
        with:
          channel-id: '${{ vars.SLACK_RUN_CHANNEL }}'
          slack-message: |
            🚨 *Docs Production Promotion Failed*
            The promotion of main branch to production has failed.
            *Repository:* ${{ github.repository }}
            *Source Branch:* main
            *Target Branch:* production
            *Workflow:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
</file>

<file path="docs/_lib/_root-intro.mdx">
Portia offer both open source and cloud base tools. See the <a href="/intro-to-tools" target="_blank">**tools docs ↗**</a> to get started using tools.
</file>

<file path="docs/_lib/_tool-intro-local-mcp.mdx">
This is a list of official MCP servers that the Portia team have tested. You will find the code snippet to easily load them into Portia in each section.
</file>

<file path="docs/_lib/_tool-intro-microsoft.mdx">
import OauthIntro from "./_tool-intro-oauth.mdx"

<OauthIntro />

## Selecting Microsoft Tools

Microsoft tools are included in Portia's cloud registry but are not included in the default `DefaultToolRegistry` class.
This is due to tool clashes with the Google tools (i.e. the agent wouldn't know whether to check Gmail or Outlook for email tasks).
In order to use Microsoft tools rather than Google tools, simply filter out the Google tools from the Portia cloud registry rather than using the default registry:

```python
from portia import PortiaToolRegistry, default_config

registry = PortiaToolRegistry(default_config()).filter_tools(lambda tool: not tool.id.startswith("portia:google:"))registry = PortiaToolRegistry(default_config()).filter_tools(
    lambda tool: not tool.id.startswith("portia:google:")
)
```
</file>

<file path="docs/_lib/_tool-intro-oauth.mdx">
## Usage

All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a `Action Clarification` with an OAuth link as the action URL. The `portia.wait_for_ready()` method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again.

For more on this, please visit to the section on running Portia tools (<a href="/run-portia-tools" target="_blank">**↗**</a>).
</file>

<file path="docs/_lib/_tool-intro-open-source.mdx">
## Usage

Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (<a href="https://github.com/portiaAI/portia-sdk-python/tree/main/portia/open_source_tools" target="_blank">**SDK repo ↗**</a>).

You can import our open source tools into your project using `from portia.open_source_tools.registry import open_source_tool_registry` and load them into an `InMemoryToolRegistry` object. You can also combine their use with cloud or custom tools as explained in the docs (<a href="/add-custom-tools" target="_blank">**Add custom tools ↗**</a>).
</file>

<file path="docs/_lib/_tool-intro-remote-mcp.mdx">
This is a list of official remote MCP servers that can be added to your `DefaultToolRegistry` from the dashboard.
</file>

<file path="docs/_lib/_tool-intro-slack.mdx">
import OauthIntro from "./_tool-intro-oauth.mdx" 

<OauthIntro />

## Configure your Slack tools with Portia AI
You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard.

### Install a Slack app
1. Head over to <a href="https://api.slack.com/apps" target="_blank">**api.slack.com/apps ↗**</a>
2. Create an app from scratch and select the Slack workplace you would like to use it in.
3. Note down the client ID and secret on the **Basic Information** page. We will need this in a couple of steps from now!
4. In the **OAuth & Permissions** tab further down in the left hand nav, add as **Redirect URL** the following URL `https://api.portialabs.ai/api/v0/oauth/slack` (don't forget to hit that **Save URLs** button!).
5. Under **Bot Token Scopes**, be sure to add the scopes
    - `channels:history` -- View messages and other content in public channels that your Slack app has been added to.
    - `channels:read` -- View basic information about public channels in a workspace.
    - `chat:write` -- Send messages as *@\{your slack app name\}*.
    - `users:read` -- View people in a workspace.
6. Under **User Token Scopes**, be sure to add the scope `search:read` to support searching workplace content.
7. Now scroll up to the top of the **OAuth & Permissions** page and hit the **Install to *\{your workplace name\}*** button.
8. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app.

### Configure access in Portia AI
1. Log into your Portia <a href="https://app.portialabs.ai" target="_blank">**dashboard ↗**</a>
2. Navigate to the **Manage Org** tab.
3. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above.

You are now ready to call Slack tools on our cloud!
</file>

<file path="docs/_lib/_tool-intro-zendesk.mdx">
import OauthIntro from "./_tool-intro-oauth.mdx" 

<OauthIntro />

## Configure your Zendesk tools with Portia AI

You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account.

### Configure access in Portia AI

1. Log into your Portia <a href="https://app.portialabs.ai" target="_blank">**dashboard ↗**</a>
2. Navigate to the **Manage Org** tab.
3. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the `.zendesk.com` domain. For example, if your Zendesk URL is `https://portialabs.zendesk.com`, your subdomain is `portialabs`.

You are now ready to call Zendesk tools on our cloud!
</file>

<file path="docs/portia-tools/local-mcp/aws-cost-analysis.mdx">
---
title: "AWS Cost Analysis"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# AWS Cost Analysis

### Description

Analyze AWS service costs and generate cost reports.

Visit the [server homepage (↗)](https://github.com/awslabs/mcp/tree/HEAD/src/cost-analysis-mcp-server) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/awslabs/mcp/tree/HEAD/src/cost-analysis-mcp-server) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="awslabs.cost-analysis-mcp-server",
    command="uvx",
    args=["awslabs.cost-analysis-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_PROFILE": "<aws_profile>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="awslabs.cost-analysis-mcp-server",
    command="uvx",
    args=["awslabs.cost-analysis-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_PROFILE": "<aws_profile>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/aws-documentation.mdx">
---
title: "AWS Documentation"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# AWS Documentation

### Description

Provides tools to access AWS documentation, search for content, and get recommendations.

Visit the [server homepage (↗)](https://github.com/awslabs/mcp/tree/HEAD/src/aws-documentation-mcp-server) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="aws-docs",
    command="uvx",
    args=["awslabs.aws-documentation-mcp-server@latest"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="aws-docs",
    command="uvx",
    args=["awslabs.aws-documentation-mcp-server@latest"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/basic-memory.mdx">
---
title: "Basic Memory"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Basic Memory

### Description

Knowledge management system that builds a persistent semantic graph in markdown, locally.

Visit the [server homepage (↗)](https://github.com/basicmachines-co/basic-memory) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="basic-memory",
    command="uvx",
    args=[
        "basic-memory",
        "mcp",
    ],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="basic-memory",
    command="uvx",
    args=[
        "basic-memory",
        "mcp",
    ],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/biomcp.mdx">
---
title: "BioMCP"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# BioMCP

### Description

Integrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution.

Visit the [server homepage (↗)](https://github.com/genomoncology/biomcp) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="biomcp",
    command="uv",
    args=["run", "--with", "biomcp-python", "biomcp", "run"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="biomcp",
    command="uv",
    args=["run", "--with", "biomcp-python", "biomcp", "run"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/bright-data.mdx">
---
title: "Bright Data"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Bright Data

### Description

Integrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites.

Visit the [server homepage (↗)](https://github.com/brightdata/brightdata-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/brightdata/brightdata-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="Bright Data",
    command="npx",
    args=["@brightdata/mcp"],
    env={"API_TOKEN": "<api_token>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="Bright Data",
    command="npx",
    args=["@brightdata/mcp"],
    env={"API_TOKEN": "<api_token>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/browserbase.mdx">
---
title: "Browserbase"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Browserbase

### Description

Automate web browsers remotely on a cloud environment.

Visit the [server homepage (↗)](https://github.com/browserbase/mcp-server-browserbase) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/browserbase/mcp-server-browserbase) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="browserbase",
    command="npx",
    args=["@browserbasehq/mcp"],
    env={"BROWSERBASE_API_KEY": "<api_key>", "BROWSERBASE_PROJECT_ID": "<project_id>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="browserbase",
    command="npx",
    args=["@browserbasehq/mcp"],
    env={"BROWSERBASE_API_KEY": "<api_key>", "BROWSERBASE_PROJECT_ID": "<project_id>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/chargebee.mdx">
---
title: "Chargebee"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Chargebee

### Description

Integration with Chargebee products and API services to facilitate billing for subscription businesses.

Visit the [server homepage (↗)](https://github.com/chargebee/agentkit/tree/HEAD/modelcontextprotocol) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="chargebee",
    command="npx",
    args=["-y", "@chargebee/mcp@latest"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="chargebee",
    command="npx",
    args=["-y", "@chargebee/mcp@latest"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/chroma.mdx">
---
title: "Chroma"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Chroma

### Description

Integrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations.

Visit the [server homepage (↗)](https://github.com/chroma-core/chroma-mcp) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="chroma-mcp",
    command="uvx",
    args=["chroma-mcp", "--client-type", "persistent", "--data-dir", "/path/to/chroma/"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="chroma-mcp",
    command="uvx",
    args=["chroma-mcp", "--client-type", "persistent", "--data-dir", "/path/to/chroma/"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/dbhub.mdx">
---
title: "DBHub"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# DBHub

### Description

Provides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks

Visit the [server homepage (↗)](https://github.com/bytebase/dbhub) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="dbhub-postgres-docker",
    command="npx",
    args=[
        "-y",
        "@bytebase/dbhub",
        "--transport",
        "stdio",
        "--dsn",
        "<connection_string>",
    ],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="dbhub-postgres-docker",
    command="npx",
    args=[
        "-y",
        "@bytebase/dbhub",
        "--transport",
        "stdio",
        "--dsn",
        "<connection_string>",
    ],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/elevenlabs.mdx">
---
title: "ElevenLabs"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# ElevenLabs

### Description

Integrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features.

Visit the [server homepage (↗)](https://github.com/elevenlabs/elevenlabs-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/elevenlabs/elevenlabs-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="elevenlabs", command="uvx", args=["elevenlabs-mcp"], env={"ELEVENLABS_API_KEY": "<api_key>"}
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="elevenlabs", command="uvx", args=["elevenlabs-mcp"], env={"ELEVENLABS_API_KEY": "<api_key>"}
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/gcp-cloud-run.mdx">
---
title: "GCP Cloud Run"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# GCP Cloud Run

### Description

Deploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content.

Visit the [server homepage (↗)](https://github.com/googlecloudplatform/cloud-run-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/googlecloudplatform/cloud-run-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="cloud-run-mcp",
    command="npx",
    args=["-y", "https://github.com/GoogleCloudPlatform/cloud-run-mcp"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="cloud-run-mcp",
    command="npx",
    args=["-y", "https://github.com/GoogleCloudPlatform/cloud-run-mcp"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/github.mdx">
---
title: "GitHub"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# GitHub

### Description

Integration with GitHub Issues, Pull Requests, and more.

Visit the [server homepage (↗)](https://github.com/github/github-mcp-server) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/github/github-mcp-server) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="github",
    command="docker",
    args=[
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server",
    ],
    env={"GITHUB_PERSONAL_ACCESS_TOKEN": "<personal_access_token>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="github",
    command="docker",
    args=[
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server",
    ],
    env={"GITHUB_PERSONAL_ACCESS_TOKEN": "<personal_access_token>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/grafana.mdx">
---
title: "Grafana"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Grafana

### Description

Integrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes.

Visit the [server homepage (↗)](https://github.com/grafana/mcp-grafana) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/grafana/mcp-grafana) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="grafana",
    command="docker",
    args=[
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_API_KEY",
        "mcp/grafana",
        "-t",
        "stdio",
    ],
    env={"GRAFANA_URL": "<grafana_url>", "GRAFANA_API_KEY": "<api_key>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="grafana",
    command="docker",
    args=[
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_API_KEY",
        "mcp/grafana",
        "-t",
        "stdio",
    ],
    env={"GRAFANA_URL": "<grafana_url>", "GRAFANA_API_KEY": "<api_key>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/hubspot.mdx">
---
title: "HubSpot"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# HubSpot

### Description

Integrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes.

Visit the [server homepage (↗)](https://www.npmjs.com/package/@hubspot/mcp-server) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://www.npmjs.com/package/@hubspot/mcp-server) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="hubspot",
    command="npx",
    args=["-y", "@hubspot/mcp-server"],
    env={"PRIVATE_APP_ACCESS_TOKEN": "<private_app_access_token>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="hubspot",
    command="npx",
    args=["-y", "@hubspot/mcp-server"],
    env={"PRIVATE_APP_ACCESS_TOKEN": "<private_app_access_token>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/hyperbrowser.mdx">
---
title: "Hyperbrowser"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Hyperbrowser

### Description

Enables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks.

Visit the [server homepage (↗)](https://github.com/hyperbrowserai/mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/hyperbrowserai/mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="hyperbrowser",
    command="npx",
    args=[
        "-y",
        "hyperbrowser-mcp",
    ],
    env={"HYPERBROWSER_API_KEY": "<api_key>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="hyperbrowser",
    command="npx",
    args=[
        "-y",
        "hyperbrowser-mcp",
    ],
    env={"HYPERBROWSER_API_KEY": "<api_key>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/index.mdx">
---
title: "Local MCP Servers"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-local-mcp.mdx';
import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Local MCP Servers

<Intro />

<ItemList items={getItems("Local MCP")} />
</file>

<file path="docs/portia-tools/local-mcp/jetbrains-ide.mdx">
---
title: "JetBrains IDE"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# JetBrains IDE

### Description

Interact with JetBrains IDEs for code analysis and development tasks.

Visit the [server homepage (↗)](https://github.com/jetbrains/mcp-jetbrains) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="jetbrains",
    command="npx",
    args=["-y", "@jetbrains/mcp-proxy"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="jetbrains",
    command="npx",
    args=["-y", "@jetbrains/mcp-proxy"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/minimax.mdx">
---
title: "MiniMax"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# MiniMax

### Description

Enables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features.

Visit the [server homepage (↗)](https://github.com/minimax-ai/minimax-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/minimax-ai/minimax-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="minmax",
    command="uvx",
    args=[
        "minimax-mcp",
        "-y",
    ],
    env={
        "MINIMAX_API_KEY": "<api_key>",
        "MINIMAX_MCP_BASE_PATH": "<path_to_minimax>",
        "MINIMAX_API_HOST": "https://api.minimax.io",
        "MINIMAX_API_RESOURCE_MODE": "url",
    },
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="minmax",
    command="uvx",
    args=[
        "minimax-mcp",
        "-y",
    ],
    env={
        "MINIMAX_API_KEY": "<api_key>",
        "MINIMAX_MCP_BASE_PATH": "<path_to_minimax>",
        "MINIMAX_API_HOST": "https://api.minimax.io",
        "MINIMAX_API_RESOURCE_MODE": "url",
    },
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/monday.com.mdx">
---
title: "Monday.com"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Monday.com

### Description

Integrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching.

Visit the [server homepage (↗)](https://github.com/mondaycom/mcp/tree/HEAD/packages/monday-api-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/mondaycom/mcp/tree/HEAD/packages/monday-api-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="monday.com",
    command="npx",
    args=[
        "@mondaydotcomorg/monday-api-mcp",
        "-t",
        "<api_key>",
    ],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="monday.com",
    command="npx",
    args=[
        "@mondaydotcomorg/monday-api-mcp",
        "-t",
        "<api_key>",
    ],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/mongodb.mdx">
---
title: "MongoDB"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# MongoDB

### Description

Provides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support.

Visit the [server homepage (↗)](https://github.com/mongodb-js/mongodb-mcp-server) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="mongodb",
    command="npx",
    args=["-y", "mongodb-mcp-server", "--connectionString", "<connection_string>"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="mongodb",
    command="npx",
    args=["-y", "mongodb-mcp-server", "--connectionString", "<connection_string>"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/netlify.mdx">
---
title: "Netlify"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Netlify

### Description

Integrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows.

Visit the [server homepage (↗)](https://github.com/netlify/netlify-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/netlify/netlify-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="netlify",
    command="npx",
    args=["-y", "@netlify/mcp"],
    env={
        "NETLIFY_PERSONAL_ACCESS_TOKEN": "<api_key>",
    },
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="netlify",
    command="npx",
    args=["-y", "@netlify/mcp"],
    env={
        "NETLIFY_PERSONAL_ACCESS_TOKEN": "<api_key>",
    },
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/notion.mdx">
---
title: "Notion"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Notion

### Description

Bridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code

Visit the [server homepage (↗)](https://github.com/makenotion/notion-mcp-server) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/makenotion/notion-mcp-server) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="notionApi",
    command="npx",
    args=["-y", "@notionhq/notion-mcp-server"],
    env={
        "OPENAPI_MCP_HEADERS": '{"Authorization": "Bearer <api_key>", "Notion-Version": "2022-06-28" }'
    },
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="notionApi",
    command="npx",
    args=["-y", "@notionhq/notion-mcp-server"],
    env={
        "OPENAPI_MCP_HEADERS": '{"Authorization": "Bearer <api_key>", "Notion-Version": "2022-06-28" }'
    },
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/perplexity.mdx">
---
title: "Perplexity"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Perplexity

### Description

Connector for the Perplexity API, to enable web search without leaving the MCP ecosystem.

Visit the [server homepage (↗)](https://github.com/ppl-ai/modelcontextprotocol) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/ppl-ai/modelcontextprotocol) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="perplexity-ask",
    command="npx",
    args=["-y", "server-perplexity-ask"],
    env={"PERPLEXITY_API_KEY": "<api_key>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="perplexity-ask",
    command="npx",
    args=["-y", "server-perplexity-ask"],
    env={"PERPLEXITY_API_KEY": "<api_key>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/playwright.mdx">
---
title: "Playwright"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Playwright

### Description

Enables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities.

Visit the [server homepage (↗)](https://github.com/microsoft/playwright-mcp) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="playwright",
    command="npx",
    args=["@playwright/mcp@latest"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="playwright",
    command="npx",
    args=["@playwright/mcp@latest"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/qdrant.mdx">
---
title: "Qdrant"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Qdrant

### Description

Store and retrieve vector-based memories for AI systems.

Visit the [server homepage (↗)](https://github.com/qdrant/mcp-server-qdrant) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="qdrant",
    command="uvx",
    args=[
        "mcp-server-qdrant",
    ],
    env={
        "QDRANT_LOCAL_PATH": "<path_to_qdrant>",
        "COLLECTION_NAME": "<collection_name>",
        "EMBEDDING_MODEL": "<model_name>",
    },
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="qdrant",
    command="uvx",
    args=[
        "mcp-server-qdrant",
    ],
    env={
        "QDRANT_LOCAL_PATH": "<path_to_qdrant>",
        "COLLECTION_NAME": "<collection_name>",
        "EMBEDDING_MODEL": "<model_name>",
    },
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/shopify-dev.mdx">
---
title: "Shopify Dev"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Shopify Dev

### Description

Integrates with Shopify Dev. Supports various tools to interact with different Shopify APIs.

Visit the [server homepage (↗)](https://github.com/shopify/dev-mcp) for more information about how to use this MCP server.

### Authorisation

This server does not require any extra authentication to use.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="shopify-dev",
    command="npx",
    args=["@shopify/dev-mcp@latest"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="shopify-dev",
    command="npx",
    args=["@shopify/dev-mcp@latest"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/supabase.mdx">
---
title: "Supabase"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Supabase

### Description

Connects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands.

Visit the [server homepage (↗)](https://github.com/supabase-community/supabase-mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/supabase-community/supabase-mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="supabase",
    command="npx",
    args=[
        "-y",
        "@supabase/mcp-server-supabase@latest",
        "--read-only",
        "--project-ref=<project_ref>",
    ],
    env={"SUPABASE_ACCESS_TOKEN": "<personal_access_token>"},
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="supabase",
    command="npx",
    args=[
        "-y",
        "@supabase/mcp-server-supabase@latest",
        "--read-only",
        "--project-ref=<project_ref>",
    ],
    env={"SUPABASE_ACCESS_TOKEN": "<personal_access_token>"},
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/twilio.mdx">
---
title: "Twilio"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Twilio

### Description

Integrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities.

Visit the [server homepage (↗)](https://github.com/twilio-labs/mcp) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/twilio-labs/mcp) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="twilio",
    command="npx",
    args=["-y", "@twilio-alpha/mcp", "YOUR_ACCOUNT_SID/YOUR_API_KEY:YOUR_API_SECRET"],
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="twilio",
    command="npx",
    args=["-y", "@twilio-alpha/mcp", "YOUR_ACCOUNT_SID/YOUR_API_KEY:YOUR_API_SECRET"],
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/local-mcp/xero.mdx">
---
title: "Xero"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Xero

### Description

Provides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management.

Visit the [server homepage (↗)](https://github.com/xeroapi/xero-mcp-server) for more information about how to use this MCP server.

### Authorisation

To use this MCP server, you need API credentials in your environment. Please refer to the [server homepage (↗)](https://github.com/xeroapi/xero-mcp-server) for more information.

### Usage

To use this MCP server in your Portia project, you need to create an `McpToolRegistry` instance and pass it to the `Portia` constructor.

```python
McpToolRegistry.from_stdio_connection(
    server_name="xero",
    command="npx",
    args=["-y", "@xeroapi/xero-mcp-server@latest"],
    env={
        "XERO_CLIENT_ID": "your-client-id",
        "XERO_CLIENT_SECRET": "your-client-secret",
    },
)
                    
```

<details>
<summary>Complete example</summary>

Equip your `Portia` instance with the tools from the MCP server, in addition to the default tools from the `DefaultToolRegistry`:

```python
from portia import DefaultToolRegistry, McpToolRegistry, Portia, Config

config = Config.from_default()
tool_registry = DefaultToolRegistry(config) +  McpToolRegistry.from_stdio_connection(
    server_name="xero",
    command="npx",
    args=["-y", "@xeroapi/xero-mcp-server@latest"],
    env={
        "XERO_CLIENT_ID": "your-client-id",
        "XERO_CLIENT_SECRET": "your-client-secret",
    },
)
                    

portia = Portia(config=config, tools=tool_registry)
```

</details>

:::tip[Copy to clipboard]
Click the "copy" icon in the top right corner of the code block to copy the code to your clipboard.
:::

See more information about integrating MCP servers [here (↗)](/mcp-servers).
</file>

<file path="docs/portia-tools/open-source/browser-for-url.mdx">
---
title: "Open Source - Browser for URL"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Browser for URL Tool

<Intro />

## Tool details
**Tool ID:** `browser_tool_for_url_www_portialabs_ai`

**Tool description:** Browser tool for the URL https://www.portialabs.ai. Can be used to navigate to the URL and complete tasks.

**Args schema:**
```json
{
  "description": "Input schema for the BrowserToolForUrl.\n\nThis schema defines the expected input parameters for the BrowserToolForUrl class.\n\nAttributes:\n    task (str): The task description that should be performed by the browser tool.\n        This is a required field that specifies what actions should be taken\n        on the predefined URL.",
  "properties": {
    "task": {
      "description": "The task to be completed by the Browser tool.",
      "title": "Task",
      "type": "string"
    }
  },
  "required": [
    "task"
  ],
  "title": "BrowserToolForUrlSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', "The Browser tool's response to the user query.")
```
</file>

<file path="docs/portia-tools/open-source/browser.mdx">
---
title: "Open Source - Browser Use"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Browser Use Tool

<Intro />

## Tool details
**Tool ID:** `browser_tool`

**Tool description:** General purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain.

**Usage notes:**

Also see the <a href='/SDK/portia/open_source_tools/browser_tool#browsertoolforurl-objects'>BrowserToolForUrl tool</a>, which you can initialise with a URL to run your browser tasks from.

**Args schema:**
```json
{
  "description": "Input schema for the BrowserTool.\n\nThis schema defines the expected input parameters for the BrowserTool class.\n\nAttributes:\n    url (str): The URL that the browser tool should navigate to.\n        This is a required field specifying the target webpage.\n    task (str): The task description that should be performed by the browser tool.\n        This is a required field that specifies what actions should be taken\n        on the provided URL.\n    task_data (list[Any] | str | None): Task data that should be used to complete the task.\n        Can be a string, a list of strings, or a list of objects that will be converted to\n        strings. Important: This should include all relevant data in their entirety,\n        from the first to the last character (i.e. NOT a summary).",
  "properties": {
    "url": {
      "description": "The URL to navigate to.",
      "title": "Url",
      "type": "string"
    },
    "task": {
      "description": "The task to be completed by the Browser tool.",
      "title": "Task",
      "type": "string"
    },
    "task_data": {
      "anyOf": [
        {
          "items": {},
          "type": "array"
        },
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary).",
      "title": "Task Data"
    }
  },
  "required": [
    "url",
    "task"
  ],
  "title": "BrowserToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', "The Browser tool's response to the user query.")
```
</file>

<file path="docs/portia-tools/open-source/crawl.mdx">
---
title: "Open Source - Crawl"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Crawl Tool

<Intro />

## Tool details
**Tool ID:** `crawl_tool`

**Tool description:** Crawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration.

**Usage notes:**

This tool uses the Tavily API. You can sign up to obtain a Tavily API key (<a href="https://tavily.com" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.

**Args schema:**
```json
{
  "description": "Input for CrawlTool.",
  "properties": {
    "url": {
      "description": "The root URL to begin the crawl (e.g., 'https://docs.tavily.com')",
      "title": "Url",
      "type": "string"
    },
    "instructions": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Natural language instructions for the crawler (e.g., 'Find all pages on the Python SDK')",
      "title": "Instructions"
    },
    "max_depth": {
      "default": 1,
      "description": "Max depth of the crawl. Defines how far from the base URL the crawler can explore",
      "maximum": 5,
      "minimum": 1,
      "title": "Max Depth",
      "type": "integer"
    },
    "max_breadth": {
      "default": 20,
      "description": "Max number of links to follow per level of the tree (i.e., per page)",
      "maximum": 100,
      "minimum": 1,
      "title": "Max Breadth",
      "type": "integer"
    },
    "limit": {
      "default": 50,
      "description": "Total number of links the crawler will process before stopping",
      "maximum": 500,
      "minimum": 1,
      "title": "Limit",
      "type": "integer"
    },
    "select_paths": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to select only URLs with specific path patterns (e.g., ['/docs/.*', '/api/v1.*'])",
      "title": "Select Paths"
    },
    "select_domains": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to select crawling to specific domains or subdomains (e.g., ['^docs\\.example\\.com$'])",
      "title": "Select Domains"
    },
    "exclude_paths": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to exclude URLs with specific path patterns (e.g., ['/private/.*', '/admin/.*'])",
      "title": "Exclude Paths"
    },
    "exclude_domains": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to exclude specific domains or subdomains from crawling (e.g., ['^private\\.example\\.com$'])",
      "title": "Exclude Domains"
    },
    "allow_external": {
      "default": false,
      "description": "Whether to allow following links that go to external domains",
      "title": "Allow External",
      "type": "boolean"
    }
  },
  "required": [
    "url"
  ],
  "title": "CrawlToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: crawled content and discovered pages')
```
</file>

<file path="docs/portia-tools/open-source/extract.mdx">
---
title: "Open Source - Extract"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Extract Tool

<Intro />

## Tool details
**Tool ID:** `extract_tool`

**Tool description:** Extracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access

**Usage notes:**

This tool uses the Tavily API. You can sign up to obtain a Tavily API key (<a href="https://tavily.com" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.

**Args schema:**
```json
{
  "description": "Input for ExtractTool.",
  "properties": {
    "urls": {
      "description": "List of URLs to extract content from",
      "items": {
        "type": "string"
      },
      "title": "Urls",
      "type": "array"
    },
    "include_images": {
      "default": false,
      "description": "Whether to include images in the extraction",
      "title": "Include Images",
      "type": "boolean"
    },
    "include_favicon": {
      "default": false,
      "description": "Whether to include favicon in the extraction",
      "title": "Include Favicon",
      "type": "boolean"
    },
    "extract_depth": {
      "default": "basic",
      "description": "The depth of the extraction process. Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency. Basic extraction costs 1 credit per 5 successful URL extractions, while advanced extraction costs 2 credits per 5 successful URL extractions.",
      "title": "Extract Depth",
      "type": "string"
    },
    "format": {
      "default": "markdown",
      "description": "Output format: 'markdown' or 'text'",
      "title": "Format",
      "type": "string"
    }
  },
  "required": [
    "urls"
  ],
  "title": "ExtractToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: extracted content from URLs')
```
</file>

<file path="docs/portia-tools/open-source/file-reader.mdx">
---
title: "Open Source - File Reader"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# File Reader Tool

<Intro />

## Tool details
**Tool ID:** `file_reader_tool`

**Tool description:** Finds and reads content from a local file on Disk

**Args schema:**
```json
{
  "description": "Schema defining the inputs for the FileReaderTool.",
  "properties": {
    "filename": {
      "description": "The path (either full or relative) where the file should be read from",
      "title": "Filename",
      "type": "string"
    }
  },
  "required": [
    "filename"
  ],
  "title": "FileReaderToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'A string dump or JSON of the file content')
```
</file>

<file path="docs/portia-tools/open-source/file-writer.mdx">
---
title: "Open Source - File Writer"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# File Writer Tool

<Intro />

## Tool details
**Tool ID:** `file_writer_tool`

**Tool description:** Writes content to a file locally

**Args schema:**
```json
{
  "description": "Schema defining the inputs for the FileWriterTool.",
  "properties": {
    "filename": {
      "description": "The location where the file should be saved",
      "title": "Filename",
      "type": "string"
    },
    "content": {
      "description": "The content to write to the file",
      "title": "Content",
      "type": "string"
    }
  },
  "required": [
    "filename",
    "content"
  ],
  "title": "FileWriterToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'A string indicating where the content was written to')
```
</file>

<file path="docs/portia-tools/open-source/image-understanding.mdx">
---
title: "Open Source - Image Understanding"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Image Understanding Tool

<Intro />

## Tool details
**Tool ID:** `image_understanding_tool`

**Tool description:** Tool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights.

**Args schema:**
```json
{
  "description": "Input for Image Understanding Tool.",
  "properties": {
    "task": {
      "description": "The task to be completed by the Image tool.",
      "title": "Task",
      "type": "string"
    },
    "image_url": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Image URL for processing.",
      "title": "Image Url"
    },
    "image_file": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Image file for processing.",
      "title": "Image File"
    }
  },
  "required": [
    "task"
  ],
  "title": "ImageUnderstandingToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', "The Image understanding tool's response to the user query about the provided image.")
```
</file>

<file path="docs/portia-tools/open-source/index.mdx">
---
title: "Open Source Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Open Source Tools

<ItemList items={getItems("Open Source")} />
</file>

<file path="docs/portia-tools/open-source/llm.mdx">
---
title: "Open Source - LLM"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# LLM Tool

<Intro />

## Tool details
**Tool ID:** `llm_tool`

**Tool description:** Jack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user.

**Args schema:**
```json
{
  "description": "Input for LLM Tool.",
  "properties": {
    "task": {
      "description": "The task to be completed by the LLM tool",
      "title": "Task",
      "type": "string"
    },
    "task_data": {
      "anyOf": [
        {
          "items": {},
          "type": "array"
        },
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary).",
      "title": "Task Data"
    }
  },
  "required": [
    "task"
  ],
  "title": "LLMToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', "The LLM's response to the user query.")
```
</file>

<file path="docs/portia-tools/open-source/map-website.mdx">
---
title: "Open Source - Map Website"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Map Website Tool

<Intro />

## Tool details
**Tool ID:** `map_tool`

**Tool description:** Maps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery.

**Usage notes:**

This tool uses the Tavily API. You can sign up to obtain a Tavily API key (<a href="https://tavily.com" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.

**Args schema:**
```json
{
  "description": "Input for MapTool.",
  "properties": {
    "url": {
      "description": "The root URL to begin the mapping (e.g., 'docs.tavily.com')",
      "title": "Url",
      "type": "string"
    },
    "max_depth": {
      "default": 1,
      "description": "Max depth of the mapping. Defines how far from the base URL the crawler can explore",
      "title": "Max Depth",
      "type": "integer"
    },
    "max_breadth": {
      "default": 20,
      "description": "Max number of links to follow per level of the tree (i.e., per page)",
      "title": "Max Breadth",
      "type": "integer"
    },
    "limit": {
      "default": 50,
      "description": "Total number of links the crawler will process before stopping",
      "title": "Limit",
      "type": "integer"
    },
    "instructions": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Natural language instructions for the crawler (e.g., 'Python SDK')",
      "title": "Instructions"
    },
    "select_paths": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to select only URLs with specific path patterns (e.g., ['/docs/.*', '/api/v1.*'])",
      "title": "Select Paths"
    },
    "select_domains": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to select crawling to specific domains or subdomains (e.g., ['^docs\\.example\\.com$'])",
      "title": "Select Domains"
    },
    "exclude_paths": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to exclude URLs with specific path patterns (e.g., ['/private/.*', '/admin/.*'])",
      "title": "Exclude Paths"
    },
    "exclude_domains": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Regex patterns to exclude specific domains or subdomains from crawling (e.g., ['^private\\.example\\.com$'])",
      "title": "Exclude Domains"
    },
    "allow_external": {
      "default": false,
      "description": "Whether to allow following links that go to external domains",
      "title": "Allow External",
      "type": "boolean"
    },
    "categories": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Filter URLs using predefined categories like 'Documentation', 'Blog', 'API', etc.",
      "title": "Categories"
    }
  },
  "required": [
    "url"
  ],
  "title": "MapToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: list of discovered URLs on the website')
```
</file>

<file path="docs/portia-tools/open-source/pdf-reader.mdx">
---
title: "Open Source - PDF Reader"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# PDF Reader Tool

<Intro />

## Tool details
**Tool ID:** `pdf_reader_tool`

**Tool description:** Read a PDF file and extract its text content using Mistral OCR

**Usage notes:**

You must have a MistralAI API key set in the environment variable `MISTRAL_API_KEY` to use this tool.

**Args schema:**
```json
{
  "description": "Input for PDFReaderTool.",
  "properties": {
    "file_path": {
      "description": "The path to the PDF file to be read.",
      "title": "File Path",
      "type": "string"
    }
  },
  "required": [
    "file_path"
  ],
  "title": "PDFReaderToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'The extracted text content from the PDF file.')
```
</file>

<file path="docs/portia-tools/open-source/search.mdx">
---
title: "Open Source - Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Search Tool

<Intro />

## Tool details
**Tool ID:** `search_tool`

**Tool description:** Searches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet

**Usage notes:**

This tool uses the Tavily API. You can sign up to obtain a Tavily API key (<a href="https://tavily.com" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.

**Args schema:**
```json
{
  "description": "Input for SearchTool.",
  "properties": {
    "search_query": {
      "description": "The query to search for. For example, 'what is the capital of France?' or 'who won the US election in 2020?'",
      "title": "Search Query",
      "type": "string"
    }
  },
  "required": [
    "search_query"
  ],
  "title": "SearchToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: output of the search results')
```
</file>

<file path="docs/portia-tools/open-source/weather.mdx">
---
title: "Open Source - Weather"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-open-source.mdx';

# Weather Tool

<Intro />

## Tool details
**Tool ID:** `weather_tool`

**Tool description:** Get the weather for a given city

**Usage notes:**

This tool uses a simple GET endpoint from OpenWeatherMap. Please sign up to obtain an API key from them (<a href="https://home.openweathermap.org/users/sign_in" target="_blank">**↗**</a>) and set it in the environment variable `OPENWEATHERMAP_API_KEY`.

**Args schema:**
```json
{
  "description": "Input for WeatherTool.",
  "properties": {
    "city": {
      "description": "The city to get the weather for",
      "title": "City",
      "type": "string"
    }
  },
  "required": [
    "city"
  ],
  "title": "WeatherToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'String output of the weather with temp and city')
```
</file>

<file path="docs/portia-tools/portia-cloud/github/index.mdx">
---
title: "GitHub Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# GitHub Tools

<ItemList items={getItems("GitHub")} />
</file>

<file path="docs/portia-tools/portia-cloud/github/list-repo-issues.mdx">
---
title: "GitHub - Issue: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Issue: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:github::list_repo_issues`

**Tool description:** List issues in a GitHub repository.

**Args schema:**
```json
{
  "description": "Schema for the StarGitHubRepoTool input.",
  "properties": {
    "repo": {
      "description": "The repository to list issues. For example: PortiaAI/portia-sdk-python",
      "title": "Repo",
      "type": "string"
    }
  },
  "required": [
    "repo"
  ],
  "title": "ListGitHubRepoIssuesToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('list', 'A list of issues in the GitHub repository.')
```
</file>

<file path="docs/portia-tools/portia-cloud/github/list-repos.mdx">
---
title: "GitHub - Repository: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Repository: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:github::list_repos`

**Tool description:** Lists all public repositories for a GitHub organization.

**Args schema:**
```json
{
  "description": "Schema for the ListGitHubReposTool input.",
  "properties": {
    "org": {
      "description": "The organization name.",
      "title": "Org",
      "type": "string"
    }
  },
  "required": [
    "org"
  ],
  "title": "ListGitHubReposSchema",
  "type": "object"
}
```

**Output schema:**
```
('list', 'A list of public repositories.')
```
</file>

<file path="docs/portia-tools/portia-cloud/github/search-repos.mdx">
---
title: "GitHub - Repository: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Repository: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:github::search_repos`

**Tool description:** Searches all public repositories for a specific term.

**Args schema:**
```json
{
  "description": "Schema for the SearchGitHubReposTool input.",
  "properties": {
    "search_term": {
      "description": "The term to search for.",
      "title": "Search Term",
      "type": "string"
    }
  },
  "required": [
    "search_term"
  ],
  "title": "SearchGitHubReposSchema",
  "type": "object"
}
```

**Output schema:**
```
('list', 'A list of public repositories that match.')
```
</file>

<file path="docs/portia-tools/portia-cloud/github/star-repo.mdx">
---
title: "GitHub - Repository: Star"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Repository: Star Tool

<Intro />

## Tool details
**Tool ID:** `portia:github::star_repo`

**Tool description:** Stars a GitHub repository.

**Args schema:**
```json
{
  "description": "Schema for the StarGitHubRepoTool input.",
  "properties": {
    "repo": {
      "description": "The repository to star in the form organization/repository.For example: PortiaAI/portia-sdk-python",
      "title": "Repo",
      "type": "string"
    }
  },
  "required": [
    "repo"
  ],
  "title": "StarGitHubRepoSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'A string indicating successful starring')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-check-availability.mdx">
---
title: "Google Calendar - Calendar: Check Availability"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Check Availability Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:check_availability`

**Tool description:** Checks the availability of this authenticated user for a given time range. DO NOT use this to validate availability of people the user wants to meet with. DO NOT use this unless the user specifically asks for availability checking, e.g by saying 'find when I am free', or 'check my availability'. Either the day, end_time, or start_time must be provided. Pay close attention to the task if it says 'before' or 'after'.

**Args schema:**
```json
{
  "description": "Schema for checking Google Calendar availability.",
  "properties": {
    "start_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Start time to check availability in ISO format, e.g 2024-09-20T20:00:00. Do not include the timezone in this field.",
      "title": "Start Time"
    },
    "end_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "End time to check availability in ISO format, can be omitted e.g 2024-09-20T20:00:00. Do not include the timezone in this field.",
      "title": "End Time"
    },
    "day": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The day to check availability for in ISO format, e.g 2024-09-20.",
      "title": "Day"
    }
  },
  "title": "GoogleCalendarCheckAvailabilitySchema",
  "type": "object"
}
```

**Output schema:**
```
('list[dict[str, str]]', 'Returns a list of times when the user is available. An empty list means the user is unavailable.')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-create-event.mdx">
---
title: "Google Calendar - Calendar: Create Event"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Create Event Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:create_event`

**Tool description:** Creates a Google Calendar event. DO NOT call portia:google:gcalendar:check_availability before using this tool, unless the user explicitly asks you to check their availability.

**Args schema:**
```json
{
  "description": "Schema for creating a Google Calendar event.",
  "properties": {
    "event_title": {
      "description": "The title of the calendar event",
      "title": "Event Title",
      "type": "string"
    },
    "start_time": {
      "description": "The start time of the event in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "format": "date-time",
      "title": "Start Time",
      "type": "string"
    },
    "end_time": {
      "description": "The end time of the event in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "format": "date-time",
      "title": "End Time",
      "type": "string"
    },
    "event_description": {
      "description": "The description of the event",
      "title": "Event Description",
      "type": "string"
    },
    "attendees": {
      "description": "List of attendees' email addresses",
      "items": {
        "type": "string"
      },
      "title": "Attendees",
      "type": "array"
    }
  },
  "required": [
    "event_title",
    "start_time",
    "end_time",
    "event_description",
    "attendees"
  ],
  "title": "GoogleCalendarCreateEventSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the tool')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-delete-event.mdx">
---
title: "Google Calendar - Calendar: Delete Event"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Delete Event Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:delete_event`

**Tool description:** Deletes the Google Calendar event associated with the ID.

**Args schema:**
```json
{
  "description": "Schema for deleting a Google Calendar event.",
  "properties": {
    "event_id": {
      "description": "The ID of the event to delete",
      "title": "Event Id",
      "type": "string"
    }
  },
  "required": [
    "event_id"
  ],
  "title": "GoogleCalendarDeleteEventSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the tool')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-get-event-details.mdx">
---
title: "Google Calendar - Calendar: Get Event"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Get Event Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:get_event_details`

**Tool description:** Gets Google Calendar event using an event ID.

**Args schema:**
```json
{
  "description": "Schema for getting details about a Google Calendar event.",
  "properties": {
    "event_id": {
      "description": "The event details to retrieve",
      "title": "Event Id",
      "type": "string"
    }
  },
  "required": [
    "event_id"
  ],
  "title": "GoogleCalendarGetEventDetailsSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'A dictionary containing information about a single calendar event')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-get-events-by-properties.mdx">
---
title: "Google Calendar - Calendar: Get Events By Properties"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Get Events By Properties Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:get_events_by_properties`

**Tool description:** Gets Google Calendar events by properties, returning the matching event details. You do not need to provide all the properties, only the ones you have provided with.

**Args schema:**
```json
{
  "description": "Schema for getting a Google Calendar events by properties.",
  "properties": {
    "event_title": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The title of the event to get",
      "title": "Event Title"
    },
    "start_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "string"
        }
      ],
      "default": "1970-01-01T00:00:00",
      "description": "The earliest time of the events to get in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "title": "Start Time"
    },
    "end_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "string"
        }
      ],
      "default": "2100-01-01T00:00:00",
      "description": "The latest time of the events to get in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "title": "End Time"
    },
    "event_description": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The description of the events to get",
      "title": "Event Description"
    },
    "attendees": {
      "default": [],
      "description": "The attendees' of the events to get",
      "items": {
        "type": "string"
      },
      "title": "Attendees",
      "type": "array"
    },
    "max_results": {
      "default": 10,
      "description": "The maximum number of events to return",
      "title": "Max Results",
      "type": "integer"
    }
  },
  "title": "GoogleCalendarGetEventsByPropertiesSchema",
  "type": "object"
}
```

**Output schema:**
```
('list[dict]', 'A list of dictionaries containing information about matching calendar events')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/calendar-modify-event.mdx">
---
title: "Google Calendar - Calendar: Modify Event"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Calendar: Modify Event Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gcalendar:modify_event`

**Tool description:** Modifies an existing Google Calendar event. You must provide the event ID to modify, and can optionally provide new values if desired for the title, start time, end time, description, and attendees.

**Args schema:**
```json
{
  "description": "Schema for modifying a Google Calendar event.",
  "properties": {
    "event_id": {
      "description": "The ID of the event to modify, likely retrieved from portia:google:gcalendar:get_events_by_properties",
      "title": "Event Id",
      "type": "string"
    },
    "event_title": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The new title of the calendar event",
      "title": "Event Title"
    },
    "start_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The new start time in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "title": "Start Time"
    },
    "end_time": {
      "anyOf": [
        {
          "format": "date-time",
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The new end time in ISO format without timezone, e.g 2024-09-20T20:00:00",
      "title": "End Time"
    },
    "event_description": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The new description of the event",
      "title": "Event Description"
    },
    "attendees": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "New list of attendees email addresses",
      "title": "Attendees"
    }
  },
  "required": [
    "event_id"
  ],
  "title": "GoogleCalendarModifyEventSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the tool')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-calendar/index.mdx">
---
title: "Google Calendar Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Google Calendar Tools

<ItemList items={getItems("Google Calendar")} />
</file>

<file path="docs/portia-tools/portia-cloud/google-docs/docs-get-document.mdx">
---
title: "Google Docs - Docs: Get Document"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Docs: Get Document Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:docs:get_document`

**Tool description:** Get a document from Google Docs in plain text format by ID. The GoogleDriveSearchTool should be used to search for a document by name if an ID is not known.

**Args schema:**
```json
{
  "description": "Schema for the Google Docs get document tool.",
  "properties": {
    "document_id": {
      "description": "The ID of the document to get. It can contain letters, numbers, and some special characters.",
      "title": "Document Id",
      "type": "string"
    }
  },
  "required": [
    "document_id"
  ],
  "title": "GoogleDocsGetDocumentToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: The content of the document in plain text format.')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-docs/docs-get-structured-document.mdx">
---
title: "Google Docs - Docs: Get Structured Document"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Docs: Get Structured Document Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:docs:get_structured_document`

**Tool description:** Get a document from Google Docs in a machine readable format. Do not use unless you reallyneed a structured document.

**Args schema:**
```json
{
  "description": "Schema for the Google Docs get document tool.",
  "properties": {
    "document_id": {
      "description": "The ID of the document to get. It can contain letters, numbers, and some special characters.",
      "title": "Document Id",
      "type": "string"
    }
  },
  "required": [
    "document_id"
  ],
  "title": "GoogleDocsGetStructuredDocumentToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Containing information about the document in a structured format.Includes title, a structured body and other metadata like file type')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-docs/index.mdx">
---
title: "Google Docs Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Google Docs Tools

<ItemList items={getItems("Google Docs")} />
</file>

<file path="docs/portia-tools/portia-cloud/google-drive/drive-search.mdx">
---
title: "Google Drive - Drive: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Drive: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:drive:search`

**Tool description:** Search for files and folders in Google Drive. Google Drive stores proprietary files like Google Docs, Sheets, and Slides. It also stores regular files like PDFs, images, and videos or even files from other apps like Microsoft docx, xlsx, pptx, etc. Use this tool to search for files using a search query.  This tool should be used to resolve name / file descriptions into concrete file IDs for other Google tools to use when needed.

**Args schema:**
```json
{
  "description": "Schema for the Google Drive search tool.",
  "properties": {
    "query": {
      "description": "The query to search for. ALWAYS EXCLUDE words like 'doc', 'sheet', 'spreadsheet', 'file' from the end query string. For example if the query is 'cash flow forecast spreadsheet', the query string should be 'cash flow forecast'",
      "title": "Query",
      "type": "string"
    },
    "mime_type": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The MIME type of the files to search for. Use this if you want to search for files with a specific type of file or file extension. For example, 'application/pdf' or 'pdf'. Uses RFC 6838 standard for MIME types.",
      "title": "Mime Type"
    }
  },
  "required": [
    "query"
  ],
  "title": "GoogleDriveSearchToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Dictionary containing the results of the Google Drive search. Each file result includes metadata like name, id, mimeType and more.')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-drive/index.mdx">
---
title: "Google Drive Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Google Drive Tools

<ItemList items={getItems("Google Drive")} />
</file>

<file path="docs/portia-tools/portia-cloud/google-gmail/gmail-draft-email.mdx">
---
title: "Google Gmail - Gmail: Draft"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Gmail: Draft Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gmail:draft_email`

**Tool description:** Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the portia:google:gmail:send_draft_email. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.

**Args schema:**
```json
{
  "description": "Input for DraftEmailTool.",
  "properties": {
    "recipients": {
      "description": "The recipients that the email should be drafted for (should be a list of email addresses)",
      "items": {
        "type": "string"
      },
      "title": "Recipients",
      "type": "array"
    },
    "email_title": {
      "description": "The title of the email draft",
      "title": "Email Title",
      "type": "string"
    },
    "email_body": {
      "description": "The body of the email draft",
      "title": "Email Body",
      "type": "string"
    }
  },
  "required": [
    "recipients",
    "email_title",
    "email_body"
  ],
  "title": "DraftEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the email drafted')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-gmail/gmail-search-email.mdx">
---
title: "Google Gmail - Gmail: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Gmail: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gmail:search_email`

**Tool description:** Searches for emails and drafts in the user's inbox and returns emails content that match the query.

**Args schema:**
```json
{
  "description": "Input for SearchEmailTool.",
  "properties": {
    "query": {
      "description": "The query to search for emails. This supports Gmail search syntax (e.g. 'from:jane@acme.com', 'subject:meeting', 'after:YYYY/MM/DD' or 'before:YYYY/MM/DD') or a combination of them.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "SearchEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('list[dict[str, str]]', 'list[dict[str, str]]: List of emails with the following keys: from, to, subject, date, body and id of the email.')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-gmail/gmail-send-draft-email.mdx">
---
title: "Google Gmail - Gmail: Send Draft"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Gmail: Send Draft Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gmail:send_draft_email`

**Tool description:** Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.

**Args schema:**
```json
{
  "description": "Input for SendDraftEmailTool.",
  "properties": {
    "draft_id": {
      "description": "The id of the draft email as returned by the DraftEmailTool tool",
      "title": "Draft Id",
      "type": "string"
    }
  },
  "required": [
    "draft_id"
  ],
  "title": "SendDraftEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('str', 'str: ID of the email sent')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-gmail/gmail-send-email.mdx">
---
title: "Google Gmail - Gmail: Send"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Gmail: Send Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:gmail:send_email`

**Tool description:** Sends an email to the recipients indicated. Should not be used with the draft email tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.

**Args schema:**
```json
{
  "description": "Input for SendEmailTool.",
  "properties": {
    "recipients": {
      "description": "The recipients that the email should be sent to (should be a list of email addresses)",
      "items": {
        "type": "string"
      },
      "title": "Recipients",
      "type": "array"
    },
    "email_title": {
      "description": "The title of the email to be sent",
      "title": "Email Title",
      "type": "string"
    },
    "email_body": {
      "description": "The body of the email to be sent",
      "title": "Email Body",
      "type": "string"
    }
  },
  "required": [
    "recipients",
    "email_title",
    "email_body"
  ],
  "title": "SendEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the email sent')
```
</file>

<file path="docs/portia-tools/portia-cloud/google-gmail/index.mdx">
---
title: "Google Gmail Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Google Gmail Tools

<ItemList items={getItems("Google Gmail")} />
</file>

<file path="docs/portia-tools/portia-cloud/google-sheets/index.mdx">
---
title: "Google Sheets Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Google Sheets Tools

<ItemList items={getItems("Google Sheets")} />
</file>

<file path="docs/portia-tools/portia-cloud/google-sheets/sheets-get-spreadsheet.mdx">
---
title: "Google Sheets - Sheets: Get Spreadsheet"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-oauth.mdx';

# Sheets: Get Spreadsheet Tool

<Intro />

## Tool details
**Tool ID:** `portia:google:sheets:get_spreadsheet`

**Tool description:** Gets the content of a spreadsheet from Google Sheets by ID. The GoogleDriveSearchTool should be used to search for a spreadsheet by name if an ID is not known.

**Args schema:**
```json
{
  "description": "Schema for the Google Sheets Get Spreadsheet tool.",
  "properties": {
    "spreadsheet_id": {
      "description": "The ID of the spreadsheet to get.",
      "title": "Spreadsheet Id",
      "type": "string"
    }
  },
  "required": [
    "spreadsheet_id"
  ],
  "title": "GoogleSheetsGetSpreadsheetToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict[str, list[dict[str, str]]]: Content of the spreadsheet.This is a structured response with a hierarchy including sheet names and its content in dict format.')
```
</file>

<file path="docs/portia-tools/portia-cloud/microsoft-outlook/index.mdx">
---
title: "Microsoft Outlook Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Microsoft Outlook Tools

<ItemList items={getItems("Microsoft Outlook")} />
</file>

<file path="docs/portia-tools/portia-cloud/microsoft-outlook/outlook-draft-email.mdx">
---
title: "Microsoft Outlook - Outlook: Draft"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-microsoft.mdx';

# Outlook: Draft Tool

<Intro />

## Tool details
**Tool ID:** `portia:microsoft:outlook:draft_email`

**Tool description:** Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.

**Args schema:**
```json
{
  "description": "Input for DraftEmailTool.",
  "properties": {
    "recipients": {
      "description": "The recipients that the email should be drafted for (should be a list of email addresses)",
      "items": {
        "type": "string"
      },
      "title": "Recipients",
      "type": "array"
    },
    "email_title": {
      "description": "The title of the email draft",
      "title": "Email Title",
      "type": "string"
    },
    "email_body": {
      "description": "The body of the email draft",
      "title": "Email Body",
      "type": "string"
    }
  },
  "required": [
    "recipients",
    "email_title",
    "email_body"
  ],
  "title": "DraftEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the email drafted')
```
</file>

<file path="docs/portia-tools/portia-cloud/microsoft-outlook/outlook-search-email.mdx">
---
title: "Microsoft Outlook - Outlook: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-microsoft.mdx';

# Outlook: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:microsoft:outlook:search_email`

**Tool description:** Searches for emails in the user's Outlook inbox and returns emails content that match the query.

**Args schema:**
```json
{
  "description": "Input for SearchEmailTool.",
  "properties": {
    "query": {
      "description": "The query to search for emails. This supports basic search terms and can include filters like 'from:', 'subject:', etc.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "SearchEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('list[dict[str, str]]', 'list[dict[str, str]]: List of emails with the following keys: from, to, subject, date, body.')
```
</file>

<file path="docs/portia-tools/portia-cloud/microsoft-outlook/outlook-send-draft-email.mdx">
---
title: "Microsoft Outlook - Outlook: Send Draft"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-microsoft.mdx';

# Outlook: Send Draft Tool

<Intro />

## Tool details
**Tool ID:** `portia:microsoft:outlook:send_draft_email`

**Tool description:** Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.

**Args schema:**
```json
{
  "description": "Input for SendDraftEmailTool.",
  "properties": {
    "draft_id": {
      "description": "The id of the draft email as returned by the DraftEmailTool tool",
      "title": "Draft Id",
      "type": "string"
    }
  },
  "required": [
    "draft_id"
  ],
  "title": "SendDraftEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the email sent')
```
</file>

<file path="docs/portia-tools/portia-cloud/microsoft-outlook/outlook-send-email.mdx">
---
title: "Microsoft Outlook - Outlook: Send"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-microsoft.mdx';

# Outlook: Send Tool

<Intro />

## Tool details
**Tool ID:** `portia:microsoft:outlook:send_email`

**Tool description:** Sends an email to the recipients indicated. Should not be used with the draft email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.

**Args schema:**
```json
{
  "description": "Input for SendEmailTool.",
  "properties": {
    "recipients": {
      "description": "The recipients that the email should be sent to (should be a list of email addresses)",
      "items": {
        "type": "string"
      },
      "title": "Recipients",
      "type": "array"
    },
    "email_title": {
      "description": "The title of the email to be sent",
      "title": "Email Title",
      "type": "string"
    },
    "email_body": {
      "description": "The body of the email to be sent",
      "title": "Email Body",
      "type": "string"
    }
  },
  "required": [
    "recipients",
    "email_title",
    "email_body"
  ],
  "title": "SendEmailToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the email sent')
```
</file>

<file path="docs/portia-tools/portia-cloud/slack/find-message.mdx">
---
title: "Slack - Message: Find"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-slack.mdx';

# Message: Find Tool

<Intro />

## Tool details
**Tool ID:** `portia:slack:user:find_message`

**Tool description:** Search for a message in a Slack channel or chat.

**Args schema:**
```json
{
  "description": "Input for FindMessageTool.",
  "properties": {
    "target": {
      "description": "Slack channel ID (e.g. C084F1FSTFC), channel name (e.g. #slack-tool-testing)or user name (e.g. @tom) that the messages were sent to.",
      "title": "Target",
      "type": "string"
    },
    "query": {
      "default": "",
      "description": "When using the Slack Find Message tool to search for             messages you have to adhere to the query string structure             of slack strictly. In addition to whatever keywords are             relevant from the user's prompt, follow the guidelines             below to build the query string and never ever add anything             other than that.             To look for messages from a specific user you have to refer             to their slack user name using @ in the query string             like so: 'from:@UserName' e.g. 'from:@nathan' to get             messages from nathan.             To look for messages sent to me or someone else you have to             refer to their Slack username using @ in the query string             like so: 'to:@UserName' e.g. 'to:@mounir'.             Next, and this should ONLY be used if the user is asking             about messages in a specific channel, to look for messages             in a specific channel you have to insert 'in:ChannelName'             in the query string e.g. 'in:social'",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "target"
  ],
  "title": "FindSlackMessageToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the messages found')
```
</file>

<file path="docs/portia-tools/portia-cloud/slack/get-conversation.mdx">
---
title: "Slack - Conversation: Get History"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-slack.mdx';

# Conversation: Get History Tool

<Intro />

## Tool details
**Tool ID:** `portia:slack:user:conversation_history`

**Tool description:** Get the conversation history for a given channel by channel id. Requires an ID typically from the list_conversation_ids tool.

**Args schema:**
```json
{
  "description": "Input for GetSlackConversationTool.",
  "properties": {
    "channel_id": {
      "description": "The channel/group/private message id to get the conversation history for.",
      "title": "Channel Id",
      "type": "string"
    },
    "limit": {
      "default": 20,
      "description": "The maximum number of messages to return. Default is 20. Too many messages cancause the context window to be exceeded.",
      "title": "Limit",
      "type": "integer"
    }
  },
  "required": [
    "channel_id"
  ],
  "title": "GetSlackConversationToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Object per message with text, user, and replies if follow_threads is true')
```
</file>

<file path="docs/portia-tools/portia-cloud/slack/index.mdx">
---
title: "Slack Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Slack Tools

<ItemList items={getItems("Slack")} />
</file>

<file path="docs/portia-tools/portia-cloud/slack/list-conversations.mdx">
---
title: "Slack - Conversation: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-slack.mdx';

# Conversation: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:slack:bot:list_conversation_ids`

**Tool description:** List all conversations meta information only without comments in the slack workspaceThis tool should be used when you need to make api calls to other slack apis that requirea conversation or channel id. DOES NOT RETURN MESSAGES, CONVERSATION HISTORY, OR USER IDS.

**Args schema:**
```json
{
  "description": "Input for ListSlackConversationIDsTool.",
  "properties": {},
  "title": "ListSlackConversationIDsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Conversation meta information: Name, ID, and Type')
```
</file>

<file path="docs/portia-tools/portia-cloud/slack/list-users.mdx">
---
title: "Slack - Users: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-slack.mdx';

# Users: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:slack:bot:list_user_ids`

**Tool description:** List all users in the slack workspace. Returns user meta information: Name, ID, and EmailThis tool should be used when you need to make api calls to other slack apis that requirea user ID.

**Args schema:**
```json
{
  "description": "Input for ListSlackUserIDsTool.",
  "properties": {},
  "title": "ListSlackUserIDsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: User meta information: Name, ID, and Email')
```
</file>

<file path="docs/portia-tools/portia-cloud/slack/send-message.mdx">
---
title: "Slack - Message: Send"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-slack.mdx';

# Message: Send Tool

<Intro />

## Tool details
**Tool ID:** `portia:slack:bot:send_message`

**Tool description:** Send a message to a specific Slack channel or user by ID. Requires an ID provided by other tools.

**Args schema:**
```json
{
  "description": "Input for SendSlackMessageTool.",
  "properties": {
    "target_id": {
      "description": "Slack channel ID (i.e. C084F1FSTFC), or user ID (i.e. U084F1FSTFC) where themessage will be sent. This can be provided by other tools like list_conversation_idsor list_user_ids.",
      "title": "Target Id",
      "type": "string"
    },
    "message": {
      "description": "The message content to send.",
      "title": "Message",
      "type": "string"
    }
  },
  "required": [
    "target_id",
    "message"
  ],
  "title": "SendSlackMessageToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('dict', 'dict: Output of the message sent')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/article-search.mdx">
---
title: "Zendesk - Articles: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Articles: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:search_articles`

**Tool description:** Returns up to 25 articles relevant to the search query, which must be provided.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskArticleSearchTool.",
  "properties": {
    "query": {
      "description": "The search text to be matched or a search string. Examples: \"carrot potato\", \"'carrot potato'\".",
      "title": "Query",
      "type": "string"
    },
    "category": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to this category id.",
      "title": "Category"
    },
    "section": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to this section id.",
      "title": "Section"
    },
    "label_names": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A comma-separated list of label names.",
      "title": "Label Names"
    },
    "locale": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Search for articles in the specified locale (e.g. en-us). ",
      "title": "Locale"
    },
    "multibrand": {
      "anyOf": [
        {
          "type": "boolean"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Enable search across all brands if true. Defaults to false if omitted.",
      "title": "Multibrand"
    },
    "brand_id": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Search for articles in the specified brand.",
      "title": "Brand Id"
    },
    "created_before": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles created before a given date (format YYYY-MM-DD).",
      "title": "Created Before"
    },
    "created_after": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles created after a given date (format YYYY-MM-DD).",
      "title": "Created After"
    },
    "created_at": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles created on a given date (format YYYY-MM-DD).",
      "title": "Created At"
    },
    "updated_before": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles updated before a given date (format YYYY-MM-DD). ",
      "title": "Updated Before"
    },
    "updated_after": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles updated after a given date (format YYYY-MM-DD). ",
      "title": "Updated After"
    },
    "updated_at": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Limit the search to articles updated on a given date (format YYYY-MM-DD). ",
      "title": "Updated At"
    },
    "sort_by": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "One of created_at or updated_at. Defaults to sorting by relevance",
      "title": "Sort By"
    },
    "sort_order": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "One of asc or desc. Defaults to desc",
      "title": "Sort Order"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskArticleSearchToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/count-ticket-comments.mdx">
---
title: "Zendesk - Tickets: Count Comments"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Count Comments Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:count_comments`

**Tool description:** Returns an approximate count of the comments added to the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskCountTicketCommentsTool.",
  "properties": {
    "ticket_id": {
      "description": "The ID of the ticket",
      "title": "Ticket Id",
      "type": "integer"
    }
  },
  "required": [
    "ticket_id"
  ],
  "title": "ZendeskCountTicketCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API containing the approximate count of comments on a Zendesk ticket.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/count-tickets.mdx">
---
title: "Zendesk - Tickets: Count"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Count Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:count`

**Tool description:** Returns an approximate count of tickets in the account. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskCountTicketsTool.",
  "properties": {},
  "title": "ZendeskCountTicketsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API with the approximate count of tickets in the account.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/create-article-comments.mdx">
---
title: "Zendesk - Articles: Create Comments"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Articles: Create Comments Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:create_article_comments`

**Tool description:** Create a comment on a zendesk article.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskCreateArticleCommentsTool.",
  "properties": {
    "article_id": {
      "description": "The unique ID of the article",
      "title": "Article Id",
      "type": "integer"
    },
    "locale": {
      "description": "The locale of the article to post the comment on",
      "title": "Locale",
      "type": "string"
    },
    "comment": {
      "description": "The comment to post on the article",
      "title": "Comment",
      "type": "string"
    }
  },
  "required": [
    "article_id",
    "locale",
    "comment"
  ],
  "title": "ZendeskCreateArticleCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/create-ticket.mdx">
---
title: "Zendesk - Tickets: Create"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Create Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:create`

**Tool description:** Create a Zendesk Ticket. This populates the ticket with the provided subject and description. This should be followed up with calls to the ZendeskUpdateTicketTool to add or change details if needed. \{SHARED_TICKET_DESCRIPTION\}

**Args schema:**
```json
{
  "description": "Input schema for ZendeskCreateTicketTool.",
  "properties": {
    "subject": {
      "description": "The subject of the ticket",
      "title": "Subject",
      "type": "string"
    },
    "description": {
      "description": "The initial comment/description of the ticket.",
      "title": "Description",
      "type": "string"
    }
  },
  "required": [
    "subject",
    "description"
  ],
  "title": "ZendeskCreateTicketToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Returns the created ticket data from Zendesk API matching the input schema')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/index.mdx">
---
title: "Zendesk Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Zendesk Tools

<ItemList items={getItems("Zendesk")} />
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-article-comments.mdx">
---
title: "Zendesk - Articles: List Comments"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Articles: List Comments Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:list_article_comments`

**Tool description:** Returns up to 100 comments made by all users on a specific article.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListArticleCommentsTool.",
  "properties": {
    "article_id": {
      "description": "The unique ID of the article",
      "title": "Article Id",
      "type": "integer"
    }
  },
  "required": [
    "article_id"
  ],
  "title": "ZendeskListArticleCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-articles-by-section.mdx">
---
title: "Zendesk - Sections: List Articles"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Sections: List Articles Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:list_articles_by_section`

**Tool description:** Lists all articles in a given section of the Zendesk Help Center. Sections group related articles together.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListArticlesBySectionToolSchema.",
  "properties": {
    "section_id": {
      "description": "The unique ID of the section",
      "title": "Section Id",
      "type": "integer"
    }
  },
  "required": [
    "section_id"
  ],
  "title": "ZendeskListArticlesBySectionToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-articles.mdx">
---
title: "Zendesk - Articles: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Articles: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:list_articles`

**Tool description:** List up to 100 Zendesk articles. An article is a piece of content that is createdby Zendesk. Use this tool to get articles without a search query.

**Args schema:**
```json
{
  "properties": {},
  "title": "_ArgsSchemaPlaceholder",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-groups-for-user.mdx">
---
title: "Zendesk - Groups: List for User"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Groups: List for User Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:groups:list_groups_for_user`

**Tool description:** Returns a list of groups that a user (Agent or Admin) is a member of. Returns a maximum of 100 records.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListGroupsTool.",
  "properties": {
    "user_id": {
      "description": "The id of the user",
      "title": "User Id",
      "type": "integer"
    }
  },
  "required": [
    "user_id"
  ],
  "title": "ZendeskListGroupsForUserToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-post-comments.mdx">
---
title: "Zendesk - Posts: List Comments"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Posts: List Comments Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:list_post_comments`

**Tool description:** Lists all comments on a specific post.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListPostCommentsTool.",
  "properties": {
    "post_id": {
      "description": "The unique ID of the post",
      "title": "Post Id",
      "type": "integer"
    }
  },
  "required": [
    "post_id"
  ],
  "title": "ZendeskListPostCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-request-comments.mdx">
---
title: "Zendesk - Request Comments: List"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Request Comments: List Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:requests:list_comments`

**Tool description:** Lists comments on a Zendesk request. Returns a maximum of 100 comments. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListRequestCommentsTool.",
  "properties": {
    "request_id": {
      "description": "The ID of the request",
      "title": "Request Id",
      "type": "integer"
    },
    "since": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Filters the comments from the given datetime. The datetime must be in ISO 8601 format. Example: 2019-01-01T00:00:00Z",
      "title": "Since"
    }
  },
  "required": [
    "request_id"
  ],
  "title": "ZendeskListRequestCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-ticket-comments.mdx">
---
title: "Zendesk - Tickets: List Comments"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: List Comments Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:list_comments`

**Tool description:** Returns the comments added to the ticket.  Each comment may include a `content_url` for an attachment or a `recording_url` for a voice comment that points to a file that may be hosted externally. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListTicketCommentsTool.",
  "properties": {
    "ticket_id": {
      "description": "The ID of the ticket",
      "title": "Ticket Id",
      "type": "integer"
    }
  },
  "required": [
    "ticket_id"
  ],
  "title": "ZendeskListTicketCommentsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API containing a list of comments on a Zendesk ticket.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/list-users-for-group.mdx">
---
title: "Zendesk - Groups: List Users"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Groups: List Users Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:groups:list_users_for_group`

**Tool description:** Returns a list of memberships for a group. Memberships include the user ID and metadata about their membership in the group. Returns a maximum of 100 records.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskListUsersForGroupTool.",
  "properties": {
    "group_id": {
      "description": "The id of the group",
      "title": "Group Id",
      "type": "integer"
    }
  },
  "required": [
    "group_id"
  ],
  "title": "ZendeskListUsersForGroupToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/search-groups.mdx">
---
title: "Zendesk - Groups: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Groups: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:groups:search`

**Tool description:** Search for groups in Zendesk. It can be a natural language query or use the syntax of the Zendesk API.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskSearchGroupsTool.",
  "properties": {
    "query": {
      "description": "The query to search for to find groups. It can be a natural language query term or use the syntax of the Zendesk API. Groups support the following keyword fields in Zendesk syntax: `name`, `created`. e.g. 'name:Support' or 'support'.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskSearchGroupsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/search-organizations.mdx">
---
title: "Zendesk - Organizations: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Organizations: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:organizations:search`

**Tool description:** Retrieves a list of organizations in Zendesk matching the query.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskSearchOrganizationsTool.",
  "properties": {
    "query": {
      "description": "The query to search for to find organizations. It can be a natural language query or use the syntax of the Zendesk API. Organizations support the following keyword fields in Zendesk syntax: `name`, `created`, `notes`, `details`, and `tags`. e.g. 'name:Acme' or 'health'.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskSearchOrganizationsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', "application/json: Payload from API containing a list of organizations in Zendesk matching the provided query. This includes (but is not limited to) the organization's name, details, and domain.")
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/search-requests.mdx">
---
title: "Zendesk - Requests: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Requests: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:requests:search`

**Tool description:** Search for requests in Zendesk. Returns a maximum of 100 requests. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskSearchRequestsTool.",
  "properties": {
    "query": {
      "description": "The syntax and matching logic for the string is detailed in the Zendesk Support search reference.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskSearchRequestsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/search-tickets.mdx">
---
title: "Zendesk - Tickets: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:search`

**Tool description:** Searches for tickets in Zendesk based on a natural language query or the Zendesk API syntax. Returns up to 1000 tickets that match the query.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskSearchTicketsTool.",
  "properties": {
    "query": {
      "description": "The query to search for. It can be a natural language query or use the syntax of the Zendesk API.",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskSearchTicketsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API for searching Zendesk tickets. This includes most core ticket information like ID, subject, description, status, priority, and type. It excludes comments.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/search-users.mdx">
---
title: "Zendesk - Users: Search"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Users: Search Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:users:search`

**Tool description:** Returns an array of users who meet the search criteria. Returns a maximum of 100 users. This may include (but is not limited to) the user's name, contact information, role, permissions, locale, organization, and other information.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskSearchUsersTool.",
  "properties": {
    "query": {
      "description": "The Zendesk domain syntax language for searching users. Supported property key words are name, email, role, organization, and phone. Multiple properties can be used in the same query. Any search terms containing spaces must be enclosed in double quotes. Examples: - name:\"John Smith\"\n-email:john.smith@thecompany.com\n-role:admin organization:The Company",
      "title": "Query",
      "type": "string"
    }
  },
  "required": [
    "query"
  ],
  "title": "ZendeskSearchUsersToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API containing a list of users in Zendesk matching the provided query.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-article.mdx">
---
title: "Zendesk - Articles: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Articles: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:show_article`

**Tool description:** Shows the properties of a Zendesk article. An article is a piece of content that is created by Zendesk.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowArticleTool.",
  "properties": {
    "article_id": {
      "description": "The unique ID of the article",
      "title": "Article Id",
      "type": "integer"
    }
  },
  "required": [
    "article_id"
  ],
  "title": "ZendeskShowArticleToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-group.mdx">
---
title: "Zendesk - Groups: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Groups: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:groups:show`

**Tool description:** Returns a group.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowGroupTool.",
  "properties": {
    "group_id": {
      "description": "The id of the group",
      "title": "Group Id",
      "type": "integer"
    }
  },
  "required": [
    "group_id"
  ],
  "title": "ZendeskShowGroupToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-organization.mdx">
---
title: "Zendesk - Organizations: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Organizations: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:organizations:show`

**Tool description:** Gets information about a specific organization in Zendesk.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowOrganizationTool.",
  "properties": {
    "organization_id": {
      "description": "The ID of an organization",
      "title": "Organization Id",
      "type": "integer"
    }
  },
  "required": [
    "organization_id"
  ],
  "title": "ZendeskShowOrganizationToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', "application/json: Payload from API containing information about a specific organization in Zendesk. This includes (but is not limited to) the organization's name, details, and domain.")
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-post.mdx">
---
title: "Zendesk - Posts: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Posts: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:show_post`

**Tool description:** Gets information about a given post. A post is community content that is created by a user and is not the same as an article.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowPostTool.",
  "properties": {
    "post_id": {
      "description": "The unique ID of the post",
      "title": "Post Id",
      "type": "integer"
    }
  },
  "required": [
    "post_id"
  ],
  "title": "ZendeskShowPostToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-request-comment.mdx">
---
title: "Zendesk - Request Comments: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Request Comments: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:requests:show_comment`

**Tool description:** Retrieves information about a specific comment on a request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowRequestCommentTool.",
  "properties": {
    "request_id": {
      "description": "The ID of the request",
      "title": "Request Id",
      "type": "integer"
    },
    "ticket_comment_id": {
      "description": "The ID of the ticket comment",
      "title": "Ticket Comment Id",
      "type": "integer"
    }
  },
  "required": [
    "request_id",
    "ticket_comment_id"
  ],
  "title": "ZendeskShowRequestCommentToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-request.mdx">
---
title: "Zendesk - Requests: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Requests: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:requests:show`

**Tool description:** Retrieves information about a specific request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowRequestTool.",
  "properties": {
    "request_id": {
      "description": "The ID of the request",
      "title": "Request Id",
      "type": "integer"
    }
  },
  "required": [
    "request_id"
  ],
  "title": "ZendeskShowRequestToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-section.mdx">
---
title: "Zendesk - Sections: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Sections: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:help_center:show_section`

**Tool description:** Returns a section of the Zendesk Help Center articles. Sections group related articles together.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowSectionTool.",
  "properties": {
    "section_id": {
      "description": "The unique ID of the section",
      "title": "Section Id",
      "type": "integer"
    }
  },
  "required": [
    "section_id"
  ],
  "title": "ZendeskShowSectionToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload from API')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-ticket-metrics.mdx">
---
title: "Zendesk - Tickets: Show Metrics"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Show Metrics Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:show_metrics`

**Tool description:** Returns metrics for a specific ticket, including first response time, full resolution time, number of reopens, and other performance metrics. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowTicketMetricsTool.",
  "properties": {
    "ticket_id": {
      "description": "The ID of the ticket to retrieve metrics for",
      "title": "Ticket Id",
      "type": "string"
    }
  },
  "required": [
    "ticket_id"
  ],
  "title": "ZendeskShowTicketMetricsToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Payload containing ticket metrics including resolution times, reply times, number of reopens, and other performance data.')
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-ticket.mdx">
---
title: "Zendesk - Tickets: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:show`

**Tool description:** Returns a number of ticket properties though not the ticket comments. To get the comments, use the ZendeskListTicketCommentsTool. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowTicketTool.",
  "properties": {
    "ticket_id": {
      "description": "The ID of the ticket",
      "title": "Ticket Id",
      "type": "integer"
    }
  },
  "required": [
    "ticket_id"
  ],
  "title": "ZendeskShowTicketToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', "application/json: Payload from API about a single Zendesk ticket. This includes (but is not limited to) the ticket's subject, description, requester, and status.")
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/show-user.mdx">
---
title: "Zendesk - Users: Show"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Users: Show Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:users:show`

**Tool description:** Returns information about a specific user in Zendesk.

**Args schema:**
```json
{
  "description": "Input schema for ZendeskShowUserTool.",
  "properties": {
    "user_id": {
      "description": "The ID of the user",
      "title": "User Id",
      "type": "integer"
    }
  },
  "required": [
    "user_id"
  ],
  "title": "ZendeskShowUserToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', "application/json: Payload from API containing information about a specific user in Zendesk. A user can be an end-user, agent, or admin. This may include (but is not limited to) the user's name, contact information, role, locale, organization, and other information.")
```
</file>

<file path="docs/portia-tools/portia-cloud/zendesk/update-ticket.mdx">
---
title: "Zendesk - Tickets: Update"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-zendesk.mdx';

# Tickets: Update Tool

<Intro />

## Tool details
**Tool ID:** `portia:zendesk:tickets:update`

**Tool description:** Updates an existing ticket in Zendesk with the provided details. For fields requiring group and user ID fields, use the ZendeskSearchGroupsTool and ZendeskSearchUsersTool to get the IDs. This tool can be run once with multiple details updated on the ticket or multiple times with a single detail updated on the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. 

**Args schema:**
```json
{
  "$defs": {
    "TicketPriority": {
      "description": "Ticket priority.",
      "enum": [
        "urgent",
        "high",
        "normal",
        "low"
      ],
      "title": "TicketPriority",
      "type": "string"
    },
    "TicketStatus": {
      "description": "Ticket status.",
      "enum": [
        "new",
        "open",
        "pending",
        "hold",
        "solved",
        "closed"
      ],
      "title": "TicketStatus",
      "type": "string"
    },
    "TicketType": {
      "description": "Ticket type.",
      "enum": [
        "problem",
        "incident",
        "question",
        "task"
      ],
      "title": "TicketType",
      "type": "string"
    }
  },
  "description": "Input schema for ZendeskUpdateTicketTool.",
  "properties": {
    "ticket_id": {
      "description": "The ID of the ticket to update",
      "title": "Ticket Id",
      "type": "integer"
    },
    "subject": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The subject of the ticket",
      "title": "Subject"
    },
    "comment": {
      "anyOf": [
        {
          "additionalProperties": true,
          "type": "object"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Optional comment to add. Format is a JSON dictionary with keys 'body' and 'public' - e.g. {'body': 'comment text', 'public': true/false}",
      "title": "Comment"
    },
    "priority": {
      "anyOf": [
        {
          "$ref": "#/$defs/TicketPriority"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The ticket priority. Can be 'urgent', 'high', 'normal', or 'low'"
    },
    "status": {
      "anyOf": [
        {
          "$ref": "#/$defs/TicketStatus"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The state of the ticket. Can be 'new', 'open', 'pending', 'hold', 'solved', or 'closed'"
    },
    "type": {
      "anyOf": [
        {
          "$ref": "#/$defs/TicketType"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The type of the ticket. Can be 'problem', 'incident', 'question', or 'task'"
    },
    "assignee_id": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The ID of the agent to assign the ticket to",
      "title": "Assignee Id"
    },
    "group_id": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The ID of the group to assign the ticket to",
      "title": "Group Id"
    },
    "collaborator_ids": {
      "anyOf": [
        {
          "items": {
            "type": "integer"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Array of user IDs to CC on the ticket",
      "title": "Collaborator Ids"
    }
  },
  "required": [
    "ticket_id"
  ],
  "title": "ZendeskUpdateTicketToolSchema",
  "type": "object"
}
```

**Output schema:**
```
('application/json', 'application/json: Returns the updated ticket data from Zendesk API. This includes information from the schema and other immutable ticket data')
```
</file>

<file path="docs/portia-tools/portia-cloud/index.mdx">
---
title: "Portia Cloud Tools"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Portia Cloud Tools

<ItemList items={getItems("Portia Cloud")} />
</file>

<file path="docs/portia-tools/remote-mcp/apify.mdx">
---
title: "Apify Actors"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Apify Actors

### Description

Use 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more.

### Authorisation

To use this MCP server, you need API credentials in your environment.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to provide your API key when you enable the server.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/asana.mdx">
---
title: "Asana"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Asana

### Description

Opens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface..

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/cloudflare.mdx">
---
title: "Cloudflare"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Cloudflare

### Description

Manage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/deepwiki.mdx">
---
title: "DeepWiki"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# DeepWiki

### Description

Provides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering.

### Authorisation

To use this MCP server, you need API credentials in your environment.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to provide your API key when you enable the server.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/firecrawl.mdx">
---
title: "Firecrawl"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Firecrawl

### Description

Integration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/hugging-face.mdx">
---
title: "Hugging Face"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Hugging Face

### Description

Integrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/index.mdx">
---
title: "Remote MCP Servers"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_tool-intro-remote-mcp.mdx';
import { getItems } from '@site/src/lib/tools'
import { ItemList } from '@site/src/components/ItemList'


# Remote MCP Servers

<Intro />

<ItemList items={getItems("Remote MCP")} />
</file>

<file path="docs/portia-tools/remote-mcp/intercom.mdx">
---
title: "Intercom"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Intercom

### Description

Enables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/invideo.mdx">
---
title: "Invideo"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Invideo

### Description

Lets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/linear.mdx">
---
title: "Linear"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Linear

### Description

Access your Linear data to manage your projects and issues in a simple and secure way.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/make.mdx">
---
title: "Make"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Make

### Description

Connects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/posthog.mdx">
---
title: "Posthog"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Posthog

### Description

Integrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions.

### Authorisation

To use this MCP server, you need API credentials in your environment.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to provide your API key when you enable the server.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/semgrep.mdx">
---
title: "Semgrep"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Semgrep

### Description

Integrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/sentry.mdx">
---
title: "Sentry"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Sentry

### Description

Exposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/shopify.mdx">
---
title: "Shopify"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Shopify

### Description

Integrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/square.mdx">
---
title: "Square"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Square

### Description

Provides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/stripe.mdx">
---
title: "Stripe"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Stripe

### Description

Integrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows.

### Authorisation

To use this MCP server, you need API credentials in your environment.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to provide your API key when you enable the server.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/supermemory.mdx">
---
title: "Supermemory"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Supermemory

### Description

Personal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting.

### Authorisation

This server does not require any extra authentication to use, other than the MCP server URL.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry).

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/webflow.mdx">
---
title: "Webflow"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Webflow

### Description

Integration with the Webflow Data API.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/wix.mdx">
---
title: "Wix"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# Wix

### Description

Enables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands.

### Authorisation

This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail [here (↗)](/run-portia-tools).

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to authorise with the server via OAuth when you enable it.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/remote-mcp/yepcode.mdx">
---
title: "YepCode"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->


# YepCode

### Description

Enables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants.

### Authorisation

To use this MCP server, you need API credentials in your environment.

### Usage

Remote MCP servers are available in the Portia cloud dashboard.

After you have [created your Portia account (↗)](/setup-account), you can enable the server via the [Portia cloud tool registry (↗)](/cloud-tool-registry). You will be requested to provide your API key when you enable the server.

Once enabled, set your Portia API key in your environment and the tools will be available to use in the `DefaultToolRegistry`.

Listing the tools with the CLI:
```bash
$ PORTIA_API_KEY=<your-api-key> portia-cli list-tools
```

Using the `DefaultToolRegistry` in your code:
```python
from portia import DefaultToolRegistry, Portia, Config

config = Config.from_default()
portia = Portia(config=config, tools=DefaultToolRegistry(config))
```
</file>

<file path="docs/portia-tools/index.mdx">
---
title: "Portia Tool Catalogue"
---
<!-- WARNING: This file is auto-generated by generate_tool_docs.py. Do not edit manually. -->

import Intro from '@site/docs/_lib/_root-intro.mdx';
import { getTools } from '@site/src/lib/tools'
import { ToolRoot } from '@site/src/components/ToolRoot'


# Portia Tool Catalogue

<Intro />

<ToolRoot />
</file>

<file path="docs/portia-tools/sidebar.json">
{
  "label": "Portia Tool Catalogue",
  "type": "category",
  "link": {
    "type": "doc",
    "id": "portia-tools/index"
  },
  "items": [
    {
      "type": "category",
      "label": "Open Source",
      "link": {
        "type": "doc",
        "id": "portia-tools/open-source/index"
      },
      "collapsed": true,
      "customProps": {
        "type": "category",
        "description": null
      },
      "items": [
        {
          "type": "doc",
          "label": "Browser Use",
          "id": "portia-tools/open-source/browser",
          "customProps": {
            "type": "tool",
            "description": "General purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain.",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": []
          }
        },
        {
          "type": "doc",
          "label": "Crawl",
          "id": "portia-tools/open-source/crawl",
          "customProps": {
            "type": "tool",
            "description": "Crawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration.",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "tavily",
              "website",
              "scrape"
            ]
          }
        },
        {
          "type": "doc",
          "label": "Extract",
          "id": "portia-tools/open-source/extract",
          "customProps": {
            "type": "tool",
            "description": "Extracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "tavily",
              "website",
              "scrape"
            ]
          }
        },
        {
          "type": "doc",
          "label": "File Reader",
          "id": "portia-tools/open-source/file-reader",
          "customProps": {
            "type": "tool",
            "description": "Finds and reads content from a local file on Disk",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": []
          }
        },
        {
          "type": "doc",
          "label": "File Writer",
          "id": "portia-tools/open-source/file-writer",
          "customProps": {
            "type": "tool",
            "description": "Writes content to a file locally",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": []
          }
        },
        {
          "type": "doc",
          "label": "Image Understanding",
          "id": "portia-tools/open-source/image-understanding",
          "customProps": {
            "type": "tool",
            "description": "Tool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights.",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": []
          }
        },
        {
          "type": "doc",
          "label": "LLM",
          "id": "portia-tools/open-source/llm",
          "customProps": {
            "type": "tool",
            "description": "Jack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user.",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": []
          }
        },
        {
          "type": "doc",
          "label": "Map Website",
          "id": "portia-tools/open-source/map-website",
          "customProps": {
            "type": "tool",
            "description": "Maps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery.",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "tavily",
              "website"
            ]
          }
        },
        {
          "type": "doc",
          "label": "PDF Reader",
          "id": "portia-tools/open-source/pdf-reader",
          "customProps": {
            "type": "tool",
            "description": "Read a PDF file and extract its text content using Mistral OCR",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "mistral",
              "ocr",
              "document"
            ]
          }
        },
        {
          "type": "doc",
          "label": "Search",
          "id": "portia-tools/open-source/search",
          "customProps": {
            "type": "tool",
            "description": "Searches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "tavily",
              "website",
              "research"
            ]
          }
        },
        {
          "type": "doc",
          "label": "Weather",
          "id": "portia-tools/open-source/weather",
          "customProps": {
            "type": "tool",
            "description": "Get the weather for a given city",
            "category": "opensource",
            "categoryLabel": "Open Source",
            "vendor": "opensource",
            "vendorLabel": "Open Source",
            "searchKeywords": [
              "temperature"
            ]
          }
        }
      ]
    },
    {
      "type": "category",
      "label": "Portia Cloud",
      "link": {
        "type": "doc",
        "id": "portia-tools/portia-cloud/index"
      },
      "collapsed": false,
      "customProps": {
        "type": "category",
        "description": null
      },
      "items": [
        {
          "type": "category",
          "label": "GitHub",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/github/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Find and interact with GitHub repositories."
          },
          "items": [
            {
              "type": "doc",
              "label": "Issue: List",
              "id": "portia-tools/portia-cloud/github/list-repo-issues",
              "customProps": {
                "type": "tool",
                "description": "List issues in a GitHub repository.",
                "category": "github",
                "categoryLabel": "GitHub",
                "vendor": "github",
                "vendorLabel": "GitHub",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Repository: List",
              "id": "portia-tools/portia-cloud/github/list-repos",
              "customProps": {
                "type": "tool",
                "description": "Lists all public repositories for a GitHub organization.",
                "category": "github",
                "categoryLabel": "GitHub",
                "vendor": "github",
                "vendorLabel": "GitHub",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Repository: Search",
              "id": "portia-tools/portia-cloud/github/search-repos",
              "customProps": {
                "type": "tool",
                "description": "Searches all public repositories for a specific term.",
                "category": "github",
                "categoryLabel": "GitHub",
                "vendor": "github",
                "vendorLabel": "GitHub",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Repository: Star",
              "id": "portia-tools/portia-cloud/github/star-repo",
              "customProps": {
                "type": "tool",
                "description": "Stars a GitHub repository.",
                "category": "github",
                "categoryLabel": "GitHub",
                "vendor": "github",
                "vendorLabel": "GitHub",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Google Calendar",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/google-calendar/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Create and modify events in Google Calendar."
          },
          "items": [
            {
              "type": "doc",
              "label": "Calendar: Check Availability",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-check-availability",
              "customProps": {
                "type": "tool",
                "description": "Checks the availability of this authenticated user for a given time range. DO NOT use this to validate availability of people the user wants to meet with. DO NOT use this unless the user specifically asks for availability checking, e.g by saying 'find when I am free', or 'check my availability'. Either the day, end_time, or start_time must be provided. Pay close attention to the task if it says 'before' or 'after'.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Calendar: Create Event",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-create-event",
              "customProps": {
                "type": "tool",
                "description": "Creates a Google Calendar event. DO NOT call portia:google:gcalendar:check_availability before using this tool, unless the user explicitly asks you to check their availability.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Calendar: Delete Event",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-delete-event",
              "customProps": {
                "type": "tool",
                "description": "Deletes the Google Calendar event associated with the ID.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Calendar: Get Event",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-get-event-details",
              "customProps": {
                "type": "tool",
                "description": "Gets Google Calendar event using an event ID.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Calendar: Get Events By Properties",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-get-events-by-properties",
              "customProps": {
                "type": "tool",
                "description": "Gets Google Calendar events by properties, returning the matching event details. You do not need to provide all the properties, only the ones you have provided with.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Calendar: Modify Event",
              "id": "portia-tools/portia-cloud/google-calendar/calendar-modify-event",
              "customProps": {
                "type": "tool",
                "description": "Modifies an existing Google Calendar event. You must provide the event ID to modify, and can optionally provide new values if desired for the title, start time, end time, description, and attendees.",
                "category": "google-calendar",
                "categoryLabel": "Google Calendar",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Google Docs",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/google-docs/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Fetch documents from Google Docs."
          },
          "items": [
            {
              "type": "doc",
              "label": "Docs: Get Document",
              "id": "portia-tools/portia-cloud/google-docs/docs-get-document",
              "customProps": {
                "type": "tool",
                "description": "Get a document from Google Docs in plain text format by ID. The GoogleDriveSearchTool should be used to search for a document by name if an ID is not known.",
                "category": "google-docs",
                "categoryLabel": "Google Docs",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Docs: Get Structured Document",
              "id": "portia-tools/portia-cloud/google-docs/docs-get-structured-document",
              "customProps": {
                "type": "tool",
                "description": "Get a document from Google Docs in a machine readable format. Do not use unless you reallyneed a structured document.",
                "category": "google-docs",
                "categoryLabel": "Google Docs",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Google Drive",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/google-drive/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Search for files in Google Drive."
          },
          "items": [
            {
              "type": "doc",
              "label": "Drive: Search",
              "id": "portia-tools/portia-cloud/google-drive/drive-search",
              "customProps": {
                "type": "tool",
                "description": "Search for files and folders in Google Drive. Google Drive stores proprietary files like Google Docs, Sheets, and Slides. It also stores regular files like PDFs, images, and videos or even files from other apps like Microsoft docx, xlsx, pptx, etc. Use this tool to search for files using a search query.  This tool should be used to resolve name / file descriptions into concrete file IDs for other Google tools to use when needed.",
                "category": "google-drive",
                "categoryLabel": "Google Drive",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Google Gmail",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/google-gmail/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Send and find emails via Google Gmail."
          },
          "items": [
            {
              "type": "doc",
              "label": "Gmail: Draft",
              "id": "portia-tools/portia-cloud/google-gmail/gmail-draft-email",
              "customProps": {
                "type": "tool",
                "description": "Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the portia:google:gmail:send_draft_email. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.",
                "category": "google-workspace",
                "categoryLabel": "Google Gmail",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Gmail: Search",
              "id": "portia-tools/portia-cloud/google-gmail/gmail-search-email",
              "customProps": {
                "type": "tool",
                "description": "Searches for emails and drafts in the user's inbox and returns emails content that match the query.",
                "category": "google-workspace",
                "categoryLabel": "Google Gmail",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Gmail: Send",
              "id": "portia-tools/portia-cloud/google-gmail/gmail-send-email",
              "customProps": {
                "type": "tool",
                "description": "Sends an email to the recipients indicated. Should not be used with the draft email tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.",
                "category": "google-workspace",
                "categoryLabel": "Google Gmail",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Gmail: Send Draft",
              "id": "portia-tools/portia-cloud/google-gmail/gmail-send-draft-email",
              "customProps": {
                "type": "tool",
                "description": "Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
                "category": "google-workspace",
                "categoryLabel": "Google Gmail",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Google Sheets",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/google-sheets/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Fetch spreadsheets from Google Sheets."
          },
          "items": [
            {
              "type": "doc",
              "label": "Sheets: Get Spreadsheet",
              "id": "portia-tools/portia-cloud/google-sheets/sheets-get-spreadsheet",
              "customProps": {
                "type": "tool",
                "description": "Gets the content of a spreadsheet from Google Sheets by ID. The GoogleDriveSearchTool should be used to search for a spreadsheet by name if an ID is not known.",
                "category": "google-sheets",
                "categoryLabel": "Google Sheets",
                "vendor": "google",
                "vendorLabel": "Google",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Microsoft Outlook",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/microsoft-outlook/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Send and find emails via Microsoft Outlook."
          },
          "items": [
            {
              "type": "doc",
              "label": "Outlook: Draft",
              "id": "portia-tools/portia-cloud/microsoft-outlook/outlook-draft-email",
              "customProps": {
                "type": "tool",
                "description": "Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.",
                "category": "microsoft",
                "categoryLabel": "Microsoft Outlook",
                "vendor": "microsoft",
                "vendorLabel": "Micrososft",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Outlook: Search",
              "id": "portia-tools/portia-cloud/microsoft-outlook/outlook-search-email",
              "customProps": {
                "type": "tool",
                "description": "Searches for emails in the user's Outlook inbox and returns emails content that match the query.",
                "category": "microsoft",
                "categoryLabel": "Microsoft Outlook",
                "vendor": "microsoft",
                "vendorLabel": "Microsoft",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Outlook: Send",
              "id": "portia-tools/portia-cloud/microsoft-outlook/outlook-send-email",
              "customProps": {
                "type": "tool",
                "description": "Sends an email to the recipients indicated. Should not be used with the draft email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email.",
                "category": "microsoft",
                "categoryLabel": "Microsoft Outlook",
                "vendor": "microsoft",
                "vendorLabel": "Microsoft",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Outlook: Send Draft",
              "id": "portia-tools/portia-cloud/microsoft-outlook/outlook-send-draft-email",
              "customProps": {
                "type": "tool",
                "description": "Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
                "category": "microsoft",
                "categoryLabel": "Microsoft Outlook",
                "vendor": "microsoft",
                "vendorLabel": "Microsoft",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Slack",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/slack/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Send messages and search channels and chats in a Slack workspace."
          },
          "items": [
            {
              "type": "doc",
              "label": "Conversation: Get History",
              "id": "portia-tools/portia-cloud/slack/get-conversation",
              "customProps": {
                "type": "tool",
                "description": "Get the conversation history for a given channel by channel id. Requires an ID typically from the list_conversation_ids tool.",
                "category": "slack",
                "categoryLabel": "Slack",
                "vendor": "slack",
                "vendorLabel": "Slack",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Conversation: List",
              "id": "portia-tools/portia-cloud/slack/list-conversations",
              "customProps": {
                "type": "tool",
                "description": "List all conversations meta information only without comments in the slack workspaceThis tool should be used when you need to make api calls to other slack apis that requirea conversation or channel id. DOES NOT RETURN MESSAGES, CONVERSATION HISTORY, OR USER IDS.",
                "category": "slack",
                "categoryLabel": "Slack",
                "vendor": "slack",
                "vendorLabel": "Slack",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Message: Find",
              "id": "portia-tools/portia-cloud/slack/find-message",
              "customProps": {
                "type": "tool",
                "description": "Search for a message in a Slack channel or chat.",
                "category": "slack",
                "categoryLabel": "Slack",
                "vendor": "slack",
                "vendorLabel": "Slack",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Message: Send",
              "id": "portia-tools/portia-cloud/slack/send-message",
              "customProps": {
                "type": "tool",
                "description": "Send a message to a specific Slack channel or user by ID. Requires an ID provided by other tools.",
                "category": "slack",
                "categoryLabel": "Slack",
                "vendor": "slack",
                "vendorLabel": "Slack",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Users: List",
              "id": "portia-tools/portia-cloud/slack/list-users",
              "customProps": {
                "type": "tool",
                "description": "List all users in the slack workspace. Returns user meta information: Name, ID, and EmailThis tool should be used when you need to make api calls to other slack apis that requirea user ID.",
                "category": "slack",
                "categoryLabel": "Slack",
                "vendor": "slack",
                "vendorLabel": "Slack",
                "searchKeywords": []
              }
            }
          ]
        },
        {
          "type": "category",
          "label": "Zendesk",
          "link": {
            "type": "doc",
            "id": "portia-tools/portia-cloud/zendesk/index"
          },
          "collapsed": true,
          "customProps": {
            "type": "category",
            "description": "Interact with Zendesk support tickets, articles, and more."
          },
          "items": [
            {
              "type": "doc",
              "label": "Articles: Create Comments",
              "id": "portia-tools/portia-cloud/zendesk/create-article-comments",
              "customProps": {
                "type": "tool",
                "description": "Create a comment on a zendesk article.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Articles: List",
              "id": "portia-tools/portia-cloud/zendesk/list-articles",
              "customProps": {
                "type": "tool",
                "description": "List up to 100 Zendesk articles. An article is a piece of content that is createdby Zendesk. Use this tool to get articles without a search query.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Articles: List Comments",
              "id": "portia-tools/portia-cloud/zendesk/list-article-comments",
              "customProps": {
                "type": "tool",
                "description": "Returns up to 100 comments made by all users on a specific article.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Articles: Search",
              "id": "portia-tools/portia-cloud/zendesk/article-search",
              "customProps": {
                "type": "tool",
                "description": "Returns up to 25 articles relevant to the search query, which must be provided.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Articles: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-article",
              "customProps": {
                "type": "tool",
                "description": "Shows the properties of a Zendesk article. An article is a piece of content that is created by Zendesk.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Groups: List Users",
              "id": "portia-tools/portia-cloud/zendesk/list-users-for-group",
              "customProps": {
                "type": "tool",
                "description": "Returns a list of memberships for a group. Memberships include the user ID and metadata about their membership in the group. Returns a maximum of 100 records.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Groups: List for User",
              "id": "portia-tools/portia-cloud/zendesk/list-groups-for-user",
              "customProps": {
                "type": "tool",
                "description": "Returns a list of groups that a user (Agent or Admin) is a member of. Returns a maximum of 100 records.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Groups: Search",
              "id": "portia-tools/portia-cloud/zendesk/search-groups",
              "customProps": {
                "type": "tool",
                "description": "Search for groups in Zendesk. It can be a natural language query or use the syntax of the Zendesk API.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Groups: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-group",
              "customProps": {
                "type": "tool",
                "description": "Returns a group.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Organizations: Search",
              "id": "portia-tools/portia-cloud/zendesk/search-organizations",
              "customProps": {
                "type": "tool",
                "description": "Retrieves a list of organizations in Zendesk matching the query.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Organizations: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-organization",
              "customProps": {
                "type": "tool",
                "description": "Gets information about a specific organization in Zendesk.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Posts: List Comments",
              "id": "portia-tools/portia-cloud/zendesk/list-post-comments",
              "customProps": {
                "type": "tool",
                "description": "Lists all comments on a specific post.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Posts: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-post",
              "customProps": {
                "type": "tool",
                "description": "Gets information about a given post. A post is community content that is created by a user and is not the same as an article.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Request Comments: List",
              "id": "portia-tools/portia-cloud/zendesk/list-request-comments",
              "customProps": {
                "type": "tool",
                "description": "Lists comments on a Zendesk request. Returns a maximum of 100 comments. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Request Comments: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-request-comment",
              "customProps": {
                "type": "tool",
                "description": "Retrieves information about a specific comment on a request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Requests: Search",
              "id": "portia-tools/portia-cloud/zendesk/search-requests",
              "customProps": {
                "type": "tool",
                "description": "Search for requests in Zendesk. Returns a maximum of 100 requests. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Requests: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-request",
              "customProps": {
                "type": "tool",
                "description": "Retrieves information about a specific request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Sections: List Articles",
              "id": "portia-tools/portia-cloud/zendesk/list-articles-by-section",
              "customProps": {
                "type": "tool",
                "description": "Lists all articles in a given section of the Zendesk Help Center. Sections group related articles together.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Sections: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-section",
              "customProps": {
                "type": "tool",
                "description": "Returns a section of the Zendesk Help Center articles. Sections group related articles together.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Count",
              "id": "portia-tools/portia-cloud/zendesk/count-tickets",
              "customProps": {
                "type": "tool",
                "description": "Returns an approximate count of tickets in the account. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Count Comments",
              "id": "portia-tools/portia-cloud/zendesk/count-ticket-comments",
              "customProps": {
                "type": "tool",
                "description": "Returns an approximate count of the comments added to the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Create",
              "id": "portia-tools/portia-cloud/zendesk/create-ticket",
              "customProps": {
                "type": "tool",
                "description": "Create a Zendesk Ticket. This populates the ticket with the provided subject and description. This should be followed up with calls to the ZendeskUpdateTicketTool to add or change details if needed. {SHARED_TICKET_DESCRIPTION}",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: List Comments",
              "id": "portia-tools/portia-cloud/zendesk/list-ticket-comments",
              "customProps": {
                "type": "tool",
                "description": "Returns the comments added to the ticket.  Each comment may include a `content_url` for an attachment or a `recording_url` for a voice comment that points to a file that may be hosted externally. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Search",
              "id": "portia-tools/portia-cloud/zendesk/search-tickets",
              "customProps": {
                "type": "tool",
                "description": "Searches for tickets in Zendesk based on a natural language query or the Zendesk API syntax. Returns up to 1000 tickets that match the query.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-ticket",
              "customProps": {
                "type": "tool",
                "description": "Returns a number of ticket properties though not the ticket comments. To get the comments, use the ZendeskListTicketCommentsTool. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Show Metrics",
              "id": "portia-tools/portia-cloud/zendesk/show-ticket-metrics",
              "customProps": {
                "type": "tool",
                "description": "Returns metrics for a specific ticket, including first response time, full resolution time, number of reopens, and other performance metrics. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Tickets: Update",
              "id": "portia-tools/portia-cloud/zendesk/update-ticket",
              "customProps": {
                "type": "tool",
                "description": "Updates an existing ticket in Zendesk with the provided details. For fields requiring group and user ID fields, use the ZendeskSearchGroupsTool and ZendeskSearchUsersTool to get the IDs. This tool can be run once with multiple details updated on the ticket or multiple times with a single detail updated on the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. ",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Users: Search",
              "id": "portia-tools/portia-cloud/zendesk/search-users",
              "customProps": {
                "type": "tool",
                "description": "Returns an array of users who meet the search criteria. Returns a maximum of 100 users. This may include (but is not limited to) the user's name, contact information, role, permissions, locale, organization, and other information.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            },
            {
              "type": "doc",
              "label": "Users: Show",
              "id": "portia-tools/portia-cloud/zendesk/show-user",
              "customProps": {
                "type": "tool",
                "description": "Returns information about a specific user in Zendesk.",
                "category": "zendesk",
                "categoryLabel": "Zendesk",
                "vendor": "zendesk",
                "vendorLabel": "Zendesk",
                "searchKeywords": []
              }
            }
          ]
        }
      ]
    },
    {
      "type": "category",
      "label": "Remote MCP",
      "link": {
        "type": "doc",
        "id": "portia-tools/remote-mcp/index"
      },
      "collapsed": false,
      "customProps": {
        "type": "category",
        "description": null
      },
      "items": [
        {
          "type": "doc",
          "label": "Apify Actors",
          "id": "portia-tools/remote-mcp/apify",
          "customProps": {
            "type": "mcp-server",
            "description": "Use 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Asana",
          "id": "portia-tools/remote-mcp/asana",
          "customProps": {
            "type": "mcp-server",
            "description": "Opens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface..",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Cloudflare",
          "id": "portia-tools/remote-mcp/cloudflare",
          "customProps": {
            "type": "mcp-server",
            "description": "Manage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "DeepWiki",
          "id": "portia-tools/remote-mcp/deepwiki",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Firecrawl",
          "id": "portia-tools/remote-mcp/firecrawl",
          "customProps": {
            "type": "mcp-server",
            "description": "Integration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Hugging Face",
          "id": "portia-tools/remote-mcp/hugging-face",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Intercom",
          "id": "portia-tools/remote-mcp/intercom",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Invideo",
          "id": "portia-tools/remote-mcp/invideo",
          "customProps": {
            "type": "mcp-server",
            "description": "Lets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Linear",
          "id": "portia-tools/remote-mcp/linear",
          "customProps": {
            "type": "mcp-server",
            "description": "Access your Linear data to manage your projects and issues in a simple and secure way.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Make",
          "id": "portia-tools/remote-mcp/make",
          "customProps": {
            "type": "mcp-server",
            "description": "Connects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Posthog",
          "id": "portia-tools/remote-mcp/posthog",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Semgrep",
          "id": "portia-tools/remote-mcp/semgrep",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Sentry",
          "id": "portia-tools/remote-mcp/sentry",
          "customProps": {
            "type": "mcp-server",
            "description": "Exposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Shopify",
          "id": "portia-tools/remote-mcp/shopify",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Square",
          "id": "portia-tools/remote-mcp/square",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Stripe",
          "id": "portia-tools/remote-mcp/stripe",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Supermemory",
          "id": "portia-tools/remote-mcp/supermemory",
          "customProps": {
            "type": "mcp-server",
            "description": "Personal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Webflow",
          "id": "portia-tools/remote-mcp/webflow",
          "customProps": {
            "type": "mcp-server",
            "description": "Integration with the Webflow Data API.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "Wix",
          "id": "portia-tools/remote-mcp/wix",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands.",
            "categoryLabel": "Remote MCP"
          }
        },
        {
          "type": "doc",
          "label": "YepCode",
          "id": "portia-tools/remote-mcp/yepcode",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants.",
            "categoryLabel": "Remote MCP"
          }
        }
      ]
    },
    {
      "type": "category",
      "label": "Local MCP",
      "link": {
        "type": "doc",
        "id": "portia-tools/local-mcp/index"
      },
      "collapsed": false,
      "customProps": {
        "type": "category",
        "description": null
      },
      "items": [
        {
          "type": "doc",
          "label": "AWS Cost Analysis",
          "id": "portia-tools/local-mcp/aws-cost-analysis",
          "customProps": {
            "type": "mcp-server",
            "description": "Analyze AWS service costs and generate cost reports.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "AWS Documentation",
          "id": "portia-tools/local-mcp/aws-documentation",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides tools to access AWS documentation, search for content, and get recommendations.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Basic Memory",
          "id": "portia-tools/local-mcp/basic-memory",
          "customProps": {
            "type": "mcp-server",
            "description": "Knowledge management system that builds a persistent semantic graph in markdown, locally.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "BioMCP",
          "id": "portia-tools/local-mcp/biomcp",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Bright Data",
          "id": "portia-tools/local-mcp/bright-data",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Browserbase",
          "id": "portia-tools/local-mcp/browserbase",
          "customProps": {
            "type": "mcp-server",
            "description": "Automate web browsers remotely on a cloud environment.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Chargebee",
          "id": "portia-tools/local-mcp/chargebee",
          "customProps": {
            "type": "mcp-server",
            "description": "Integration with Chargebee products and API services to facilitate billing for subscription businesses.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Chroma",
          "id": "portia-tools/local-mcp/chroma",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "DBHub",
          "id": "portia-tools/local-mcp/dbhub",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "ElevenLabs",
          "id": "portia-tools/local-mcp/elevenlabs",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "GCP Cloud Run",
          "id": "portia-tools/local-mcp/gcp-cloud-run",
          "customProps": {
            "type": "mcp-server",
            "description": "Deploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "GitHub",
          "id": "portia-tools/local-mcp/github",
          "customProps": {
            "type": "mcp-server",
            "description": "Integration with GitHub Issues, Pull Requests, and more.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Grafana",
          "id": "portia-tools/local-mcp/grafana",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "HubSpot",
          "id": "portia-tools/local-mcp/hubspot",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Hyperbrowser",
          "id": "portia-tools/local-mcp/hyperbrowser",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "JetBrains IDE",
          "id": "portia-tools/local-mcp/jetbrains-ide",
          "customProps": {
            "type": "mcp-server",
            "description": "Interact with JetBrains IDEs for code analysis and development tasks.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "MiniMax",
          "id": "portia-tools/local-mcp/minimax",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Monday.com",
          "id": "portia-tools/local-mcp/monday.com",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "MongoDB",
          "id": "portia-tools/local-mcp/mongodb",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Netlify",
          "id": "portia-tools/local-mcp/netlify",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Notion",
          "id": "portia-tools/local-mcp/notion",
          "customProps": {
            "type": "mcp-server",
            "description": "Bridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Perplexity",
          "id": "portia-tools/local-mcp/perplexity",
          "customProps": {
            "type": "mcp-server",
            "description": "Connector for the Perplexity API, to enable web search without leaving the MCP ecosystem.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Playwright",
          "id": "portia-tools/local-mcp/playwright",
          "customProps": {
            "type": "mcp-server",
            "description": "Enables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Qdrant",
          "id": "portia-tools/local-mcp/qdrant",
          "customProps": {
            "type": "mcp-server",
            "description": "Store and retrieve vector-based memories for AI systems.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Shopify Dev",
          "id": "portia-tools/local-mcp/shopify-dev",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Shopify Dev. Supports various tools to interact with different Shopify APIs.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Supabase",
          "id": "portia-tools/local-mcp/supabase",
          "customProps": {
            "type": "mcp-server",
            "description": "Connects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Twilio",
          "id": "portia-tools/local-mcp/twilio",
          "customProps": {
            "type": "mcp-server",
            "description": "Integrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities.",
            "categoryLabel": "Local MCP"
          }
        },
        {
          "type": "doc",
          "label": "Xero",
          "id": "portia-tools/local-mcp/xero",
          "customProps": {
            "type": "mcp-server",
            "description": "Provides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management.",
            "categoryLabel": "Local MCP"
          }
        }
      ]
    }
  ]
}
</file>

<file path="docs/product/Evals and SteelThread/Evals/_category_.json">
{
  "label": "📈 Evals",
  "position": 4,
  "link": {
    "type": "generated-index",
    "slug": "evals",
    "description": "Evaluate agent performance against ground truth during agent development and in production."
  }
}
</file>

<file path="docs/product/Evals and SteelThread/Evals/Eval_results.md">
---
sidebar_position: 4
slug: /evals-results
---

# Visualise Eval results

Results from Evals are pushed to the Portia UI for visualization. This allows you to quickly see trends over time and to drill into why metrics may have changed. Clicking into a dataset will show you a summary of the current metrics for that dataset. Metrics are plotted by run.

![Eval Metrics](/img/eval_metrics.png)

You can expand each graph to get a detailed view of the metric. This also allows you to group the metric by any tags that were attached. 

![Eval Metric Group](/img/eval_metrics_group.png)

Clicking on a specific run will bring up the detailed summary of each test case from that run. 

![Eval Metric Table](/img/eval_metric_table.png)

Finally clicking on a specific test case will show you the details of each metric.

![Eval Iteration](/img/eval_iteration.png)
</file>

<file path="docs/product/Evals and SteelThread/Evals/Evals_custom_evaluators.md">
---
sidebar_position: 2
slug: /evals-custom-evaluators
---

# Custom evaluators

Evaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a multitude of built-in evaluators you can configure from the dashboard and then pass to your EvalRun via the `DefaultEvaluator` class. This explained in the previous section on [basic usage](/evals-overview).

You can add your own custom evaluators, be it LLM-as-Judge or deterministic ones. `Evaluator` implements a single methods.

```python
from portia import Plan, PlanRun
from steelthread.evals import EvalTestCase, EvalMetric, PlanRunMetadata

def eval_test_case(
    self,
    test_case: EvalTestCase,
    final_plan: Plan,
    final_plan_run: PlanRun,
    additional_data: PlanRunMetadata,
) -> list[EvalMetric] | EvalMetric | None:
```

We have seen how to implement a custom LLM-as-Judge as part of the default evaluators from the dashboard so let's focus on using custom assertions to implement a custom, deterministic evaluator. To do that you can attach an assertion to your test case from the dashboard, then use a custom evaluator to assess whether your Eval run complied with it:
* From the dashboard, navigate to your Eval set and then to the specific test case. Click on the edit icon on the right end of the row.
* Scroll to the bottom and under 'Add Evaluators' select `Run some custom logic based on tags`.
* Enter `word_count_limit` in the Key textbox and `50` in the Value textbox. This assertion is basically offering this key:value pair as the ground truth reference.
* Don't forget to scroll back up and hit that 'Save Changes' button (yeah we need to fix the UX so you don't need to scroll so much!).

<table style={{ border: 'none', borderCollapse: 'collapse' }}>
<tr>
    <td><img src="/img/custom_assertion_1.png"></img></td>
    <td><img src="/img/custom_assertion_2.png"></img></td>
</tr>
</table>

Next we will write a custom evaluator that detects whenever a test case includes an `expected_emojis` custom assertion so make sure you set that up for one or more test cases in your desired dataset. The custom evaluator loads the value of the custom assertion using the `get_custom_assertion` method and compares the plan run outputs to it. In this case we are counting the emojis in the final plan run output `final_plan_run.outputs.final_output.get_value()`, and comparing it to the `expected_emojis` number entered in the custom assertion via dashboard.

```python
from portia import Config, Portia, Plan, PlanRun
from steelthread.steelthread import SteelThread, EvalConfig
from steelthread.evals import EvalMetric, Evaluator, EvalTestCase, PlanRunMetadata
import re


# Custom evaluator implementation to count emojis
class EmojiEvaluator(Evaluator):
    def eval_test_case(
        self,
        test_case: EvalTestCase,
        final_plan: Plan,  
        final_plan_run: PlanRun,
        additional_data: PlanRunMetadata,  
    ) -> list[EvalMetric] | EvalMetric | None:
        # Load plan run output value
        string_to_score = (
            f"{final_plan_run.outputs.final_output.get_value()}"
            if final_plan_run.outputs.final_output
            else ""
        )
        # Count emojis in the loaded output
        emoji_pattern = re.compile(
            "[\U0001f600-\U0001f64f"  # emoticons
            "\U0001f300-\U0001f5ff"  # symbols & pictographs
            "\U0001f680-\U0001f6ff"  # transport & map symbols
            "\U0001f1e0-\U0001f1ff"  # flags
            "]+",
            flags=re.UNICODE,
        )
        emojis = emoji_pattern.findall(string_to_score)
        emoji_count = len(emojis)

        # Compare to the custom assertion
        expected = int(test_case.get_custom_assertion("expected_emojis") or 2)
        score = min(emoji_count / expected, 1.0)

        return EvalMetric.from_test_case(
            test_case=test_case,
            name="emoji_score",
            score=score,
            description="Returns a number lower than 1 if the final output is below max emoji count"
            explanation=f"Target: {expected}, Found: {emoji_count}",
        )

# Initialize Portia
config = Config.from_default()
portia = Portia(config=config)

# Initialize SteelThread with our custom evaluator to run on your dataset
st = SteelThread()
st.run_evals(
    portia,
    EvalConfig(
        eval_dataset_name="your-eval-dataset-name-here",
        config=config,
        iterations=5,
        evaluators=[EmojiEvaluator(config)],
    ),
)
```

You should now be able to see `emoji_score` as a new metric for your dataset in the dashboard.
</file>

<file path="docs/product/Evals and SteelThread/Evals/Evals_tool_stubbing.md">
---
sidebar_position: 3
slug: /evals-tool-stubbing
---

# Tool stubbing

When running evals, your agent may call tools like `weather_lookup`, `search`, or `send_email`. If those tools hit live systems, you'll get non-deterministic results — which can make evaluation noisy and inconsistent. There's also of course undesirable real-world effects (e.g. emails sent) and cost to these tool calls when you're simply trying to run evals!

To solve this, Steel Thread supports stubbing tools. This makes your tests:

- **Deterministic** — the same input always produces the same output
- **Isolated** — no external API calls or flaky systems
- **Repeatable** — easy to track regressions across changes

## When to stub

Use tool stubs when:

- You're writing **evals**
- The tool response **affects the plan or output**
- You want **consistent scoring** across iterations

## How Tool stubbing works

Steel Thread provides a `ToolStubRegistry` — a drop-in replacement for Portia’s default registry. You can wrap your existing tools and selectively override individual tools by ID. Tool stubs are simple Python functions and the `ToolStubContext` contains all the original tool's context to help you generate realistic stubs. Below is an example where we use use a tool stub for the open source `weather_tool` [available in the Portia SDK](https://docs.portialabs.ai/portia-tools/open-source/weather).


```python
from portia import Portia, Config, DefaultToolRegistry
from steelthread.steelthread import SteelThread, EvalConfig
from steelthread.portia.tools import ToolStubRegistry, ToolStubContext
from dotenv import load_dotenv

load_dotenv(override=True)


# Define stub behavior
def weather_stub_response(
    ctx: ToolStubContext,
) -> str:
    """Stub for weather tool to return deterministic weather."""
    city = ctx.kwargs.get("city", "").lower()
    if city == "sydney":
        return "33.28"
    if city == "london":
        return "2.00"

    return f"Unknown city: {city}"


config = Config.from_default()

# Run evals with stubs 
portia = Portia(
    config,
    tools=ToolStubRegistry(
        DefaultToolRegistry(config),
        stubs={
            "weather_tool": weather_stub_response,
        },
    ),
)

SteelThread().run_evals(
    portia,
    EvalConfig(
        eval_dataset_name="your-dataset-name-here",
        config=config,
        iterations=5
    ),
)
```

With the stubbed tool in place, your evals will be clean, fast, and reproducible. The rest of your tools still work as normal with only the stubbed one being overridden.


:::tip[Best Practices for tool stubbing]
* Stub only the tools that matter for evaluation
* Use consistent return types (e.g. same as real tool)
* Use `tool_call_index` if you want per-run variance
* Combine stubbing with assertions to detect misuse (e.g. tool called too many times)
:::

---
</file>

<file path="docs/product/Evals and SteelThread/Evals/Evals.md">
---
sidebar_position: 1
slug: /evals-overview
---

# Overview and basic usage

Evals are static, ground truth datasets designed to be run multiple times against your agents to assess their performance. These datasets are comprised of multiple test cases which are pairs of inputs (query or plan) and outputs (plan or plan run).

Running an Eval simply means putting the input of the test case through your agents, and comparing the output it yields with the test case output to make sure it's still behaving reliably. Any number of changes in the agents can cause a divergence from the expected output e.g. changes to your underlying system prompts, tool definitions, LLM choice etc.

:::info[Get your Portia API key]
Please make sure you have a `PORTIA_API_KEY` set up in your environment to use Steel Thread, as it relies on plans and plan runs stored in Portia cloud.
:::

## Basic usage

The overall flow is:
1. From the Portia dashboard, create a new eval dataset including at least one test case. You can add existing plans / plan runs directly from the dashboard to use as test cases so you don't need to create them from scratch. Note that the query and tools will be automatically populated as test case inputs, but you can still edit those.
2. You can rely on the default evaluators offered by Portia or create your own. Feel free to explore the available defautl evaluators in the dashboard. We will explain those in more detail below.
3. Run your Evals by passing the name of the Eval dataset to your Steel Thread instance along with your preferred evaluators.
4. Visualize the metrics from each run in the Portia UI.

Here is a step-by-step walkthrough with screenshots from the Portia UI. 
* Eval Test cases are designed to be generated from existing data making it easy to do. You can also create a new test case from blank though if you'd like to!
![Wizard One](/img/wizard_1.png)
* Step one of the process is about specifying the input to Portia. Either a query or an existing plan can be provided depending on your use case.
![Wizard Two](/img/wizard_2.png)
* Step two involves the assertions that we will make when the plan_run is complete. This allows you to use the built in evaluators or to use custom tags.
![Wizard Three](/img/wizard_3.png)
* Finally give the test case a description to make it easy to understand whats going on it in.
![Wizard Four](/img/wizard_4.png)

:::tip[A shortcut to adding existing plan runs]
You can add plan runs into an existing Eval dataset directly from the Plan Run view. When you're in the [Plan Runs tab in the dashboard](https://app.portialabs.ai/dashboard/plan-runs), click on the plan run you want to add to your Eval dataset, and look for the 'Add to Evals' button in the Plan Run view modal. This is perfect when you're iterating on an agent in development, so that you can immediately add your ideal plan run to your Evals once you manage to produce it.
:::

With the setup above completed you're now ready to run this basic example.
```python
from portia import Config, Portia
from steelthread.steelthread import SteelThread, EvalConfig


# Initialize Portia
config = Config.from_default()
portia = Portia(config=config)

# Initialize SteelThread with the dataset and evaluators set in the dashboard
st = SteelThread()
st.run_evals(
    portia,
    EvalConfig(
        eval_dataset_name="your-dataset-name-here",
        config=config,
        iterations=5,
    ),
)
```

## Default evaluators

Steel Thread comes with a decent helping of evaluators by default. The `EvalConfig` object above takes a list of evaluators (of type `Evaluator`) as an argument. SteelThread's `DefaultEvaluator` is available off the shelf and is used by default when no evaluators are specified. It picks up all the evaluators you set up in the dashboard, of which the available options currently include:
* **Final plan run state** -- this not only helps you test for a successful plan completion (State = `COMPLETE`), but it also helps you test for plans that should fail or trigger a clarification e.g. for auth.
* **Tool calls** -- you can confirm whether all the tools you expected to be called were indeed called (and include an exclusion set as well e.g. to track tool selection confusion).
* **Latency** -- how long a plan run took to complete.
* **LLM judge on plan run** -- feed the whole plan run with some guidance to an LLM as judge.
</file>

<file path="docs/product/Evals and SteelThread/Streams/_category_.json">
{
  "label": "🌊 Streams",
  "position": 3,
  "link": {
    "type": "generated-index",
    "slug": "streams",
    "description": "Monitor the real-time performance of your agents in production."
  }
}
</file>

<file path="docs/product/Evals and SteelThread/Streams/Stream_custom_evaluators.md">
---
sidebar_position: 2
slug: /streams-custom-evaluators
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Custom Stream evaluators

Evaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a built-in `LLMJudgeEvaluator` for stream based evaluation using LLM-as-Judge. This explained in the previous section on [basic usage](/streams-overview).

You can add your own custom Stream evaluators, be it LLM-as-Judge or deterministic ones. `StreamEvaluator` can implement two methods:

```python
from steelthread.streams import PlanStreamItem, PlanRunStreamItem, StreamMetric,
class MyStreamEvaluator(StreamEvaluator):
    def process_plan(self, stream_item: PlanStreamItem) -> list[StreamMetric] | StreamMetric:
        ...

    def process_plan_run(self, stream_item: PlanRunStreamItem) -> list[StreamMetric] | StreamMetric | None:
        ...
```

Below are two examples of custom evaluators, both using LLM-as-Judge or deterministic

<Tabs>
<TabItem value="llm_as_judge" label="LLM-as-judge">
You can use an LLM to score plan runs automatically. When you subclass `StreamEvaluator`, you first initialise your `LLMScorer` and then define how you want to process plans / plan runs with this evaluator.

```python
from portia import Config

from steelthread.steelthread import SteelThread

from steelthread.streams import (
    StreamConfig, 
    PlanRunStreamItem,
    StreamEvaluator,
    StreamMetric
)
from steelthread.utils.llm import LLMScorer, MetricOnly


class LLMVerbosityJudge(StreamEvaluator):
    def __init__(self, config):
        self.scorer = LLMScorer(config)

    def process_plan_run(self, stream_item: PlanRunStreamItem):
        # The stream_item object holds the underlying plan / plan run being evaluated.
        task_data = stream_item.plan_run.model_dump_json()
        # The description is used to inform the LLM on how to score the metric.
        metrics = self.scorer.score(
            task_data=[task_data],
            metrics_to_score=[
                MetricOnly(
                    name="verbosity", 
                    description="Scores 0 if the answer is too verbose. 0 otherwise."), 
            ],
        )

        return [
            StreamMetric.from_stream_item(
                stream_item=stream_item,
                score=m.score,
                name=m.name,
                description=m.description,
                explanation=m.explanation,
            )
            for m in metrics
        ]

# Setup config + Steel Thread
config = Config.from_default()

# To use your evaluator, pass it to the runner
SteelThread().process_stream(
    StreamConfig(
        eval_dataset_name="your-stream-name-here",
        config=config,
        evaluators=[LLMVerbosityJudge(config)],
    ),
)
```
</TabItem>
<TabItem value="deterministic" label="Deterministic">
You can score plan runs using your own code by subclassing `StreamEvaluator` and writing your own implementation of `process_plan` or `process_plan_run`.

```python
from portia import Config

from steelthread.steelthread import (
    SteelThread,
)
from steelthread.streams import (
    StreamConfig, 
    PlanRunStreamItem,
    StreamEvaluator,
    StreamMetric
)

from dotenv import load_dotenv
load_dotenv(override=True)

class JudgeDread(StreamEvaluator):
    def process_plan_run(self, stream_item: PlanRunStreamItem):
        # The stream_item object holds the underlying plan / plan run being evaluated.
        # In this example we're just returning a static score and explanation.
        return StreamMetric.from_stream_item(
            stream_item=stream_item,
            name="dread_score",
            score=1,
            description="Dreadful stuff",
            explanation="The dread was palpable",
        )

# Setup config + Steel Thread
config = Config.from_default()

# Process stream
SteelThread().process_stream(
    StreamConfig(
        stream_name="your-stream-name-here",
        config=config, 
        evaluators=[JudgeDread(config)])
)
```
</TabItem>
</Tabs>
</file>

<file path="docs/product/Evals and SteelThread/Streams/Stream_results.md">
---
sidebar_position: 3
slug: /streams-results
---

# Visualise Stream results

Stream metrics are pushed to the [Portia dashboard](https://app.portialabs.ai/dashboard/streams). Clicking on any stream will show the latest metrics for it grouped by the time of run to show you the performance of the stream over time.

![Stream Metrics](/img/stream_metrics_1.png)

You can also drill down into the analysis by clicking on any row in the table to see a detailed breakdown of the individual plan or plan runs that were processed.

![Stream Grouped Metrics](/img/stream_metrics_2.png)

Finally clicking on an individual plan or plan run will show all the specific metrics for that plan run allowing you to see the explanation for scores.

![Stream Grouped Metrics](/img/stream_metrics_3.png)
</file>

<file path="docs/product/Evals and SteelThread/Streams/Streams.md">
---
sidebar_position: 1
slug: /streams-overview
---

# Overview and basic usage

Streams are a way to sample real plans and plan runs from your Portia cloud account allowing you to monitor the performance of your agents in production. 

The overall flow is:

1. From the Portia dashboard, create a new stream including the desired sampling rate. 
2. You can rely on the default evaluators offered by Portia or create your own.
3. Process your stream periodically to pick up all plan runs that haven't been sampled yet. Steel Thread will process each `Plan` or `PlanRun` in the stream using your preferred evaluators.
4. Visualize the metrics from each run in the Portia UI.

:::info[Get your Portia API key]
Please make sure you have a `PORTIA_API_KEY` set up in your environment to use Steel Thread, as it relies on plans and plan runs stored in Portia cloud.
:::

## Basic usage

Let's create a Stream from the 'Observability' tab in the dashboard:
* Give your stream a memorable name we can refer to in the code.
* Select 'Plan Runs' as your Stream source -- SteelThread allows you to monitor Plans more specifically if you wanted to.
* Select 100% as your sampling rate for this demo -- We allow you to dial up or down your sampling rate depending on how close an eye you need to keep on your agents.

<img src="/img/create_stream.gif" alt="Create Stream" style={{ width: '100%', borderRadius: '8px', margin: '24px' }} />

Now that our Stream is created, it can be used to sample future runs and score based on a number of evaluators. Make sure you have some plan run data generated **after** the stream is created so that we can sample it as shown below.

```python
from portia import Config
from steelthread.steelthread import SteelThread, StreamConfig
from dotenv import load_dotenv


load_dotenv(override=True)

config = Config.from_default()

# Setup SteelThread instance and process stream
st = SteelThread()
st.process_stream(
    StreamConfig(
        # The stream name is the name of the stream we created in the dashboard.
        stream_name="your-stream-name-here",
        config=config,
    )
)
```

## Default evaluators 

The `StreamConfig` object above takes a list of evaluators (of type `StreamEvaluator`) as an argument. SteelThread's `LLMJudgeEvaluator` is available off the shelf and is used by default when no evaluators are specified. It is an LLM-as-judge evaluator and it computes the list of metrics below:

#### If you're sampling plans:

| Metric        | Description                                      |
|---------------|--------------------------------------------------|
| `correctness` | Are the steps logically valid?                   |
| `completeness`| Are all necessary steps included?                |
| `clearness`   | Are the steps clearly written and easy to follow?|

#### If you're sampling plan runs:

| Metric       | Description                                       |
|--------------|---------------------------------------------------|
| `success`    | Did the run accomplish its intended goal?         |
| `efficiency` | Were the steps necessary and minimal?             |

Once you process a stream you should be able to see the results in the dashboard, from the 'Observability` tab. Navigate to your stream's results by clicking on your stream name from there. You should see `success` and `efficiency` metrics aggregated at the stream processing time stamp. You can drill into the sampled plan runs under each timestamp by clicking on the relevant row in the table.

:::info[How sampling works with Streams]
Every time you process a stream (by running the `process_stream` method above), SteelThread evaluates all plan runs since the last stream processing timestamp. Think of it as a FIFO queue of plans / plan runs where items are inserted every time you generate a plan / plan run and removed every time you process the stream.
:::
</file>

<file path="docs/product/Evals and SteelThread/_category_.json">
{
  "label": "Evals and SteelThread",
  "position": 5,
  "link": {
    "type": "generated-index",
    "slug": "evals-steel-thread",
    "description": "Monitor the performance of your agents."
  }
}
</file>

<file path="docs/product/Evals and SteelThread/Custom_backend.md">
---
sidebar_position: 5
slug: /custom-backend
---

# Custom backends

SteelThread is designed to allow for metrics to be pushed to other sinks, simply by implementing the correct metrics backend and passing it as config. 

```python
class StreamMetricsBackend(ABC):
    """Abstract interface for saving metrics."""

    @abstractmethod
    def save_metrics(self, metrics: list[StreamMetric]) -> None:
        """Save a list of tagged metrics for a specific evaluation run.

        Args:
            metrics (list[StreamMetricWithTags]): The metrics to save.

        """
        raise NotImplementedError


class MyMetricsBackend(StreamMetricsBackend):
    def save_metrics(self, metrics: list[StreamMetric]) -> None:
        return    

conf = StreamConfig(stream_name="stream_v1", config=config, metrics_backends=[MyMetricsBackend()])
```
</file>

<file path="docs/product/Evals and SteelThread/Introducing Steel Thread.md">
---
sidebar_position: 1
slug: /steel-thread-intro
---

# Introducing Steel Thread

Steel Thread is a lightweight, extensible framework for evaluating LLM agents — designed to help teams measure quality, catch regressions, and improve performance with minimal friction.

Steel Thread is built around two core abstractions:

- **Streams** are dynamic datasets built from sampling real plans and plan runs in production allowing you to monitor live agent behaviour.
- **Evals** are static data sets designed to be run multiple times to allow you to analyze the impact of changes to your agents before deploying them.

Note that Steel Thread is built to work specifically with Portia cloud and therefore requires a Portia API key.

---

## Why we built Steel Thread

Evaluating agents isn’t hard because the models are bad — it’s hard because:

- The output space is non-deterministic.
- The tool usage is complex and multi-step.
- The definition of "correct" can be subjective.
- And most of all: **curating test data is painful** ☠️.

We found that most eval frameworks fall down not on logic or metrics — but on data. They assume someone else is maintaining eval datasets that are 1) clean, 2) up-to-date with how their agents are behaving in production.

Instead of asking teams to build new datasets from scratch, Steel Thread **plugs directly into the data you already generate in Portia Cloud**:

- Plans
- Plan Runs
- Tool Calls
- User IDs
- Metadata and outputs

Now, every agent execution can become an eval — either retrospectively or in real time.

---

## What does it do?

Steel Thread helps you figure out whether your agents are getting better or worse across runs. It does this by providing:

### 🌊 Streams
Run against your live or recent production runs. More commonly referred to as 'online evals', they are useful for:
- Monitoring quality in production usage.
- Tracking performance across time or model changes.
- Detecting silent failures.

### 📈 Evals
Run against curated static datasets. More commonly referred to as 'offline evals', they are useful for:
- Iterating on prompts.
- Testing new chains of tool calls.
- Benchmarking models.
- Catching regressions on common use cases before deployment.

### 🎯 Custom metrics
Use both determistic evaluators or LLMs-as-judge ones to compute:
- Accuracy
- Completeness
- Clarity
- Efficiency
- Latency
- Tool usage
- ...or domain-specific checks

---

## Built for Portia

Steel Thread is deeply integrated with the Portia SDK and cloud. It works natively with:
- Plan and PlanRun IDs
- Tool call metadata
- End user context
- Agent outputs (e.g. final outputs, intermediate values)
- APIs and UI features in Portia Cloud

This means you don’t need to create new test harnesses or annotate synthetic datasets — you can evaluate what's already happening.

Just point Steel Thread at your Portia instance, and start measuring.
</file>

<file path="docs/product/Evals and SteelThread/Quickstart.md">
---
sidebar_position: 2
slug: /steel-thread-quickstart
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Install and quickstart
SteelThread relies on access to agent activity in Portia cloud (queries, plans, plan runs). You will need a `PORTIA_API_KEY` to get started. Head over to (<a href="https://app.portialabs.ai" target="_blank">**app.portialabs.ai ↗**</a>) and navigate to the `Manage API keys` tab from the left hand nav. There you can generate a new API key.
:::tip[For a deeper dive]
Below takes you through install and two end-to-end examples. If you wanted to get a deeper understanding, head over to:
* [Streams page](/streams).
* [Evals page](/evals).
:::

## Install using your framework of choice

<Tabs groupId="installer">
    <TabItem value="pip" label="pip" default>
    ```bash
    pip install steel-thread
    ```
    </TabItem>
    <TabItem value="poetry" label="poetry">
    ```bash
    poetry add steel-thread
    ```
    </TabItem>
    <TabItem value="uv" label="uv">
    ```bash
    uv add steel-thread
    ```
    </TabItem>
</Tabs>

## Create a dataset

If you're new to Portia you may not have agent runs in the cloud just yet so let's start by creating those. Run the query `Read the user feedback notes in local file {path}, and call out recurring themes in their feedback. Use lots of ⚠️ emojis when highlighting areas of concern.` where `path` is a local file you can put a couple of lines of fictitious user feedback in. Here's the script to save you same time:

```python
from portia import Portia

path = "./uxr/calorify.txt" # TODO: change to your desired path
query =f"Read the user feedback notes in local file {path}, \
            and call out recurring themes in their feedback. \
                Use lots of ⚠️ emojis when highlighting areas of concern."

Portia().run(query=query)
```

## Basic example Streams

Below is example code to process a stream. Before running it make sure you set up your stream from the Portia dashboard's Observability tab, **paying special attention to the name you gave your stream** so you can pass it to the `process_stream` method per below. This method will use the built-in set of Stream evaluators to give you data out of the box. 

```python
from portia import Config
from steelthread.steelthread import SteelThread, StreamConfig
from dotenv import load_dotenv


load_dotenv(override=True)

config = Config.from_default()

# Setup SteelThread instance and process stream
st = SteelThread()
st.process_stream(
    StreamConfig(
        # The stream name is the name of the stream we created in the dashboard.
        stream_name="your-stream-name-here",
        config=config,
    )
)
```

## End-to-end example with Evals

Let's push the envelope with some more advanced usage for Evals. Create an Eval dataset in the dashboard from the plan run we made in the **Create a dataset** section. Navigate to the "Evaluations" tab of the dashboard, create a new eval set from existing data and select the relevant plan run. Record the name you bestowed upon your Eval dataset as you will need to pass it to the evaluators in the code below, which you are now ready to run. This code:
* Uses a custom evaluator to count ⚠️ emojis in the output. We will do this by subclassing the `Evaluator` class.
* Stubs the `file_reader_tool` with static text. We will point our `Portia` client to a `ToolStubRegistry` to do this.
* Run the evals for the dataset you create to compute the emoji count metric over it.

Feel free to mess around with the output from the tool stub and re-run these Evals a few times to see the progression in scoring.

```python
from portia import Portia, Config, DefaultToolRegistry
from steelthread.steelthread import SteelThread, EvalConfig
from steelthread.evals import Evaluator, EvalMetric
from steelthread.portia.tools import ToolStubRegistry, ToolStubContext


# Define custom evaluator
class EmojiEvaluator(Evaluator):
    def eval_test_case(self, test_case,plan, plan_run, metadata):
        out = plan_run.outputs.final_output.get_value() or ""
        count = out.count("⚠️")
        return EvalMetric.from_test_case(
            test_case=test_case,
            name="emoji_score",
            score=min(count / 2, 1.0),
            description="Emoji usage",
            explanation=f"Found {count} ⚠️ emojis in the output.",
            actual_value=str(count),
            expectation="2"
        )

# Define stub behavior
def file_reader_stub_response(
    ctx: ToolStubContext,
) -> str:
    """Stub response for file reader tool to return static file content."""
    filename = ctx.kwargs.get("filename", "").lower()

    return f"Feedback from file: {filename} suggests \
        ⚠️ 'One does not simply Calorify' \
        and ⚠️ 'Calorify is not a diet' \
        and ⚠️ 'Calorify is not a weight loss program' \
        and ⚠️ 'Calorify is not a fitness program' \
        and ⚠️ 'Calorify is not a health program' \
        and ⚠️ 'Calorify is not a nutrition program' \
        and ⚠️ 'Calorify is not a meal delivery service' \
        and ⚠️ 'Calorify is not a meal kit service' "


config = Config.from_default()

# Add the tool stub definition to your Portia client using a ToolStubRegistry
portia = Portia(
    config,
    tools=ToolStubRegistry(
        DefaultToolRegistry(config),
        stubs={
            "file_reader_tool": file_reader_stub_response,
        },
    ),
)

# Run evals with stubs 
SteelThread().run_evals(
    portia,
    EvalConfig(
        eval_dataset_name="your-dataset-name-here", #TODO: replace with your dataset name
        config=config,
        iterations=5,
        evaluators=[EmojiEvaluator(config)]
    ),
)
```
</file>

<file path="docs/product/Extend and run tools/_category_.json">
{
  "label": "Extend and run tools",
  "position": 4,
  "link": {
    "type": "generated-index",
    "slug": "extend-run-tools",
    "description": "Add your own tools to your Portia project."
  }
}
</file>

<file path="docs/product/Extend and run tools/Adding custom tools.md">
---
sidebar_position: 5
slug: /add-custom-tools
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Add custom tools

Let's build two custom tools that allow an LLM to write / read content to / from a local file. We'll start building the tool using the `@tool` decorator, which provides a simple and straightforward way to create custom tools from Python functions.

## Using the @tool decorator

The `@tool` decorator converts your functions into Portia tools. Let's create our custom tools in a separate folder called `custom_tools` at the root of the project directory:

<Tabs>
  <TabItem value="file_reader" label="file_reader_tool.py">
    ```python title="custom_tools/file_reader_tool.py" id=file_reader_tool
    from pathlib import Path
    import pandas as pd
    import json
    from typing import Annotated
    from portia import tool

    @tool
    def file_reader_tool(
        filename: Annotated[str, "The location where the file should be read from"]
    ) -> str | dict:
        """Finds and reads content from a local file on Disk."""
        file_path = Path(filename)
        suffix = file_path.suffix.lower()

        if file_path.is_file():
            if suffix == '.csv':
                return pd.read_csv(file_path).to_string()
            elif suffix == '.json':
                with file_path.open('r', encoding='utf-8') as json_file:
                    data = json.load(json_file)
                    return data
            elif suffix in ['.xls', '.xlsx']:
                return pd.read_excel(file_path).to_string()
            elif suffix in ['.txt', '.log']:
                return file_path.read_text(encoding="utf-8")
    ```
  </TabItem>
  <TabItem value="file_writer" label="file_writer_tool.py">
    ```python title="custom_tools/file_writer_tool.py" id=file_writer_tool
    from pathlib import Path
    from typing import Annotated
    from portia import tool

    @tool
    def file_writer_tool(
        filename: Annotated[str, "The location where the file should be saved"],
        content: Annotated[str, "The content to write to the file"]
    ) -> str:
        """Writes content to a file."""
        filepath = Path(filename)
        if filepath.is_file():
            with open(filepath, "w") as file:
                file.write(content)
        else:
            with open(filepath, "x") as file:
                file.write(content)
        return f"Content written to {filename}"
    ```
    </TabItem>
</Tabs>

The file reader tool expects a `filename` argument, which includes the file path and specifies the file to be read, and then returns the contents of the file as an output. The file writer tool expects the content to be written alongside the `filename` tool and then returns a string summarising the successful action. If a file already exists at the specified location its content will be overwritten. In general, a custom tool can return any type that can be safely serialised to a string, though we suggest basic data types (e.g. `str`, `int`, `float`, `bool`), collections of these types (e.g. `list`, `set`, `dict`) or [Pydantic models](https://docs.pydantic.dev/latest/concepts/models/) as they are easier to work with.

:::note[On the local file tools]
If those tools look familiar it's because we actually offer them in our open source repo ready-made. We just wanted to walk you through building your own local version from scratch (<a href="https://github.com/portiaAI/portia-sdk-python/tree/main/portia/open_source_tools" target="_blank">**Open source tools in our SDK repo ↗**</a>). We will save adding clarifications to the next section though.
:::

## Manage tool registries

Let's group our custom tools into a registry so we can import it into code afterwards. Let's create a `registry.py` file in the `custom_tools` directory and declare our registry as follow:
```python title="custom_tools/registry.py" depends_on=file_reader_tool,file_writer_tool id=registry
"""Registry containing my custom tools."""

from portia import ToolRegistry

my_tool_registry = ToolRegistry([
    file_reader_tool(),
    file_writer_tool(),
])
```

Here we are loading our freshly minted local tools into a tool registry called `my_tool_registry` represented by the `ToolRegistry` class. This takes a list of instantiated tool functions as a parameter.<br/>

## Bringing it together in an example

Now let's bring it all together. We can combine any number of tool registries into a single one with the `+` operator. This can just as well be done to combine local and Portia tools together in one fell swoop! For this example, we will combine our custom tool(s) from the `my_tool_registry` we created above with the `example_tool_registry` using `complete_tool_registry = example_tool_registry + my_tool_registry`.<br/>
**Note: Make a `demo_runs` directory at this point. We will be using repeatedly.**

<details>
<summary>**API keys required**</summary>

We will use a simple GET endpoint from OpenWeatherMap in this section. Please sign up to obtain an API key from them (<a href="https://home.openweathermap.org/users/sign_in" target="_blank">**↗**</a>) and set it in the environment variable `OPENWEATHERMAP_API_KEY`.

We're assuming you already have a Tavily key provisioned from the previous sections in this doc. If not, then head over to their website and do so (<a href="https://tavily.com/" target="_blank">**↗**</a>). We will set it in the environment variable `TAVILY_API_KEY`.
</details>

```python title="custom_tools/main.py" id=main depends_on=registry,file_reader_tool,file_writer_tool
from dotenv import load_dotenv
from portia import (
    Portia,
    example_tool_registry,
    Config,
    LogLevel,
)

load_dotenv()

# Load example and custom tool registries into a single one
complete_tool_registry = example_tool_registry + my_tool_registry
# Instantiate Portia with the tools above
portia = Portia(
    Config.from_default(default_log_level=LogLevel.DEBUG),
    tools=complete_tool_registry,
)

# Execute the plan from the user query
plan_run = portia.run('Get the weather in the town with the longest name in Welsh'
                                + ' and write it to demo_runs/weather.txt.')

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```

This should result in a plan and subsequent plan run automatically weaving in the `WeatherTool` and `SearchTool` from the `example_tool_registry` as well as our hot-off-the-press `file_writer_tool` from our `custom_tool_registry`.
You should expect the weather information in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch to be printed in a weather.txt file inside a `demo_runs` folder as specified. If you're in the mood, now is a good time to practise your Welsh pronunciation.
```text title="demo_runs/weather.txt"
The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.
```

## Class-based approach (Alternative)

For more complex scenarios requiring advanced customisation, you can also use the class-based approach. This provides more control over tool configuration and is equivalent to the decorator approach shown above:

<Tabs>
  <TabItem value="class_file_reader" label="file_reader_tool.py (class-based)">
    ```python title="custom_tools/file_reader_tool.py"
    from pathlib import Path
    import pandas as pd
    import json
    from pydantic import BaseModel, Field
    from portia.tool import Tool, ToolRunContext


    class FileReaderToolSchema(BaseModel):
        """Schema defining the inputs for the FileReaderTool."""

        filename: str = Field(...,
            description="The location where the file should be read from",
        )


    class FileReaderTool(Tool[str]):
        """Finds and reads content from a local file on Disk."""

        id: str = "file_reader_tool"
        name: str = "File reader tool"
        description: str = "Finds and reads content from a local file on Disk"
        args_schema: type[BaseModel] = FileReaderToolSchema
        output_schema: tuple[str, str] = ("str", "A string dump or JSON of the file content")

        def run(self, _: ToolRunContext, filename: str) -> str | dict[str,any]:
            """Run the FileReaderTool."""

            file_path = Path(filename)
            suffix = file_path.suffix.lower()

            if file_path.is_file():
                if suffix == '.csv':
                    return pd.read_csv(file_path).to_string()
                elif suffix == '.json':
                    with file_path.open('r', encoding='utf-8') as json_file:
                        data = json.load(json_file)
                        return data
                elif suffix in ['.xls', '.xlsx']:
                    return pd.read_excel(file_path).to_string()
                elif suffix in ['.txt', '.log']:
                    return file_path.read_text(encoding="utf-8")
    ```
  </TabItem>
  <TabItem value="class_file_writer" label="file_writer_tool.py (class-based)">
    ```python title="my_custom_tools/file_writer_tool.py"
    from pathlib import Path
    from pydantic import BaseModel, Field
    from portia.tool import Tool, ToolRunContext

    class FileWriterToolSchema(BaseModel):
        """Schema defining the inputs for the FileWriterTool."""

        filename: str = Field(...,
            description="The location where the file should be saved",
        )
        content: str = Field(...,
            description="The content to write to the file",
        )


    class FileWriterTool(Tool):
        """Writes content to a file."""

        id: str = "file_writer_tool"
        name: str = "File writer tool"
        description: str = "Writes content to a file locally"
        args_schema: type[BaseModel] = FileWriterToolSchema
        output_schema: tuple[str, str] = ("str", "A string indicating where the content was written to")

        def run(self, _: ToolRunContext, filename: str, content: str) -> str:
            """Run the FileWriterTool."""

            filepath = Path(filename)
            if filepath.is_file():
                with open(filepath, "w") as file:
                    file.write(content)
            else:
                with open(filepath, "x") as file:
                    file.write(content)
            return f"Content written to {filename}"
    ```
    </TabItem>
</Tabs>

When using the class-based approach you would be registering the tools the exact same way as the decorator approach:

```python title="my_custom_tools/registry.py (class-based)"
"""Registry containing my custom tools."""

from portia import InMemoryToolRegistry
from my_custom_tools.file_reader_tool import FileReaderTool
from my_custom_tools.file_writer_tool import FileWriterTool

custom_tool_registry = InMemoryToolRegistry.from_local_tools(
    [
        FileReaderTool(),
        FileWriterTool(),
    ],
)
```

The `@tool` decorator approach is recommended for most use cases due to its simplicity and ease of use, while the class-based approach provides more flexibility for advanced scenarios.
</file>

<file path="docs/product/Extend and run tools/Browser based tools.md">
---
sidebar_position: 7
slug: /browser-tools
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Using browser tools

Browser tools (<a href="/SDK/portia/open_source_tools/browser_tool" target="_blank">**SDK ↗**</a>) can deploy an agent to browse the internet and retrieve data or enact actions on your behalf. Portia will use Browser tools when it recognises there is a web-based task to be performed. We use the <a href="https://browser-use.com" target="_blank">**Browser Use (↗)**</a> library to offer a multi-modal web agent that will visually and textually analyse a website in order to navigate it and carry out a task.

Our browser tool can be used in two modes:
- **Remote mode**: Runs on a remote chromium instance using <a href="https://www.browserbase.com/" target="_blank">**Browserbase (↗)**</a> as the underlying infrastructure. Browserbase offers infrastructure for headless browsers remotely. We spin up remote sessions for your end-users which persist through clarifications.
- **Local mode (DEFAULT)**: Runs on a chrome instance on your own computer. Requires Chrome to be started fresh by the agent to work.

The underlying library for navigating the page is provided by <a href="https://browser-use.com" target="_blank">**Browser Use (↗)**</a>. It uses a number of LLM calls to navigate the page and complete the action.

## Setting up the browser based tools

<Tabs>
  <TabItem label="Browserbase setup" value="browserbase_setup">
    To use browserbase infrastructure, you need to install the required `tools-browser-browserbase` dependency group:
    ```
    pip install "portia-sdk-python[tools-browser-browserbase]"
    # Alternatively, install our 'all' dependency group to get everything
    pip install "portia-sdk-python[all]"
    ```
    You must also ensure that you have set the `BROWSERBASE_API_KEY` and `BROWSERBASE_PROJECT_ID` in your .env file (or equivalent). These can be obtained by creating an account on <a href="https://www.browserbase.com" target="_blank">**Browserbase (↗)**</a>. The current behaviour requires a paid version of Browserbase to use.
  </TabItem>
  <TabItem label="Local setup" value="local_setup">
    With local setup, the browser tool uses chrome on the machine it is running on. This means that it is not possible to support end-users but is a good way to test or to write agents for your own purposes. To use the browser tool in local mode, you need to install the required `tools-browser-local` dependency group:
    ```
    pip install "portia-sdk-python[tools-browser-local]"
    # Alternatively, install our 'all' dependency group to get everything
    pip install "portia-sdk-python[all]"
    ```

    You must then specify the `BrowserInfrastructureOption` when creating the tool, i.e:
    
    ```python
    from portia.open_source_tools.browser_tool import BrowserInfrastructureOption, BrowserTool
    browser_tool = BrowserTool(infrastructure_option=BrowserInfrastructureOption.LOCAL)
    ```
  
    You can specify the executable for the Chrome instance, by setting `PORTIA_BROWSER_LOCAL_CHROME_EXEC='path/to/chrome/exec'`. If not specified, the default location on most operating systems will be used. For the agent to work, all other Chrome instances must be closed before the task starts.
  </TabItem>
</Tabs>

## Using browser based tools in Portia

The `BrowserTool` is located in our open source tools folder <a href="/SDK/portia/open_source_tools/browser_tool.py" target="_blank">**SDK ↗**</a>. Additionally, there are 2 ways to use the tool:
- **`BrowserTool()`**: This is a general browser tool and it will be used when a URL is provided as part of the query.

```python title="BrowserTool example"
from portia import Config, Portia
from portia.open_source_tools.browser_tool import BrowserTool

task = "Find my connections called 'Bob' on LinkedIn (https://www.linkedin.com)"

# Needs BrowserBase API key and project_id
portia = Portia(config=Config.from_default(),
                tools=[BrowserTool()])
```

- **`BrowserToolForUrl(url)`**: To restrict the browser tool to a specific URL. This is particularly useful to ensure that the planner is restricted to the domains that you want it to be support.

```python title="BrowserToolForUrl example"
from portia import Config, Portia
from portia.open_source_tools.browser_tool import BrowserToolForUrl

task = "Find my connections called 'Bob' on LinkedIn"

# Needs BrowserBase API key and project_id
portia = Portia(config=Config.from_default(),
                tools=[BrowserToolForUrl("https://www.linkedin.com")])
```

### A simple E2E example

```python title="Full example"
from dotenv import load_dotenv

from portia import (
    ActionClarification,
    Config,
    PlanRunState,
    Portia,
)
from portia.open_source_tools.browser_tool import BrowserTool

load_dotenv(override=True)

task = "Get the top news headline from the BBC news website (https://www.bbc.co.uk/news)"

portia = Portia(Config.from_default(), tools=[BrowserTool()])

plan_run = portia.run(task)

while plan_run.state == PlanRunState.NEED_CLARIFICATION:
    # If clarifications are needed, resolve them before resuming the workflow
    print("\nPlease resolve the following clarifications to continue")
    for clarification in plan_run.get_outstanding_clarifications():
        # Handling of Action clarifications
        if isinstance(clarification, ActionClarification):
            print(f"{clarification.user_guidance} -- Please click on the link below to proceed.")
            print(clarification.action_url)
            input("Press Enter to continue...")

    # Once clarifications are resolved, resume the workflow
    plan_run = portia.resume(plan_run)
```

## Authentication with browser based tools

:::tip[Recap: Portia Authentication]
Portia uses `Clarifications` to handle human-in-the-loop authentication (full explanation <a href="/run-portia-tools" target="_blank">**here ↗**</a>). In our OAuth based tools, the user clicks on a link, authenticates and their token is used when the agents resumes.
:::

In the browser tool case, whenever a browser tool encounters a page that requires authentication, it will raise a clarification request to the user, just like API-based Portia tools. The user will need to provide the necessary credentials or authentication information into the website to proceed. The cookies for that authentication are then used for the rest of the plan run.

![Browser authentication with clarifications](/img/browser_auth.png)

<Tabs>
  <TabItem label="Authentication with Browserbase" value="browserbase_authentication">
    In the case of Browserbase Authentication, the end-user will be provided with a URL starting with `browserbase.com/devtools-fullscreen/...`. When the end-user visits this page, they will see the authentication screen to enter their credentials (and any required 2FA or similar checks). This requires a paid version of Browserbase to work. In addition, Browserbase sessions have a timeout (default is 1hr with a max of 6hr) and the clarification must be handled by the user within this time.

    Once the end-user has performed the authentication, they should then indicate to your application that they have completed the flow, and you should call `portia.resume(plan_run)` to resume the agent. Note if you are using the `CLIClarificationHandler`, this will not work in this way and you will need to override it to ensure this behaviour.
    
    The authentication credentials will be saved against the end user and can be reused until they expire. When the credentials expire, a new clarification will be raised to reset the authentication. If you want to disable persistent authentication across agent runs, you should clear the `bb_context_id` attribute.
  </TabItem>
  <TabItem label="Local Browser Authentication" value="local_authentication">
    When running via a Local browser, i.e via your own computer, the clarification URL will be a regular URL that you can click on to authenticate.
  </TabItem>
</Tabs>

## When to use API vs browser based tools

Browser based tools are very flexible in terms of what they do, however they do not have the same tight permissioning as OAuth tools and require more LLM calls so we recommend balancing between the two and using browser tools only when APIs are not available.

## Known issues and caveats

### Popups and authentication
When using Browserbase as the underlying browser infrastructure, if authentication requires a popup, it will not show to the user and they will not be able to log-in. We are investigating solutions for this at the moment.

### Local chrome failing to connect
If you see an issue whereby Chrome opens, but then immediately closes and restarts, the issue is likely because it can't find the user data directory and the debug server is not starting. You can fix this by specifying the env variable `PORTIA_BROWSER_LOCAL_EXTRA_CHROMIUM_ARGS="--user-data-dir='path/to/dir'"` and there's more information about this on the <a href="https://github.com/browser-use/browser-use/issues/291#issuecomment-2792636861">**browser-use issue link ↗**</a>.

### LLM moderation
We have occasionally observed that LLMs might get moderated on tasks that look like authentication requests to websites. These issues are typically transient but you may want to adjust the task or plan to avoid direct requests for the agent to login to a website.
</file>

<file path="docs/product/Extend and run tools/Cloud Tool Registry.md">
---
sidebar_position: 3
slug: /cloud-tool-registry
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Remote MCP and cloud tools

When your agents are connected to Portia Cloud, they gain access to an extensive tool registry with powerful integrations. The registry includes by default popular services like Gmail, Google Calendar, Slack, GitHub, Zendesk, and is extensible to many more by integrating remote MCP servers. You can check out and configure the integrations you want access to in [the dashboard (↗)](https://app.portialabs.ai/dashboard/tool-registry). This will update update the tools available to your `DefaultToolRegistry` (see [here](/integrating-tools#tool-registries) if you need a recap on how tool registries work).

Authentication for these tools is handled seamlessly by <a href="/run-portia-tools">Portia's authentication system ↗</a>. This means all tools are available using just the Portia API key and you don't have to worry about implementing OAuth flows or handling tokens and API keys yourself!

<figure style={{ textAlign: 'center' }}>
  <img src="/img/tool_registry.png" alt="Tool registry" />
  <figcaption>A snippet of our tool registry</figcaption>
</figure>

The registry contains applications, which are a collection of tools.
It is fully configurable, allowing you to turn applications on and off so you can control which tools your agents have access to.
The applications in the registry are a combination of remote MCP servers from official providers and tools developed by Portia.

## Remote MCP Servers

The Model Context Protocol (MCP) makes it very easy to integrate third-party tools with Portia AI.
To find out more about MCP you can visit the official MCP docs (<a href="https://modelcontextprotocol.io/" target="_blank">**↗**</a>).

We support remote MCP execution within our tool registry and, where possible, our integrations use remote MCP servers from official providers, with communication over a streamable HTTP connection.
This allows our tool registry to grow rapidly as providers bring out new remote MCP servers.
We support authentication natively for all of these servers and are in the process of adding many other features to make working with them easier.

You can extend your Portia cloud tool registry by configuring your own remote MCP server. This allows you to seamlessly integrate tools from any provider with a remote MCP server while Portia handles the authentication for you.

<figure style={{ textAlign: 'center' }}>
  <div style={{ display: 'flex', justifyContent: 'center' }}>
    <video width="100%" autoPlay playsInline muted loop>
      <source src="/img/register_mcp_server.mp4" type="video/mp4" />
    </video>
  </div>
  <figcaption>Connect your own MCP server into our cloud tool registry</figcaption>
</figure>

:::info[Enabling authenticated remote MCP servers]
It is worth noting that, when enabling MCP-based applications which use OAuth or API key authentication, you will need to authenticate with the server. This is required because MCP requires authentication in order to view available tools. The authentication credentials provided here are only used for listing tools from the server and are separate to those that the tool is executed with. We store all authentication credentials using <a href="/security">production-grade encryption</a>.
:::

### Customizing MCP and other cloud based tools

We offer an easy way to customize our cloud based tools, or remote MCP server tool descriptions using the `ToolRegistry.with_tool_description` function. You can read more about this <a href="/integrating-tools" target="_blank">here</a>.

## Other Portia Cloud Tools

Where there is no official remote MCP server for a provider, we have a collection of tools developed by Portia.
This allows you to integrate easily with providers that are yet to release a remote MCP server.
Authentication for the tools is handled fully by the Portia platform and you can use these tools in exactly the same way as you can use tools coming from remote MCP servers.

## Enabling and Disabling Tools

When you enable an application, all tools in this application become available to your agent. Applications can be easily enabled and disabled in the UI by:
1. Clicking on the 'Enable' / 'Disable' button when you hover over the application.
2. Configuring access if required - this is only required for remote MCP servers
3. Once this is done, the tool is configured and you'll be able to view the available tools under the application in the dashboard.

<figure style={{ textAlign: 'center' }}>
  <div style={{ display: 'flex', justifyContent: 'center' }}>
    <video width="50%" autoPlay playsInline muted loop>
      <source src="/img/tool_hover.mp4" type="video/mp4" />
    </video>
  </div>
  <figcaption>Quickly enable and disable tools hovering over them</figcaption>
</figure>


It is important to choose your enabled tools carefully to avoid tool clashes. For example, if you wish to enable Microsoft Outlook, you should disable Gmail so that the agent knows which email provider to choose when you give it prompts like 'send an email'.
</file>

<file path="docs/product/Extend and run tools/Integrating tools.md">
---
sidebar_position: 2
slug: /integrating-tools
---

# Integrating tools
Learn how to integrate tools that your agent can use to answer a user query.
:::tip[TL;DR]
- You can specify the tools that agents can use to answer a user query by using the `tools` argument in your `Portia` instance. If you don't specify this, the `Portia` instance will use a default set of tools.
- Tool registries are useful to group frequently used tools together. They are represented by the `ToolRegistry` class (<a href="/SDK/portia/tool_registry" target="_blank">**SDK reference ↗**</a>).
:::

## Overview of tool integration
As part of defining your `Portia` instance for a query, you can specify the tools that the LLM can use to answer the query. This is done by specifying the `tools` argument in the `Portia` instance definition.

```python
from portia import (
  default_config, 
  Portia,
)
from portia.open_source_tools.calculator_tool import CalculatorTool
from portia.open_source_tools.search_tool import SearchTool
from portia.open_source_tools.weather import WeatherTool

# Instantiate a Portia instance. Load it with the default config and with the example tools.
portia = Portia(tools=[CalculatorTool(), SearchTool(), WeatherTool()])
```

If you don't specify the `tools` argument, your `Portia` instance will use a default set of tools.

:::info[Default tools]
The default tool set comprises:
* The [**open source tool set**](/portia-tools/open-source/), with the Search tool and Weather tool only included if you have the corresponding Tavily / OpenWeatherMap API keys specified.
* If you have an API key for Portia Cloud, the tools from your cloud tool registry will be included. This includes the ability to integrate any remote MCP server, as well as a suite of pre-created integrations you can use straight off the bat.
Further information on this tool registry, including how it can be configured, can be found on the <a href="/cloud-tool-registry" target="_blank">**Remote MCP and cloud tools page ↗**</a>.
:::

## Tool registries

A tool registry is a collection of tools and is represented by the `ToolRegistry` class (<a href="/run-portia-tools" target="_blank">**SDK reference ↗**</a>). Tool registries are useful to group frequently used tools together, e.g. you could imagine having a tool registry by function in your organisation. Portia's default tool registry can be accessed by calling `DefaultToolRegistry(config=default_config())`.

```python
from dotenv import load_dotenv
from portia import (
    DefaultToolRegistry,
    Portia,
    default_config,
)
from portia.open_source_tools.calculator_tool import CalculatorTool
from portia.open_source_tools.search_tool import SearchTool
from portia.open_source_tools.weather import WeatherTool

load_dotenv()

# Instantiate a Portia instance. Load it with the example tools and Portia's tools.
portia = Portia(tools=DefaultToolRegistry(default_config()))
```

### Customizing tool descriptions

It's often the case that you want to provide custom instructions to Portia agents about how to use a tool, for example, because the author of the MCP tool has missed some context that's important for your usecase, or because you want to personalize the tool in some way. We offer an easy way to edit tool descriptions to do this using the `ToolRegistry.with_tool_description` function.

Consider the below example that personalizes the Linear MCP server with the default team ID:

```python title="customize_tool_descriptions.py"
from portia import Config, Portia, PortiaToolRegistry
from portia.cli import CLIExecutionHooks

my_config = Config.from_default()

portia = Portia(
    config=my_config,
    tools=PortiaToolRegistry(my_config).with_tool_description(
        "portia:mcp:custom:mcp.linear.app:create_issue",
        "If a teamID is not provided, use teamID 123."),
    execution_hooks=CLIExecutionHooks(),
)
```

This customization can be used across any tool registry in Portia.

## Available tools

When setting up your tool registry, there are four sources of tools you can use: our open-source tools, our Portia cloud tools, your own MCP tool registry and custom code tools.

### Open source tools

Portia provides an open source tool registry that contains a selection of general-purpose utility tools. For example, it includes a Tavily tool for web search, an OpenWeatherMap tool for determining weather and a PDF reader tool, among many others.
The open source tool registry can be used as follows, though for some of the tools you will need to retrieve an API key first:

```python
from portia import open_source_tool_registry, Portia

portia = Portia(tools=open_source_tool_registry)
```

For more details, check out our <a href="/portia-tools/open-source/" target="_blank">open-source tool documentation ↗</a>.

### Portia cloud registry

Portia cloud provides an extensive tool registry to speed up your agent development, with authentication handled seamlessly by Portia for you.
You can select any MCP server with an official remote server implementation from our Tool registry dashboard and connect it to your account. We are rapidly growing our library as providers bring out new remote MCP servers. If you'd like to add a missing or proprietary remote MCP server to your Portia cloud registry and rely on Portia to handle authentication for you, you can do that from the dashboard as well.
Finally Portia cloud also includes some in-house-built tools that don't have an official MCP server implementation e.g. Google and Microsoft productivity tools.

Your Portia tool registry is available through the  `PortiaToolRegistry` class (<a href="/run-portia-tools" target="_blank">**SDK reference ↗**</a>). This gives access to all the tools you have enabled in your registry:

```python
from portia import Portia, PortiaToolRegistry

portia = Portia(tools=PortiaToolRegistry())
```

More details can be found on our <a href="/cloud-tool-registry" target="_blank">Cloud tool registry ↗</a> page, including how to enable / disable tools within the registry and how to connect in your own remote MCP server.

### Integrate your own MCP servers [SDK-only option]

You can easily add any local or remote MCP servers directly into a Portia agent through our `McpToolRegistry` class.
The key difference between integrating an MCP server this way and through the Portia cloud registry is that authentication needs to be handled manually when integrating directly into the Portia instance.
The MCP server can be added to your Portia instance as follows, with more details available on our <a href="/mcp-servers" target="_blank">integrating MCP servers ↗</a> page.

```python
from portia import Portia, McpToolRegistry

tool_registry = (
    # Assumes server is running on port 8000
    McpToolRegistry.from_sse_connection(
        server_name="mcp_sse_example_server",
        url="http://localhost:8000",
    )
)
portia = Portia(tools=tool_registry)
```

### Custom tools

As outlined in the <a href="/mcp-servers" target="_blank">Introduction to tools ↗</a>, it is easy to define your own tools in python code with Portia. In (<a href="/add-custom-tools" target="_blank">**Adding custom tools ↗**</a>), we'll walk through how to do this in more detail by creating our own tool registries with custom tools.

## Filtering tool registries

You can create new tool registries from existing ones by filtering tools to your desired subset. For example, you might want to prevent one of your agents from accessing emails in Gmail. This can be done by setting up a filter to exclude the Gmail tools from the registry:

```python
from dotenv import load_dotenv
from portia import (
    Portia,
    PortiaToolRegistry,
    Tool,
    default_config,
)

load_dotenv()

def exclude_gmail_filter(tool: Tool) -> bool:
    return not tool.id.startswith("portia:google:gmail:")

registry = PortiaToolRegistry(config=default_config()).filter_tools(exclude_gmail_filter)
portia = Portia(tools=registry)
```
</file>

<file path="docs/product/Extend and run tools/Intro to tools.md">
---
sidebar_position: 1
slug: /intro-to-tools
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Introduction to tools
Understand tools at Portia and add your own.
:::tip[TL;DR]
- Tools are used by LLMs as part of their response to indicate that a particular software service or data store is required to fulfil a user's query.
- We represent a tool with the `Tool` class (<a href="/SDK/portia/tool" target="_blank">**SDK reference ↗**</a>). The LLM parses the tool properties, namely its name, description, input and output schemas to determine whether the tool is relevant to its response and how to invoke it.
:::

## Tools at Portia
A tool is a natural language wrapper around a data source or software service that the LLM can point to in order to accomplish tasks beyond its inherent capabilities. As a simple example, an LLM could respond to the user query `email avrana@kern.ai and tell her that spiders are now sentient` by suggesting a call to the email sending service wrapped in the `send_email` tool.

We represent a tool with the `Tool` class (<a href="/SDK/portia/tool" target="_blank">**SDK reference ↗**</a>). Let's look at the `weather_tool` provided with our SDK as an example:
```python title="weather_tool.py"
"""Tool to get the weather from openweathermap."""
import os
import httpx
from pydantic import BaseModel, Field
from portia.errors import ToolHardError, ToolSoftError
from portia.tool import Tool, ToolRunContext


class WeatherToolSchema(BaseModel):
    """Input for WeatherTool."""

    city: str = Field(..., description="The city to get the weather for")


class WeatherTool(Tool[str]):
    """Get the weather for a given city."""

    id: str = "weather_tool"
    name: str = "Weather Tool"
    description: str = "Get the weather for a given city"
    args_schema: type[BaseModel] = WeatherToolSchema
    output_schema: tuple[str, str] = ("str", "String output of the weather with temp and city")

    def run(self, _: ToolRunContext, city: str) -> str:
        """Run the WeatherTool."""
        api_key = os.getenv("OPENWEATHERMAP_API_KEY")
        if not api_key or api_key == "":
            raise ToolHardError("OPENWEATHERMAP_API_KEY is required")
        url = (
            f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"
        )
        response = httpx.get(url)
        response.raise_for_status()
        data = response.json()
        if "weather" not in data:
            raise ToolSoftError(f"No data found for: {city}")
        weather = data["weather"][0]["description"]
        if "main" not in data:
            raise ToolSoftError(f"No main data found for city: {city}")
        temp = data["main"]["temp"]
        return f"The current weather in {city} is {weather} with a temperature of {temp}°C."
```

Here are the key points to look out for:
- All properties of a tool are parsed by the LLM to determine whether that tool is salient to a user's query and should therefore be invoked in response to it.
- The `args_schema` property describes the tool inputs. This is important to help the LLM understand what parameters it can invoke a tool with.
- The `output_schema` property describes the expected output of the tool. This helps the LLM know what to expect from the tool and informs its sequencing decisions for tool calls as well.
- Optionally, you can override the `should_summarize` property to determine whether the tool output should be summarised. When this setting is turned on, it uses an additional LLM call to populate the summary field in the step's output of the plan run object.
- Every tool has a `run` function which is the actual tool implementation. The method always takes `ToolRunContext` which is contextual information implicitly passed by Portia. We will look into this more deeply in a future section (<a href="/manage-end-users" target="_blank">**Manage execution context ↗**</a>). The only thing to note now is that you have to include this argument and always import the underlying dependency.

:::note[Track tool calls in logs]
You can track tool calls live as they occur through the logs by setting `default_log_level` to DEBUG in the `Config` of your `Portia` instance (<a href="/manage-config#manage-logging" target="_blank">**Manage logging ↗**</a>).
:::
</file>

<file path="docs/product/Extend and run tools/MCP servers.md">
---
sidebar_position: 4
slug: /mcp-servers
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Integrating an MCP server with the SDK

The Model Context Protocol (MCP) makes it very easy to integrate third-party tools into your Portia AI project.
To find out more you can visit the <a href="https://modelcontextprotocol.io/" target="_blank">official MCP docs ↗</a>.

:::tip[Remote MCP servers]
This section covers integration an MCP server with the **SDK**. The easiest way to connect a remote MCP server with managed authentication is through the <a href="https://app.portialabs.ai/dashboard/tool-registry" target="_blank">Cloud tool registry</a> (see documentation <a href="/cloud-tool-registry" target="_blank">here</a>). When using the cloud tool registry, authentication is handled for you, but if you're connecting directly into the SDK then you'll need to handle authentication yourself.
:::

We provide developers with the ability to set up their own MCP server connections (local or remote) directly into our SDK. When integrating an SDK server directly with the SDK, we offer the three methods currently available for interacting with MCP servers:
- **STDIO** (Standard input/output): The server runs as a subprocess of your main python process. Below we interact with that process via an npx command and a docker command provided with the correct arguments.
- **Streamable HTTP**: Communication is over HTTP, you can run the server locally or deploy a server remotely. Per below, you just need to specify the current server name and URL.
- **SSE** (Server-Sent Events): A legacy method of communication over HTTP, since replaced by Streamable HTTP.

To find out more about these options, see the official MCP docs (<a href="https://modelcontextprotocol.io/docs/concepts/transports" target="_blank">**↗**</a>).

The `server_name` argument is used by Portia to identify where tools have come from, you can set this to whatever makes most sense for the MCP server you are integrating. If you re-use old `Plan` objects later on, make sure to use the same `server_name` with the MCP server.

<Tabs>
  <TabItem value="mcp_stdio" label="STDIO">
    ```python title="mcp_stdio_example.py"
    import os

    from portia import (
        DefaultToolRegistry,
        Portia,
        McpToolRegistry,
        Config,
    )

    config = Config.from_default()

    tool_registry = (
        # Integrates the Stripe MCP server from 
        # https://github.com/stripe/agent-toolkit/tree/main/modelcontextprotocol
        McpToolRegistry.from_stdio_connection(
            server_name="stripe",
            command="npx",
            args=[
                "-y",
                "@stripe/mcp",
                "--tools=all",
                f"--api-key={os.getenv('STRIPE_API_KEY')}",
            ],
        )
        # Integrates Github MCP server using docker
        + McpToolRegistry.from_stdio_connection(
            server_name="github",
            command="docker",
            args=[
                "run",
                "-i",
                "--rm",
                "-e",
                "GITHUB_PERSONAL_ACCESS_TOKEN",
                "ghcr.io/github/github-mcp-server"
            ],
            env={
                "GITHUB_PERSONAL_ACCESS_TOKEN": "<YOUR TOKEN>"
            }
        )
        + DefaultToolRegistry(config)
    )

    portia = Portia(config=config, tools=tool_registry)
    ```
  </TabItem>
  <TabItem value="mcp_streamable_http" label="Streamable HTTP">
    ```python title="mcp_streamable_http_example.py"
    from portia import (
        DefaultToolRegistry,
        Portia,
        McpToolRegistry,
        Config,
    )

    config = Config.from_default()

    tool_registry = (
        # Assumes server is running on port 8000
        McpToolRegistry.from_streamable_http_connection(
            server_name="mcp_streamable_http_example_server",
            url="http://mcp.example.com/http",
        )
        + DefaultToolRegistry(config)
    )

    portia = Portia(config=config, tools=tool_registry)
    ```
  </TabItem>
  <TabItem value="mcp_sse" label="SSE">
    ```python title="mcp_sse_example.py"
    from portia import (
        DefaultToolRegistry,
        Portia,
        McpToolRegistry,
        Config,
    )

    config = Config.from_default()

    tool_registry = (
        # Assumes server is running on port 8000
        McpToolRegistry.from_sse_connection(
            server_name="mcp_sse_example_server",
            url="http://localhost:8000",
        )
        + DefaultToolRegistry(config)
    )

    portia = Portia(config=config, tools=tool_registry)
    ```
  </TabItem>
</Tabs>

:::info[Pre-requisites]
To run the stdio example, make sure `npx` and `docker` are available in your environment. Many MCP servers are currently provided to run in this way, usually either run with the `npx`, `docker` or `uvx` command.
:::

When you provide a `McpToolRegistry`, Portia will pull in the tool definitions from the MCP server, making them available to the Planner and Execution Agents during a plan run. To see an example of this implementation, head over to our agent-examples repo where we built an agent to manage customer refunds (<a href="https://github.com/portiaAI/portia-agent-examples/tree/main/refund-agent-mcp" target="_blank">**↗**</a>).

There are many open source MCP servers already available: check out the list of servers on the official MCP github repository (<a href="https://github.com/modelcontextprotocol/servers" target="_blank">**↗**</a>).
</file>

<file path="docs/product/Extend and run tools/Use clarifications in tools.md">
---
sidebar_position: 6
slug: /clarifications-in-tools
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Use clarifications in custom tools
:::tip[TL;DR]
You can raise a `Clarification` in any custom tool definition to prompt a plan run to interrupt itself and solicit input (<a href="/SDK/portia/clarification" target="_blank">**SDK reference ↗**</a>).
:::


## Add a clarification to your custom tool
Let's pick up the custom tool example we looked at previously (<a href="/add-custom-tools" target="_blank">**Add custom tools ↗**</a>). We will now examine the code that defines a clarification in a tool explicitly. We're going to add a clarification to the `FileReaderTool` custom tool to handle cases where a file is not found. Instead of throwing an error directly, we will attempt to find the file in other folders in the project directory. We do that by adding the highlighted lines in the `FileReaderTool` class definition as shown below.

```python title="my_custom_tools/file_reader_tool.py" id=clarification_file_reader_tool
from pathlib import Path
import pandas as pd
import json
from pydantic import BaseModel, Field
from portia import (
    MultipleChoiceClarification,
    Tool,
    ToolHardError,
    ToolRunContext,
)


class FileReaderToolSchema(BaseModel):
    """Schema defining the inputs for the FileReaderTool."""

    filename: str = Field(..., 
        description="The location where the file should be read from",
    )


class FileReaderTool(Tool[str]):
    """Finds and reads content from a local file on Disk."""

    id: str = "file_reader_tool"
    name: str = "File reader tool"
    description: str = "Finds and reads content from a local file on Disk"
    args_schema: type[BaseModel] = FileReaderToolSchema
    output_schema: tuple[str, str] = ("str", "A string dump or JSON of the file content")

    def run(self, ctx: ToolRunContext, filename: str) -> str | dict[str,any] | MultipleChoiceClarification:
        """Run the FileReaderTool."""
        
        file_path = Path(filename)
        suffix = file_path.suffix.lower()

        if file_path.is_file():
            if suffix == '.csv':
                return pd.read_csv(file_path).to_string()
            elif suffix == '.json':
                with file_path.open('r', encoding='utf-8') as json_file:
                    data = json.load(json_file)
                    return data
            elif suffix in ['.xls', '.xlsx']:
                return pd.read_excel(file_path).to_string
            elif suffix in ['.txt', '.log']:
                return file_path.read_text(encoding="utf-8")
            else:
               raise ToolHardError(f"Unsupported file format: {suffix}. Supported formats are .txt, .log, .csv, .json, .xls, .xlsx.")
        
        # highlight-start
        alt_file_paths = self.find_file(filename)
        if alt_file_paths:
            return MultipleChoiceClarification(
                plan_run_id=ctx.plan_run.id,
                argument_name="filename",
                user_guidance=f"Found {filename} in these location(s). Pick one to continue:\n{alt_file_paths}",
                options=alt_file_paths,
            )
        # highlight-end

        raise ToolHardError(f"No file found on disk with the path {filename}.")

    # highlight-start
    def find_file(self, filename: str) -> list[Path]:
        """Returns a full file path or None."""

        search_path = Path("../")
        filepaths = []

        for filepath in search_path.rglob(filename):
            if filepath.is_file():
                filepaths.append(str(filepath))
        if filepaths:
            return filepaths
        return None
    # highlight-end
```

The block below results in the tool using the `find_file` method to look for alternative locations and raising this clarification if multiple paths are found in the project directory. Here we're using `MultipleChoiceClarification` specifically, which takes a `options` property where the paths found are enumerated. You can explore the other types a `Clarification` object can take in our documentation (<a href="/SDK/portia/clarification" target="_blank">**SDK reference ↗**</a>).

```python skip=true skip_reason=copied_from_example_above
alt_file_paths = self.find_file(filename)
if alt_file_paths:
    return MultipleChoiceClarification(
        plan_run_id=ctx.plan_run.id,
        argument_name="filename",
        user_guidance=f"Found {filename} in these location(s). Pick one to continue:\n{alt_file_paths}",
        options=alt_file_paths,
    )
```

## Testing your tool with clarifications
We're now ready to put our clarification to the test. We won't revisit how clarifications work and are handled in detail here, For that you can check out the section dedicated to clarifications (<a href="/understand-clarifications" target="_blank">**Understand clarifications↗**</a>).

:::info[Make a `weather.txt` file for this section]
In this example, our custom tool `FileReaderTool` will attempt to open a non-existent local file `weather.txt`. This should trigger the tool to search for the file across the rest of the project directory and return all matches. Make sure to sprinkle a few copies of a `weather.txt` file around in the project directory. 
Note: Our `weather.txt` file contains "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C."
:::

```python title="main.py" depends_on=clarification_file_reader_tool
from portia import Portia
from portia.config import default_config
from portia.open_source_tools.registry import example_tool_registry
from my_custom_tools.registry import custom_tool_registry
from portia.clarification import MultipleChoiceClarification
from portia.plan_run import PlanRunState

# Load example and custom tool registries into a single one
complete_tool_registry = example_tool_registry + custom_tool_registry
# Instantiate a Portia instance. Load it with the default config and with the tools above
portia = Portia(tools=complete_tool_registry)

# Execute the plan from the user query
plan_run = portia.run('Read the contents of the file "weather.txt".')

# Check if the plan run was paused due to raised clarifications
while plan_run.state == PlanRunState.NEED_CLARIFICATION:
    # If clarifications are needed, resolve them before resuming the plan run
    for clarification in plan_run.get_outstanding_clarifications():
        # For each clarification, prompt the user for input
        print(f"{clarification.user_guidance}")
        user_input = input("Please enter a value:\n" 
                        + (("\n".join(clarification.options) + "\n") if "options" in clarification else ""))
        # Resolve the clarification with the user input
        plan_run = portia.resolve_clarification(clarification, user_input, plan_run)

    # Once clarifications are resolved, resume the plan run
    plan_run = portia.resume(plan_run)

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```

For the example query above `Read the contents of the file "weather.txt".`, where the user resolves the clarification by entering one of the options offered by the clarification (in this particular case `demo_runs/weather.txt` in our project directory `momo_sdk_tests`), you should see the following plan run state and notice:
- The multiple choice clarification where the `user_guidance` was generated by Portia based on your clarification definition in the `FileReaderTool` class,
- The `response` in the second plan run snapshot reflecting the user input, and the change in `resolved` to `true` as a result
- The plan run `state` will appear to `NEED_CLARIFICATION` if you look at the logs at the point when the clarification is raised. It then progresses to `COMPLETE` once you respond to the clarification and the plan run is able to resume:
```json title="run_state.json"
{
  "id": "prun-54d157fe-4b99-4dbb-a917-8fd8852df63d",
  "plan_id": "plan-b87de5ac-41d9-4722-8baa-8015327511db",
  "current_step_index": 0,
  "state": "COMPLETE",
  "outputs": {
    "clarifications": [
      {
        "id": "clar-216c13a1-8342-41ca-99e5-59394cbc7008",
        "category": "Multiple Choice",
        "response": "../momo_sdk_tests/demo_runs/weather.txt",
        "step": 0,
        "user_guidance": "Found weather.txt in these location(s). Pick one to continue:\n['../momo_sdk_tests/demo_runs/weather.txt', '../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt']",
        "resolved": true,
        "argument_name": "filename",
        "options": [
          "../momo_sdk_tests/demo_runs/weather.txt",
          "../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt"
        ]
      }
    ],
    "step_outputs": {
      "$file_contents": {
        "value": "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.",
        "summary": null
      }
    },
    "final_output": {
      "value": "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.",
      "summary": null
    }
  }
}
```

## Accessing clarifications in your custom tool
The above example showed how you can access a clarification in your custom tool when it relates directly to the tool's arguments. If however you wanted to access a clarification from your tool that is not related to the tool's arguments, you can do so by using the `ToolRunContext` object that is passed to the `run` method of your tool.

```python
from portia import ToolRunContext, MultipleChoiceClarification

def run(self, ctx: ToolRunContext, filename: str) -> str | dict[str,any] | MultipleChoiceClarification:
    """Run the FileReaderTool."""
    clarifications = ctx.clarifications
```

This allows you to return more complex clarifications from your tool and access them once they have been resolved by the user.
</file>

<file path="docs/product/Get started/_category_.json">
{
  "label": "Get started",
  "position": 1,
  "link": {
    "type": "doc",
    "id": "index"
  }
}
</file>

<file path="docs/product/Get started/A tour of our SDK.md">
---
sidebar_position: 6
slug: /getting-started-tour
---

# A tour of our SDK

Portia AI enables developers to build powerful, production-ready agents that can interact with real-world APIs, manage context intelligently, and even automate web browsers.
This tutorial provides a whistlestop tour of the SDK to get you started.
It provides four examples, each building on top of the previous to show how to develop increasingly capable AI agents with just a few lines of code.
Our [examples repository ↗](https://github.com/portiaAI/portia-agent-examples) on GitHub also provides some advanced agent examples that can be a useful reference.

## Before you start

Make sure you have the SDK environment set up:

1. Copy `.env.example` to `.env` and fill in the necessary configuration values for the script you want to run.
  Each Python script documents the configuration required to run it at the top of the file.
2. Run any example using:

   ```bash
   uv run <script_name>.py
   ```

   This will:

   * Obtain an appropriate version of Python if necessary.
   * Create a virtual environment for your Python dependencies.
   * Install all required dependencies.
   * Run your script!
  
With that out of the way, let's look at running the first sample script!

## 1. GitHub OAuth integration

**File**: [`1_github_oauth.py` ↗](https://github.com/portiaAI/portia-agent-examples/blob/main/getting-started/1_github_oauth.py)

This is the most straightforward example of using Portia to connect to third-party APIs with OAuth.
It demonstrates how an agent can perform actions on behalf of a user,
such as starring a GitHub repository or checking availability on their Google Calendar.

### Key concepts

* OAuth authentication for third-party services.
* Use of `Portia` with multiple tools.
* Simple command execution.

### Configuring Portia with a .env file

Before we get started with the Portia-specific code, let's talk about configuration.
In all of our examples, we use the popular [`python-dotenv` ↗](https://pypi.org/project/python-dotenv/) library.
This library will read a `.env` file from your current directory,
and copy the variables defined in the file into the Python program's environment.

Portia automatically reads certain environment variables, such as `PORTIA_API_KEY`,
which allows it to connect to the Portia cloud service.
Portia cloud provides useful extra services, such as the ability to:

* See all the plans created or run against your account.
* Store credentials for different services, like the GitHub API.
* Approve certain good plans, making future planning more reliable for your use-cases.

Portia will also automatically look for a variable called `OPENAI_API_KEY`.
If it's available, Portia will configure OpenAI as your underlying default LLM,
used for planning and other tasks that work with human language.

If `OPENAI_API_KEY` is not available, Portia will look for the following keys in order,
and use the first one that is defined:

* `ANTHROPIC_API_KEY`
* `MISTRAL_API_KEY`
* `GOOGLE_API_KEY`
* `AZURE_OPENAI_API_KEY`

Instead of implicitly loading configuration from your environment (and a .env file),
it's often better to explicitly configure Portia.
This can be done when obtaining a `Config` instance,
for example: `config = Config.from_default(llm_provider=LLMProvider.MISTRALAI)`
will override any other API keys configured in the environment.

### Code walkthrough

Let's step through the first code example.
We'll go slower through this first file,
so you can understand all the details,
and in later examples I'll just cover what's changed.

```python id=tour_code_1
from portia import (
   Config,
   Portia,
   PortiaToolRegistry,
   StorageClass,
)
from portia.cli import CLIExecutionHooks
```

Core Portia functionality is stored in the `portia` package.
Other, more specific APIs are in sub-packages.
As you can see here, command-line functionality is stored in `portia.cli`.

| Class                | What does it do?                                                                                                                                                                                                                                                                                               |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Config`             | This object will load configuration from the environment, and allow you to configure Portia explicitly in code.                                                                                                                                                                                                |
| `Portia`             | This is the primary class in the Portia SDK, and allows you to plan what an agent will do, and execute that plan with the assistance of any tools that Portia is configured with.                                                                                                                              |
| `PortiaToolRegistry` | This is the default set of tools that allows Portia to interact with APIs such as GitHub and Google. The list of tools provided in the PortiaTool Registry is growing all the time. You can find a complete list in the [Portia Tool Catalogue ↗](/portia-tools)                       |
| `StorageClass`       | This is an enum, allowing you to configure where Portia's state is stored. If you use `StorageClass.CLOUD`, Portia will store plans and plan runs on Portia's servers, allowing various extended functionality. If you would rather store your state locally, use `StorageClass.MEMORY` or `StorageClass.DISK` |

With that out of the way, let's define a task!
This file contains two hard-coded tasks:

```python id=tour_code_2
# A relatively simple task:
task0 = "Star the github repo for portiaAI/portia-sdk-python"

# A more complex task:
task1 = """
Check my availability in Google Calendar for tomorrow between 10am and 12pm.
If I have any free times between 10am and 12pm, please schedule a 30-minute meeting with
bob (bob@portialabs.ai) with title 'Encode Hackathon', and description 'hack it'.
If I don't have any free times, please output the next time after 12pm when I am free.
"""
```

You'll notice, just from the length of the strings, that one task is significantly more complex than the other. For now I'll just focus on `task0`, which automatically [gives us a star on GitHub ↗](https://github.com/portiaAI/portia-sdk-python).

The next step is to put all of the classes that we imported to work,
and to compose a `Portia` instance.
The following code combines configuration,
the list of tools in the Portia Catalogue,
and adds in the `CLIExecutionHooks`,
which adds control-flow for Portia to interrupt the run when required,
and interact with the user on the command-line.

```python id=tour_code_3 depends_on=tour_code_1
# Instantiate a Portia runner.
# Load it with the default config from the environment, and with Portia cloud tools.
# Use the CLIExecutionHooks to allow the user to provide input to the agents via the CLI when needed
my_config = Config.from_default(storage_class=StorageClass.CLOUD)
portia = Portia(
   config=my_config,
   tools=PortiaToolRegistry(my_config),
   execution_hooks=CLIExecutionHooks(),
)
```

Finally, the `Portia` class is used to run the task!
`portia.run` returns a `PlanRun` object that contains the outputs of the agent run,
including those at each step in the plan.
This is very useful for debugging what the agent did,
as well as obtaining any output from `plan_run.outputs`.

```python id=tour_code_4 depends_on=tour_code_2,tour_code_3
plan_run = portia.run(task0)
```

In this example:

* The agent is initialized with the [default tools ↗](https://docs.portialabs.ai/portia-tools/) that are provided with Portia.
 This includes tools for connecting to the GitHub API and Google Calendar.
* The `run` method receives a high-level instruction.
* Portia handles breaking down the instruction,
 authenticating where needed and calling any necessary tools.

### Running the example

If you haven't done it already, now is a good time to copy the `.env.example`
file and to add your configuration for `PORTIA_API_KEY` (you can grab this from the [the Portia dashboard ↗](https://app.portialabs.ai/dashboard/api-keys) if you don't already have one),
and provide a key for your favourite LLM.

This code has been designed to run with `uv`.
Providing you have `uv` installed, you can run this example with:

`uv run 1_github_oauth.py`

If the user hasn't authorized GitHub yet,
Portia will request authentication before proceeding.
**This is a major feature of Portia!**
Behind the scenes,
this ability for a tool to pause execution of the agent,
and to ask the user for input,
is super-powerful.
We call this process a "clarification."

If you're planning to write your own tools to take advantage of this feature,
do check out the documentation for [clarifications ↗](/understand-clarifications).

### Before moving on

Before moving on, why not swap the task variable provided to `plan.run()`?
Trying out the more complex example can show you how powerful autonomous agents can be!

---

## 2. Tools, end users, and LLMs

**File**: [`2_tools_end_users_llms.py` ↗](https://github.com/portiaAI/portia-agent-examples/blob/main/getting-started/2_tools_end_users_llms.py)

### Key concepts

* Introducing more diverse tools.
* Supporting named end users.
* Separation of planning and execution.

### Code walkthrough

Here's the task that will be execute by default:

```python id=tour_code_5
# Needs Tavily API key
task2 = (
   "Research the price of gold in the last 30 days, "
   "and send bob@portialabs.ai a report about it."
)
```

In order to execute this task,
three tools will be required.

* One tool will be needed to research the price of gold.
 In this example, the planning agent should choose the [Tavily tool ↗](https://tavily.com/).
 Tavily is a research API designed for agents.
* A tool to send an email.
 The planning agent should choose a Google Mail tool for this.
* An LLM (used as a tool!) to generate the email content that will be sent.

Let's skip to near the end 🙂!
The following code configures a Portia instance:

```python id=tour_code_6 depends_on=tour_code_3
# Insert other imports detailed above
from portia import open_source_tool_registry

portia = Portia(
   config=my_config,
   tools=PortiaToolRegistry(my_config) + open_source_tool_registry,
   execution_hooks=CLIExecutionHooks(),
)
```

This is very similar to the previous example.
The first thing to notice in this example is that two tool registries are being provided,
the `PortiaToolRegistry` (which needs to be instantiated with configuration),
and `open_source_tool_registry` which contains some extra open-source tools that are released as part of the Portia SDK.
As seen above, you can combine multiple registries by adding them together,
in the same way as you might combine two Python lists.
(Sometimes tool registries _are_ simply a list of Portia `Tool` objects.)

Finally, let's look at the code that executes the task.
It's slightly different from before:

<!-- Don't send the email in our tests. This won't be shown on the website
```python id=tour_code_invisible_1
task2 = (
   "Research the price of gold in the last 30 days."
)
```
-->
```python id=tour_code_7 depends_on=tour_code_5,tour_code_6,tour_code_invisible_1
plan = portia.plan(task2)
print(plan.pretty_print())

plan_run = portia.run_plan(plan, end_user="its me, mario")
```

Note that this time, instead of calling `portia.run` to plan and execute in a single step,
the code calls `portia.plan`, and then the plan
(after being printed)
is executed with `run_plan`.
Separating out these steps is useful in the case when you would like to validate the plan before it's run,
or even refine the plan before executing.

Note, also, the `end_user` parameter that is passed to `run_plan`.
You can also provide this variable to Portia's `run` method,
if you are planning and executing in a single step.
The `end_user` parameter, as a string, identifies the end-user driving the agent's actions.
It should be a string that uniquely identifies a particular user,
and will be used within the Portia cloud to look up any stored credentials.
This means that if you called `run_plan(end_user="end_user_123")`,
and the user authenticated against the Google API,
future runs of the agent will be authenticated and executed as that user.
When providing an identifier like this,
you should use a value that you can map back to a user session on your own system.
(Don't use "it's me, mario"!)

Here:

* A user is explicitly declared.
* The agent is equipped with tools that allow it to search the web and send emails.
* The instruction combines multiple actions: fetch data, generate a message, and send it.

This example shows how Portia agents can become personalized assistants that combine tool outputs into LLM-generated messages.

---

## 3. Model Context Protocol (MCP)

**File**: [`3_mcp.py` ↗](https://github.com/portiaAI/portia-agent-examples/blob/main/getting-started/3_mcp.py)

### Key concepts

* Setting up an MCP tool registry.
* Configuring Portia to use an MCP tool registry.
* Viewing the final output of a run.

### Code walkthrough

The third example introduces the [Model Context Protocol (MCP) ↗](https://modelcontextprotocol.io/introduction).
At the time of writing, MCP is all-the-rage among the cool kids!
This is a protocol that allows agents to interact with remote tool registries.
Many companies are now providing MCP services alongside their more traditional APIs.
In some cases, including the example below,
the MCP server is a local process that is run directly by the Python code.

Portia supports MCP through the `MCPToolRegistry` class,
which you'll see below.

Here's the task that the example code will execute:

```python id=tour_code_8
task = "Read the portialabs.ai website and tell me what they do"
```

In order to complete this task, a tool will be needed to fetch a web page.
Fortunately, there's an MCP tool to do just that!
The [mcp-server-fetch ↗](https://github.com/modelcontextprotocol/servers/tree/main/src/fetch) tool is an MCP server that can be run as a local Python process.
If you were executing it directly from the shell, you could download and run it by calling

```bash
# Don't actually run this:
uvx mcp-server-fetch
```

UVX is provided as part of [UV ↗](https://github.com/astral-sh/uv) and will automatically download and run an executable Python package.
It's also super-fast!

We configured an `MCPToolRegistry` that will run this server with the following code:

```python id=tour_code_9
from portia import McpToolRegistry
registry = McpToolRegistry.from_stdio_connection(
   server_name="fetch",
   command="uvx",
   args=["mcp-server-fetch"],
)
```

This will execute the underlying shell command, _and_ return a `ToolRegistry` object that will allow Portia to call it.

```python id=tour_code_10 depends_on=tour_code_3,tour_code_9
portia = Portia(
   config=my_config,
   tools=registry,
   execution_hooks=CLIExecutionHooks(),
)
```

If you were running this task as part of a larger application,
your Python code would require access to the end-result of the agent's research.
This can be found in the `PlanRun.outputs.final_output` attribute,
as shown in the last line of code:

```python id=tour_code_11 depends_on=tour_code_8,tour_code_10
print(portia.run(task).outputs.final_output)
```

---

## 4. Browser automation

**File**: [`4_browser_use.py` ↗](https://github.com/portiaAI/portia-agent-examples/blob/main/getting-started/4_browser_use.py)

### Key concepts

* Use of local browser automation
* Use of Browserbase (remote browser-as-a-service)
* Extraction of real-world data from websites

### Code walkthrough

This final example introduces browser-based automation, showing how Portia can automate interactions in real browsers – especially useful when no API is available.
This is a particularly powerful feature when used with websites that require authentication.
Portia is capable of opening a local browser session to allow the user to authenticate.
After successful authentication,
the new browser session details are sent to Browserbase,
where they can then be used remotely to drive the browser,
still authenticated as the local user.
It's important to note that at no point are user credentials shared with Portia!

As with the other examples, let start by looking at the task we wish the agent to complete:

```python id=tour_code_12
task = (
   "Find my connections called 'Bob' on LinkedIn (https://www.linkedin.com)"
)
```

This task doesn't just require the ability to fetch a web page,
like the previous example did.
Instead, it needs the user to log into LinkedIn,
so that the agent can drive the browser as the logged-in user.

```python id=tour_code_13
from portia.open_source_tools.browser_tool import BrowserTool, BrowserInfrastructureOption
# Change `infrastructure_option` to `BrowserInfrastructureOption.REMOTE` to use Browserbase
# instead of local Chrome.
browser_tool = BrowserTool(
    infrastructure_option=BrowserInfrastructureOption.LOCAL
)
```

The code above defines a local browser tool.
If (as here), `infrastructure_option`, is set to `BrowserInfrastructureOption.LOCAL`, then the tool will run Chrome locally, with no remote browser component.
If the argument is set to `BrowserInfrastructureOption.REMOTE` then it will use the remote [Browserbase ↗](https://www.browserbase.com/) service.
In production you'd want to use the Browserbase tool,
but that does require a paid account.
So for running this example locally,
we recommend that you run using the local browser tool.

```python id=tour_code_14 depends_on=tour_code_3,tour_code_12,tour_code_13
portia = Portia(
   config=my_config,
   tools=[browser_tool],
)

plan_run = portia.run(task)
```

### Running this example

When running this example, it's important to fully shut down any version of Chrome you have running.
The local browser tool needs to start up Chrome with various debugging flags enabled,
as these allow the LLM to drive the browser.

Run the tool with:

```sh
uv run 4_browser_use.py
```

After the planning stage,
you should see a browser start up.
It should navigate to the LinkedIn log in page,
and then pause, allowing you to log into your LinkedIn account.
Once you have logged in,
return to the command-line and follow the instructions to continue.
The agent should then control the browser,
identifying the search box at the top of the screen,
and then using it to locate all your connections called "Bob".
(If you don't have any connections called Bob,
maybe change the task so that it looks up a name you know is in your LinkedIn connection list.)

In this example:

* The agent is capable of using either local or remote browser automation.
* It allows the user to log into LinkedIn,
 navigates the interface,
 and extracts relevant connections.

This highlights Portia's flexibility when building agents that must operate outside the bounds of standard APIs.

### Before moving on

Check out the following video,
showing this feature in action,
with an even more complex and powerful use-case.

<iframe width="560" height="315" src="https://www.youtube.com/embed/hSq8Ww-hagg?si=MEae99Z8n-3X_9Fd" title="Build an AI browser agent to manage LinkedIn connections, with Portia AI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---

## Summary table

| Example File                | Focus             | Features Introduced                      |
| --------------------------- | ----------------- | ---------------------------------------- |
| `1_github_oauth.py`         | OAuth API use     | OAuth, basic agent commands              |
| `2_tools_end_users_llms.py` | Multi-tool agent  | End users, multi-step reasoning          |
| `3_mcp.py`                  | Running MCP Tools | MCP format, structured execution         |
| `4_browser_use.py`          | Web automation    | Browser automation, local & remote modes |

These examples form a practical foundation for building agents with Portia.
Look out for tutorials that take these concepts even further, with some sample web applications, integrating with popular frameworks.

We have more tutorials on our [blog ↗](https://blog.portialabs.ai/),
or check out our [GitHub repository ↗](https://github.com/portiaAI/portia-sdk-python).
</file>

<file path="docs/product/Get started/index.mdx">
---
title: ""
slug: /
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import DocCardList from '@theme/DocCardList';
import { CardLayout } from '@theme/DocCard';
import { useColorMode } from '@docusaurus/theme-common';

export const Logo = ({ lightSrc = '/img/logo_light.png', darkSrc = '/img/logo_dark.png', width, altText }) => {
  const { colorMode } = useColorMode();
  const logoSrc = colorMode === 'dark' ? darkSrc : lightSrc;
  return <img src={logoSrc} alt="{altText}" style={{ width: width || 'auto' }} />;
};

<p align="center">
    <Logo 
      lightSrc="/img/Logo_Portia_Symbol_Black.png"
      darkSrc="/img/Logo_Portia_Symbol_White.png"
      altText="Portia AI logo" 
      width="200px"
    />
</p>

<h1>Welcome to our docs!</h1>
Portia AI is an open source developer framework. We want to allow any developer to deploy agents that are transparent, steerable and authenticated.
<br/>Try out our product and give us some feedback on our <a href="https://discord.gg/DvAJz9ffaR" target="_blank">**Discord channel (↗)**</a>.<br/>

## Overview of Portia AI
The core product accessible in our <a href="https://github.com/portiaAI/portia-sdk-python" target="_blank">**Github repository (↗)**</a> 
is extensible with our complimentary cloud features which are aimed at making production deployments easier and faster.

With our open source capabilities you should be able to:
- Ingest a user query and leverage our system prompting to generate a structured plan.
- Run a plan, invoking tools and tracking the plan run state at every step.
- Build your own tools.
- Define clarifications to interrupt a plan run and solicit structured human / machine input when necessary, e.g. to handle required authentication or missing input.

Our cloud offering, which can be enabled from the <a href="https://app.portialabs.ai" target="_blank">**Portia dashboard (↗)**</a> 
works seamlessly with our open source library. It will give you the ability to:
- Store and retrieve plan run states and review historical plan runs.
- Invoke tools from remote MCP servers and other cloud-hosted applications, with authentication handled for you.
- Access the tool call logs of your plan runs.

<p align="center">
    <Logo 
      lightSrc="/img/portia_architecture.png"
      darkSrc="/img/portia_architecture_dark.png"
      altText="Portia AI architecture" 
      width="800px"
    />
</p>

## Why Portia AI
We are beginning our journey as a developer framework by focusing on this problem set. Shout if you think we should add to this list :pray:

<table style={{ width: "100%", borderCollapse: "collapse" }}>
  <thead>
    <tr>
      <th style={{ width: "50%", verticalAlign: "top", padding: "8px", fontSize: "16px" }}>**Problem**</th>
      <th style={{ width: "50%", verticalAlign: "top", padding: "8px", fontSize: "16px" }}>**Portia's solution**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Planning:</strong> Many use cases require visibility into the LLM’s reasoning, 
        particularly for complex tasks requiring multiple steps and tools. 
        LLMs also struggle picking the right tools as their tool set grows.
      </td>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Pre-expressed plans:</strong> Our open source, multi-shot prompter guides your LLM to 
        produce an explicit <a href="https://docs.portialabs.ai/generate-plan">Plan</a> in response to a prompt, 
        weaving the relevant tools, inputs, and outputs for every step.
      </td>
    </tr>
    <tr>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Execution:</strong> Tracking an LLM’s progress mid-task is difficult, making it 
        harder to intervene when guidance is needed. This is especially critical for enforcing 
        company policies or correcting hallucinations (hello, missing arguments in tool calls!)
      </td>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Stateful, steerable agents:</strong> Portia will spin up a multi-agent
        plan to execute and track its state throughout execution via a 
        [`PlanRun`](https://docs.portialabs.ai/run-plan). Using our 
        [`Clarification`](https://docs.portialabs.ai/understand-clarifications) abstraction you can 
        define points where you want to take control of plan runs e.g. to resolve missing 
        information or multiple choice decisions. Portia serialises the plan run state, and you can 
        manage its storage / retrieval yourself or use our cloud offering for simplicity.
      </td>
    </tr>
    <tr>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Authentication:</strong> Existing solutions often disrupt the user experience 
        with cumbersome authentication flows or require pre-emptive, full access to every tool—an 
        approach that doesn’t scale for multi-agent assistants. 
      </td>
      <td style={{ width: "50%", verticalAlign: "top", padding: "8px" }}>
        <strong>Extensible, authenticated tool calling:</strong> Bring your own tools on our 
        extensible [`Tool`](https://docs.portialabs.ai/intro-to-tools) abstraction, or use 
        our growing plug and play authenticated 
        [tool library](https://docs.portialabs.ai/run-portia-tools), which will include a number of 
        popular SaaS providers over time (Google, Zendesk, Hubspot, Github etc.). All Portia tools 
        feature just-in-time authentication with token refresh, offering security without 
        compromising on user experience.
      </td>
    </tr>
  </tbody>
</table>

Alright let's roll our sleeves up and get you spinning up them agents :robot:! Next up we'll install 
the SDK locally and validate your setup, before creating a Portia cloud account.

<details open style={{
  backgroundColor: "rgba(128, 0, 128, 0.1)",
  borderLeft: "5px solid purple",
  padding: "10px",
  borderRadius: "5px",
  margin: "10px 0"
}}>
  <summary style={{ color: "5D3FD3", fontWeight: "bold", cursor: "pointer" }}>
    🎉 I'm feeling lucky
  </summary>
  <p>If you prefer to just dive right into an example, why not head over to the intro example in our <a href="https://github.com/portiaAI/portia-agent-examples/blob/main/get_started_google_tools/README.md" target="_blank">**examples repo (↗)**</a>.</p>
</details>

## Setup and configuration

<div style={{ display: "flex", flexWrap: "nowrap", overflow: "visible", gap: "16px", width: "100%" }}>
    <div style={{ width: "33%" }}>
      <CardLayout
        href="/install"
        icon=""
        title="Install and setup"
        description="Get setup and run a query."
      />
    </div>
    <div style={{ width: "34%" }}>
      <CardLayout
        href="/setup-account"
        icon=""
        title="Set up a Portia account"
        description="Sign up for a Portia cloud account."
      />
    </div>
    <div style={{ width: "33%" }}>
      <CardLayout
        href="/manage-config"
        icon=""
        title="Manage your config"
        description="Learn how to configure your Portia." 
      />
    </div>
</div>
</file>

<file path="docs/product/Get started/install.md">
---
sidebar_position: 3
slug: /install
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Install and setup
Let's get you set up and run a test query to make sure everything is in order.

:::info[Requirements]
Portia requires **python v3.11 and above**. If you need to update your python version please visit their [docs](https://python.org/downloads/). If you are unsure what python version you have, you can check using
```bash
python3 --version
```
:::

### Install the Portia Python SDK
Run the following command to install our SDK and its dependencies. The command below assumes you're using **pip** as your installer. For poetry the install command would be `poetry add ...` and for uv it's `uv add ...`. The args otherwise remain the same.

```bash
pip install portia-sdk-python
```
Out of the box the SDK comes with dependencies for OpenAI (and Azure OpenAI) + Anthropic. We additionally support Amazon Bedrock, Mistral and Google GenAI (Gemini). These dependencies can be added with:
```bash
pip install "portia-sdk-python[all]"
# Or only with Amazon Bedrock extra dependencies
pip install "portia-sdk-python[amazon]"
# Or only with Google GenAI extra dependencies
pip install "portia-sdk-python[google]"
# Or only with Mistral extra dependencies
pip install "portia-sdk-python[mistral]"
```

### Configure access to your preferred LLM
Set environment variables to connect to one of our currently supported LLMs. We are currently expanding this list. See <a href="/manage-config#configure-llm-options" target="_blank">**Configure LLM options ↗**</a> for more information on how to configure Portia for different LLM providers and models.

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
    `gpt-4.1` is set as the default model. You can sign up to their platform **[here](https://platform.openai.com/signup)**
    ```bash
    export OPENAI_API_KEY='your-api-key-here'
    ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
    `sonnet-3.7` and `sonnet-3.5 are both used by default. You can sign up to their platform **[here](https://www.anthropic.com/api)**
    ```bash
    export ANTHROPIC_API_KEY='your-api-key-here'
    ```
    </TabItem>
    <TabItem value="mistral" label="Mistral">
    `mistral-large-latest` is set as the default model. You can sign up to their platform **[here](https://auth.mistral.ai/ui/registration)**

    Ensure Mistral dependencies are installed with `pip install "portia-sdk-python[mistral]"` or `"portia-sdk-python[all]"`

    ```bash
    export MISTRAL_API_KEY='your-api-key-here'
    ```
    </TabItem>
    <TabItem value="google" label="Google GenAI">
    `gemini-2.5-pro` and `gemini-2.5-flash` are both used by default. You can sign up to their platform **[here](https://ai.google.dev/)**

    Ensure Google GenAI dependencies are installed with `pip install "portia-sdk-python[google]"` or `"portia-sdk-python[all]"`

    ```bash
    export GOOGLE_API_KEY='your-api-key-here'
    ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
    `gpt-4.1` is set as the default model. You can sign up to their platform **[here](https://azure.microsoft.com/en-us/products/ai-services/openai-service)**

    ```bash
    export AZURE_OPENAI_API_KEY='your-api-key-here'
    export AZURE_OPENAI_ENDPOINT='your-api-key-here'
    ```
    </TabItem>
    <TabItem value="amazon" label="Amazon Bedrock">
    `eu.anthropic.claude-3-7-sonnet-20250219-v1:0` is set as the default model. You can sign up to their platform **[here](https://aws.amazon.com/bedrock/)**

    Ensure Amazon dependencies are installed with `pip install "portia-sdk-python[amazon]"` or `"portia-sdk-python[all]"`

    ```bash
    export AWS_ACCESS_KEY_ID = 'your-access-key-id'
    export AWS_SECRET_ACCESS_KEY = 'your-secret-access-key'
    export AWS_DEFAULT_REGION = 'your-default-region'
    # OR if you want using you ~/.aws/credentials
    export AWS_CREDENTIALS_PROFILE_NAME = 'your-credentials-profile-name'
    ```
    </TabItem>

</Tabs>

### Test your installation from the command line
Let's submit a basic prompt to your LLM using our framework to make sure it's all working fine. We will submit a simple maths question, which should invoke one of the open source tools in our SDK:

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
    Open AI is the default LLM provider. Just run:
    ```bash
    portia-cli run "add 1 + 2"
    ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
    To use Anthropic from the CLI, just run:
    ```bash
    portia-cli run --llm-provider="anthropic" "add 1 + 2"
    ```
    </TabItem>
    <TabItem value="mistral" label="Mistral">
    To use Mistral from the CLI, just run:
    ```bash
    portia-cli run --llm-provider="mistralai" "add 1 + 2"
    ```
    </TabItem>
    <TabItem value="google" label="Google GenAI">
    To use Google GenAI from the CLI, just run:
    ```bash
    portia-cli run --llm-provider="google" "add 1 + 2"
    ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
    To use Azure OpenAI from the CLI, just run:
    ```bash
    portia-cli run --llm-provider="azure-openai" "add 1 + 2"
    ```
    </TabItem>
    <TabItem value="amazon" label="Amazon Bedrock">
    To use Amazon Bedrock models from the CLI, just run:
    ```bash
    portia-cli run --llm-provider="amazon" "add 1 + 2"
    ```
    </TabItem>
</Tabs>

:::warning[Are you stuck? Try this 😅]
Remember to use the **command specific to your installer**. The instructions above are for **pip** specifically. For other installers use one of the commands below (args don't change):
* For poetry, the run command is `poetry run portia-cli ...`.
* For uv, the run command is `uv run portia-cli ...`.

Make sure you're in the **right directory or venv** as well (where your lock file is)!
:::

Portia will return the final state of the plan run created in response to the submitted prompt. We will delve into plan run states more deeply in a later section but for now you want to be sure you can see `"state": "COMPLETE"` and the answer to your maths question e.g. `"final_output": {"value": 3.0}` as part of that returned state. Here's an example output:
```bash
{
    "id": "prun-13a97e70-2ca6-41c9-bc49-b7f84f6d3982",
    "plan_id": "plan-96693022-598e-458c-8d2f-44ba51d4f0b5",
    "current_step_index": 0,
    "clarifications": [],
    # highlight-next-line
    "state": "COMPLETE",
    "step_outputs": {
        "$result": {
            "value": 3.0
        }
    },
    # highlight-start
    "final_output": {
        "value": 3.0
    }
    # highlight-end
}
```

### Test your installation from a Python file
As a final verification step for your installation, set up the required environment variables in the `.env` of a project directory of your choice, namely the relevant LLM API keys. We can now replicate the CLI-driven test above from a python file within that directory.

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
        In your local `.env` file, set up your API key as an environment variable using `OPENAI_API_KEY`.<br/>
        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        from dotenv import load_dotenv
        from portia import (
            Portia,
            default_config,
            example_tool_registry,
        )

        load_dotenv()

        # Instantiate Portia with the default config which uses Open AI, and with some example tools.
        portia = Portia(tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
        In your local `.env` file, set up your API key as an environment variable using `ANTHROPIC_API_KEY`.<br/>
        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        import os
        from dotenv import load_dotenv
        from portia import (
            Config,
            LLMProvider,
            Portia,
            example_tool_registry,
        )

        load_dotenv()
        ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')

        # Create a default Portia config with LLM provider set to Anthropic and to the Sonnet 3.5 model
        anthropic_config = Config.from_default(
            llm_provider=LLMProvider.ANTHROPIC,
            default_model="anthropic/claude-3-5-sonnet-latest",
            anthropic_api_key=ANTHROPIC_API_KEY
        )
        # Instantiate a Portia instance. Load it with the config and with the example tools.
        portia = Portia(config=anthropic_config, tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
    <TabItem value="mistral" label="Mistral">
        In your local `.env` file, set up your API key as an environment variable using `MISTRAL_API_KEY`.<br/>
        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        import os
        from dotenv import load_dotenv
        from portia import (
            Config,
            LLMProvider,
            Portia,
            example_tool_registry,
        )

        load_dotenv()
        MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')

        # Create a default Portia config with LLM provider set to Mistral AI and the latest Mistral Large model
        mistral_config = Config.from_default(
            llm_provider=LLMProvider.MISTRALAI,
            default_model="mistralai/mistral-large-latest",
            mistralai_api_key=MISTRAL_API_KEY
        )
        # Instantiate a Portia instance. Load it with the config and with the example tools.
        portia = Portia(config=mistral_config, tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
    <TabItem value="google" label="Google GenAI">
        In your local `.env` file, set up your API key as an environment variable using `GOOGLE_API_KEY`.<br/>
        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        import os
        from dotenv import load_dotenv
        from portia import (
            Config,
            LLMProvider,
            Portia,
            example_tool_registry,
        )

        load_dotenv()
        GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

        # Create a default Portia config with LLM provider set to Google GenAI and model set to Gemini 2.0 Flash
        google_config = Config.from_default(
            llm_provider=LLMProvider.GOOGLE,
            default_model="google/gemini-2.0-flash",
            google_api_key=GOOGLE_API_KEY
        )
        # Instantiate a Portia instance. Load it with the config and with the example tools.
        portia = Portia(config=google_config, tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
        <TabItem value="amazon" label="Amazon Bedrock">
        In your local `.env` file, set up your API key as an environment variable using `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_DEFAULT_REGION`. 
        You can also use the local aws credentials file e.g. `~/.aws/credentials` by just specifying the `aws_credentials_profile_name` parameter.  <br/>

        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        import os
        from dotenv import load_dotenv
        from portia import (
            Config,
            LLMProvider,
            Portia,
            example_tool_registry,
        )

        load_dotenv()
        AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
        AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')
        AWS_DEFAULT_REGION = os.getenv('AWS_DEFAULT_REGION')

        # Create a default Portia config ussing aws access keys with LLM provider set to AMAZON and model set to anthropic within Bedrock (make sure you enable the model in your Bedrock model access settings).
        amazon_config = Config.from_default(
            llm_provider=LLMProvider.AMAZON,
            default_model="amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0",
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            aws_default_region=AWS_DEFAULT_REGION,
        )
        # Config using the aws_credentials_profile_name, if you're using ~/.aws/credentials (generated by `aws configure`).
        AWS_CREDENTIALS_PROFILE_NAME = os.getenv('AWS_CREDENTIALS_PROFILE_NAME') | "default"
        amazon_config2 = Config.from_default(
            llm_provider=LLMProvider.AMAZON,
            default_model="amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0",
            aws_credentials_profile_name=AWS_CREDENTIALS_PROFILE_NAME,
        )
        portia = Portia(config=amazon_config, tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
        In your local `.env` file, set up your API key and API endpoint as environment variables using `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT`.<br/>
        Then create a file e.g. `main.py` in your project directory and paste the following code in.
        ```python title="main.py"
        import os
        from dotenv import load_dotenv
        from portia import (
            Config,
            LLMProvider,
            Portia,
            example_tool_registry,
        )

        load_dotenv()
        AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')
        AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')

        # Create a default Portia config with LLM provider set to Azure OpenAI and model to GPT 4o
        azure_config = Config.from_default(
            llm_provider=LLMProvider.AZURE_OPENAI,
            default_model="azure-openai/gpt-4o",
            azure_openai_api_key=AZURE_OPENAI_API_KEY,
            azure_openai_endpoint=AZURE_OPENAI_ENDPOINT,
        )
        # Instantiate a Portia instance. Load it with the config and with the example tools.
        portia = Portia(config=azure_config, tools=example_tool_registry)
        # Run the test query and print the output!
        plan_run = portia.run('add 1 + 2')
        print(plan_run.model_dump_json(indent=2))
        ```
    </TabItem>
</Tabs>


You should see a similar output to the the CLI-driven test we ran in step 4.

We will review the various elements in `main.py` in more detail in later sections. For now you should remember that:
- You will use a `Portia` instance to handle user prompts.
- A `Portia` instance expects a `Config`. This is where you can specify things like the model you want to use and where you want to store plan runs.
- A `Portia` instance also expects `tools`. This can be a list of tools, or a `ToolRegistry` (i.e a collection of tools you want to use).

If you got this far then we're off to the races :racehorse:. Let's get you set up with a Portia account so you can also use our cloud features. 
Don't worry it comes with a free trial (<a href="https://www.portialabs.ai/pricing" target="_blank">**Pricing page ↗**</a>) :wink:
</file>

<file path="docs/product/Get started/Manage config options.md">
---
sidebar_position: 5
slug: /manage-config
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Manage your config
Learn how to use your `Portia` instance's `Config` to configure LLM and agent execution options, and select different plan and plan run storage options.

:::tip[TL;DR]
The `Config` class of your `Portia` instance allows you to:
- Configure your LLM provider, model and API key
- Save plans and runs to disk or the Portia cloud
- Manage logging behaviour
:::

## Configure LLM options
The `Config` class (<a href="/SDK/portia/config" target="_blank">**SDK reference ↗**</a>) allows you to control various LLM and agent execution options.

### LLM provider

Portia uses providers such as OpenAI and Anthropic for usage of generative AI models. You can configure the provider that Portia will use with the `llm_provider` config setting.

If set, this decides which generative AI models are used in Portia defined Agents and Tools. Portia has built-in defaults for which models to use for each provider, so at a minimum you only need to set this property.

Options for setting the LLM provider are:

| Option | Values |
| - | - |
| `LLMProvider` enum | `LLMProvider.OPENAI`<br/>`LLMProvider.ANTHROPIC`<br/>`LLMProvider.MISTRALAI`<br/>`LLMProvider.GOOGLE`<br/>`LLMProvider.AZURE_OPENAI`<br/>`LLMProvider.OLLAMA` <br/>`LLMProvider.AMAZON`|
| Provider name (`str`) | `"openai"`<br/>`"anthropic"`<br/>`"mistralai"`<br/>`"google"`<br/>`"azure-openai"`<br/>`"ollama"`<br/>`"amazon"` |
| Inferred from environment variable | `OPENAI_API_KEY`<br/>`ANTHROPIC_API_KEY`<br/>`MISTRAL_API_KEY`<br/>`GOOGLE_API_KEY`<br/>`AZURE_OPENAI_API_KEY`<br/>`AWS_ACCESS_KEY_ID`<br/>`AWS_SECRET_KEY_ID`<br/>`AWS_DEFAULT_REGION`<br/>`AWS_CREDENTIALS_PROFILE_NAME` |


#### Examples:

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.OPENAI)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="anthropic")
        ```

        Inferred from environment variables (if `OPENAI_API_KEY=sk-...` is in the environment variables):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.OPENAI
        ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.ANTHROPIC)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="anthropic")
        ```

        Inferred from environment variables (if `ANTHROPIC_API_KEY=sk-...` is in the environment variables):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.ANTHROPIC
        ```
    </TabItem>
    <TabItem value="mistralai" label="Mistral AI">
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.MISTRALAI)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="mistralai")
        ```

        Inferred from environment variables (if `MISTRAL_API_KEY=sk-...` is in the environment variables):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.MISTRALAI
        ```
    </TabItem>
    <TabItem value="google" label="Google">
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.GOOGLE)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="google")
        ```

        Inferred from environment variables (if `GOOGLE_API_KEY=sk-...` is in the environment variables):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.GOOGLE
        ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.AZURE_OPENAI)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="azure-openai")
        ```

        Inferred from environment variables (if `AZURE_OPENAI_API_KEY=sk-...` _and_ `AZURE_OPENAI_ENDPOINT=https://...` are in the environment variables):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.AZURE_OPENAI
        ```
    </TabItem>
        <TabItem value="amazon" label="Amazon Bedrock">
        Using the `LLMProvider` enum:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider=LLMProvider.AMAZON)
        ```

        Passing the Provider name as a string value:
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default(llm_provider="amazon")
        ```

        Inferred from environment variables (if `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_DEFAULT_REGION` OR `AWS_CREDENTIALS_PROFILE_NAME`):
        ```python
        from portia import LLMProvider, Config

        config = Config.from_default()  # config.llm_provider => LLMProvider.AMAZON
        ```
    </TabItem>
</Tabs>

### API keys

The API keys for the LLM Providers can be set via `Config` class properties or environment variables.

| Option | Values |
| - | - |
| Config property | `openai_api_key`<br/>`anthropic_api_key`<br/>`mistralai_api_key`<br/>`google_api_key`<br/>`azure_openai_api_key` <br/>`aws_access_key_id`<br/>`aws_secret_key_id`<br/>`aws_default_region`<br/>`aws_credentials_profile_name`|
| Environment variable | `OPENAI_API_KEY`<br/>`ANTHROPIC_API_KEY`<br/>`MISTRAL_API_KEY`<br/>`GOOGLE_API_KEY`<br/>`AZURE_OPENAI_API_KEY`<br/>`AWS_ACCESS_KEY_ID`<br/>`AWS_SECRET_KEY_ID`<br/>`AWS_DEFAULT_REGION`<br/>`AWS_CREDENTIALS_PROFILE_NAME` |


#### Examples:
<Tabs groupId="llm-provider">
    <TabItem value="openai" label="OpenAI" default>
        Passing the API key to the `Config` class:
        ```python
        from portia import Config

        config = Config.from_default(openai_api_key="sk-...")
        ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
        Passing the API key to the `Config` class:
        ```python
        from portia import Config

        config = Config.from_default(anthropic_api_key="sk-...")
        ```
    </TabItem>
    <TabItem value="mistralai" label="Mistral AI">
        Passing the API key to the `Config` class:
        ```python
        from portia import Config

        config = Config.from_default(mistralai_api_key="sk-...")
        ```
    </TabItem>
    <TabItem value="google" label="Google">
        Passing the API key to the `Config` class:
        ```python
        from portia import Config

        config = Config.from_default(google_api_key="sk-...")
        ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
        Passing the API key to the `Config` class:
        ```python
        from portia import Config
        # NB You must also set the Azure OpenAI endpoint to your Azure OpenAI instance!
        config = Config.from_default(azure_openai_api_key="sk-...", azure_openai_endpoint="https://...")
        ```
    </TabItem>
    <TabItem value="amazon" label="Amazon Bedrock">
        Passing the API key to the `Config` class:
        ```python
        from portia import Config

        # NB You must provide (aws_access_key_id, aws_secret_access_key and aws_default_region) OR aws_credentials_profile_name.
        config = Config.from_default(aws_access_key_id='..', aws_secret_access_key='...', ..)
        ```
    </TabItem>
</Tabs>

### Model overrides

You can configure Portia to use specific models for different components, overriding the default model for the LLM provider.

You might do this if you want to:
- Trade off cost against performance, for example using a cheaper model for planning
- Extend Portia to support an LLM provider that we do not natively support
- Mix and match models from different providers, for example using OpenAI o3-mini for planning and Anthropic Claude 3.7 Sonnet for everything else

The preferred way to do this is via the `Config.from_default(...)` method, which allows you to specify the models using the following arguments:
- `default_model` - The fallback default model for all use-cases if not specified elsewhere
- `planning_model` - The model used for the Planning process
- `execution_model` - The model used for the execution of a step
- `introspection_model` - The model used for evaluating conditionals
- `summarizer_model` - The model used for summarizing the output of a step

You can configure each of these models in the following ways:

| Option | Value |
| - | - |
| Model name (`str`) | A `str` in the form `provider/model_name`, for example `openai/gpt-4.1`. See tip below for more examples. |
| Model object (`GenerativeModel`) | An instance of a `GenerativeModel` class. See the <u>[Bring your own models](#bring-your-own-models)</u> section below for more details. |

Alternatively, if setting the models directly in the `Config` class, you should use the `models` property, which is a `GenerativeModelsConfig` object (<a href="/SDK/portia/config#generativemodelsconfig-objects" target="_blank">**SDK reference ↗**</a>). See the example below for more details.

:::tip[Configuring models with model names]
Model strings are in the format `provider/model_name`, where the `provider` is the string value of the LLM provider (e.g. `openai`) and the `model_name` is the name of the model you want to use.<br/>
Examples:
- `openai/gpt-4.1`
- `anthropic/claude-3-5-sonnet`
- `mistralai/mistral-large-latest`
- `google/gemini-1.5-flash`
- `azure-openai/gpt-4o`
- `amazon/eu.anthropic.claude-3-7-sonnet-20250219-v1:0`
:::

#### Examples:

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="openai/gpt-4.1")
        ```        
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="anthropic/claude-3-5-sonnet-latest")
        ```
    </TabItem>
    <TabItem value="mistralai" label="Mistral AI">
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="mistralai/mistral-large-latest")
        ```
    </TabItem>
    <TabItem value="google" label="Google">
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="google/gemini-2.0-flash")
        ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="azure-openai/gpt-4o")
        ```
    </TabItem>
    <TabItem value="amazon" label="Amazon Bedrock">
        Setting the default model by its name:
        ```python
        from portia import Config

        config = Config.from_default(default_model="amazon/eu.anthropic.claude-3-7-sonnet-20250219-v1:0")
        ```
    </TabItem>
</Tabs>

Mixing and matching models from different providers. Make sure that the relevant API keys are set in the environment variables, or passed along with the model name:

```python
from portia import Config

config = Config.from_default(default_model="openai/gpt-4.1", planning_model="anthropic/claude-3-5-sonnet")
```

### Models for tools

A couple of the tools provided in the Portia SDK use generative models to complete tasks, specifically:

- `LLMTool` (<a href="/SDK/portia/open_source_tools/llm_tool" target="_blank">**SDK reference ↗**</a>)
- `ImageUnderstandingTool` (<a href="/SDK/portia/open_source_tools/image_understanding_tool" target="_blank">**SDK reference ↗**</a>)

You can replace the tool in the `DefaultToolRegistry` with your own instance of the tool that uses a different model by passing a `model` directly to the tool constructor:

<Tabs groupId="llm-provider">
    <TabItem value="openai" label="Open AI" default>
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="openai/gpt-4.1-mini")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
    <TabItem value="anthropic" label="Anthropic">
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="anthropic/claude-3-5-sonnet-latest")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
    <TabItem value="mistralai" label="Mistral AI">
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="mistralai/mistral-large-latest")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
    <TabItem value="google" label="Google">
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="google/gemini-2.0-flash")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
    <TabItem value="azure-openai" label="Azure OpenAI">
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="azure-openai/gpt-4o")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
    <TabItem value="amazon" label="Amazon Bedrock">
        ```python
        import dotenv
        from portia import Config, DefaultToolRegistry, LLMTool, Portia

        dotenv.load_dotenv()

        config = Config.from_default()

        tool_registry = DefaultToolRegistry(config).replace_tool(
            LLMTool(model="amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0")
        )

        portia = Portia(config=config, tools=tool_registry)
        ```
    </TabItem>
</Tabs>

:::tip[NB]
If you do not provide a model, the default model for the LLM provider will be used.
:::

### Bring your own models

You can bring your own models to Portia by implementing the `GenerativeModel` base class (<a href="/SDK/portia/model#generativemodel-objects" target="_blank">**SDK reference ↗**</a>) and passing an instance of your class to the `Config` class.

```python
from typing import TypeVar
from portia import Config, GenerativeModel, LLMProvider, Message
from pydantic import BaseModel
from langchain_core.language_models.chat_models import BaseChatModel

BaseModelT = TypeVar("BaseModelT", bound=BaseModel)

class MyGenerativeModel(GenerativeModel):
    provider: LLMProvider = LLMProvider.CUSTOM

    def get_response(self, messages: list[Message]) -> Message:
        """Requires implementation"""

    def get_structured_response(
        self,
        messages: list[Message],
        schema: type[BaseModelT],
    ) -> BaseModelT:
        """Requires implementation"""

    def to_langchain(self) -> BaseChatModel:
        """Requires implementation"""

config = Config.from_default(
    default_model=MyGenerativeModel("my-model-name")
)
```

In this case you do **not** need to set the `llm_provider` config setting, or provide any API keys.

:::tip[NB]
Currently Portia relies on LangChain `BaseChatModel` clients in several places, so we are limited to the models that LangChain supports.<br/>
Thankfully, this is a very <a href="https://python.langchain.com/docs/integrations/providers/" target="_blank">broad set of models</a>, so there is a good chance that your model of choice is supported.
:::


## Manage storage options
You can control where you store and retrieve plan run states using the `storage_class` property in the `Config` class (<a href="/SDK/portia/config" target="_blank">**SDK reference ↗**</a>), which is an ENUM accessible from the `StorageClass` class:
- `MEMORY` allows you to use working memory (default if PORTIA_API_KEY is not specified).
- `DISK` allows you to use local storage. You will need to set the `storage_dir` appropriately (defaults to .portia in the directory you are running Portia from).
- `CLOUD` uses the Portia cloud (<a href="/store-retrieve-plan-runs" target="_blank">**Use Portia cloud ↗**</a> - default if PORTIA_API_KEY is specified).

## Manage logging
You can control logging behaviour with the following `Config` properties (<a href="/SDK/portia/config" target="_blank">**SDK reference ↗**</a>):
| Property | Purpose |
| ----------- | ----------- |
| `default_log_level` | Controls the minimal log level, i.e. setting it to `DEBUG` will print all logs whereas setting it to `ERROR` will only display ERROR logs and above. This defaults to `INFO`. The ENUM is accessible via the `LogLevel` class |
| `default_log_sink` | Controls where logs are sent. By default this string is set to  `"sys.stdout"` (STDOUT) but can also be set to  `"sys.stderr"` (STDERR) or to a file by setting this to a file path e.g. `"./logs.txt"` |
| `json_log_serialize` | Sets whether logs are JSON serialized before sending them to the log sink. |


## Manage caching

| Property | Purpose |
| ----------- | ----------- |
| `llm_redis_cache_url` | You can specify a URL for a redis instance for the purposes of LLM caching using the llm_redis_cache_url property of your Portia client Config. This can also be set with the LLM_REDIS_CACHE_URL environment variable. If this is set, then we will hit this cache instance before any calls to LLMs. The URL should include any auth details that are needed for access to the redis including username/password e.g. redis://default:$PASSWORD@localhost:6379 |

## Bringing it all together
<details>
<summary>**Tavily API key required**</summary>

We will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (<a href="https://tavily.com/" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.
</details>

Let's test out a couple of these parameters. We will start first by loading the default config values within the `Config` class using the `from_default` method. This method uses the `default_config` within the `Config` class as the baseline and allows you to tweak specific attributes:
- We will explicitly save plans and runs to disk in a `demo_runs` directory. In the default config the `storage_class` is set to `MEMORY` so we will change it to `DISK`
- We will set the `default_log_level` to `DEBUG`, which will result in the generated plan, every change in the plan run state and all tool calls appearing in the logs.

```python title="main.py" test_containers=redis
from dotenv import load_dotenv
from portia import (
    Config,
    LogLevel,
    Portia,
    StorageClass,
)
from portia.open_source_tools.registry import example_tool_registry

load_dotenv()

# Load the default config with specified storage, logging and caching options
my_config = Config.from_default(
    storage_class=StorageClass.DISK, 
    storage_dir='demo_runs', # Amend this based on where you'd like your plans and plan runs saved!
    default_log_level=LogLevel.DEBUG,
    llm_redis_cache_url="redis://localhost:6379"
)

# Instantiate a Portia instance. Load it with the default config and with some example tools
portia = Portia(config=my_config, tools=example_tool_registry)

# Execute the plan run from the user query
output = portia.run('Which stock price grew faster in 2024, Amazon or Google?')

# Serialise into JSON and print the output
print(output.model_dump_json(indent=2))
```

In your `demo_runs` directory, you should now be able to see a plan and a plan run written to disk per the changes made to the `Config`.
<Tabs>
  <TabItem value="plan" label="Generated plan">
    ```json title="plan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e.json"
    {
        "id": "plan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e",
        "plan_context": {
            "query": "Which stock price grew faster in 2024, Amazon or Google?",
            "tool_ids": [
                "calculator_tool",
                "weather_tool",
                "search_tool"
            ]
        },
        "steps": [
            {
                "task": "Search for the stock price growth of Amazon in 2024.",
                "inputs": [],
                "tool_id": "search_tool",
                "output": "$amazon_stock_growth_2024"
            },
            {
                "task": "Search for the stock price growth of Google in 2024.",
                "inputs": [],
                "tool_id": "search_tool",
                "output": "$google_stock_growth_2024"
            },
            {
                "task": "Compare the stock price growth of Amazon and Google in 2024.",
                "inputs": [
                    {
                        "name": "$amazon_stock_growth_2024",
                        "description": "The stock price growth of Amazon in 2024."
                    },
                    {
                        "name": "$google_stock_growth_2024",
                        "description": "The stock price growth of Google in 2024."
                    }
                ],
                "tool_id": "llm_tool",
                "output": "$faster_growth"
            }
        ]
    }
    ```
  </TabItem>
    <TabItem value="plan run" label="Plan run in final state" default>
    ```json title="prun-e3a77013-2bd4-459c-898c-6a8cc9e77d12.json"
    {
        "id": "prun-e3a77013-2bd4-459c-898c-6a8cc9e77d12",
        "plan_id": "plan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e",
        "current_step_index": 2,
        "state": "COMPLETE",
        "outputs": {
            "clarifications": [],
            "step_outputs": {
                "$amazon_stock_growth_2024": {
                    "value": "In 2024, Amazon's stock price reached an all-time high closing price of $214.10 in November, having risen consistently since the start of 2023. Analysts remain optimistic, with many maintaining a 'Buy' rating and predicting further growth. By the end of 2024, Amazon's stock was expected to continue its upward trend, with projections varying but generally positive. The latest closing stock price as of November 14, 2024, was $211.48, just below the all-time high of $214.10.",
                    "summary": null
                },
                "$google_stock_growth_2024": {
                    "value": "As of today, January 23, 2025, Google's stock has experienced an 18% increase since the beginning of the year, starting at $139.56 and trading at $164.74. Analysts predict the stock price to reach $208 by the end of 2024, marking a year-on-year growth rate of 49.03%. The forecast for the end of 2024 is an estimated increase of 18.18% from today's price.",
                    "summary": null
                },
                "$faster_growth": {
                    "value": "In 2024, Amazon's stock price growth was positive, reaching an all-time high closing price of $214.10 in November. Google's stock price growth in 2024 was also strong, with a year-on-year growth rate of 49.03% and a forecasted increase of 18.18% by the end of the year.",
                    "summary": null
                }
            },
            "final_output": {
                "value": "In 2024, Amazon's stock price growth was positive, reaching an all-time high closing price of $214.10 in November. Google's stock price growth in 2024 was also strong, with a year-on-year growth rate of 49.03% and a forecasted increase of 18.18% by the end of the year.",
                "summary": null
            }
        }
    }
    ```
  </TabItem>
</Tabs>

Now let's start exploring the developer abstractions Portia offers in more detail!
</file>

<file path="docs/product/Get started/Set up your account.md">
---
sidebar_position: 4
slug: /setup-account
---

# Set up your Portia account
Set up your Portia cloud account. This will allow you to:
- Store and retrieve plan runs in the Portia cloud.
- Access our library of cloud hosted tools.
- Use the Portia dashboard to:
    - View your plan run history, unhandled clarifications, tool call logs.
    - Manage users, orgs and Portia API keys.

You first need to obtain a Portia API key. Head over to (<a href="https://app.portialabs.ai" target="_blank">**app.portialabs.ai ↗**</a>) and navigate to the `Manage API keys` tab from the left hand nav. There you can generate a new API key.
:::note[On org users]
You will notice a `Manage orgs and users` tab. You can set up multiple orgs in Portia. Users under the same org can all see each others' plan runs and tool call logs.
:::

By default, Portia will look for the API key in the `PORTIA_API_KEY` environment variable. You can choose to override it for a specific `Portia` instance instance by configuring the `portia_api_key` variable as well. For now let's simply set the environment variable with the key value you generated and proceed to the next section. You can use the command below but it's always preferable to set your API keys in a .env file ultimately.
```bash
export PORTIA_API_KEY='your-api-key-here'
``` 

:::tip[Upgrading your account]
You can upgrade your account to a Pro plan to increase your Portia tool and plan run usage limits. Head over to the <a href="https://app.portialabs.ai/dashboard/billing" target="_blank">**Billing page ↗**</a> to upgrade or manage your current plan.
:::
</file>

<file path="docs/product/Handle auth and clarifications/_category_.json">
{
  "label": "Handle auth and clarifications",
  "position": 3,
  "link": {
    "type": "generated-index",
    "slug": "handle-auth-clarifications",
    "description": "Understand the concept of clarifications. Learn how to handle Portia tool OAuth and how to define custom clarifications."
  }
}
</file>

<file path="docs/product/Handle auth and clarifications/Run Portia tools with authentication.md">
---
sidebar_position: 2
slug: /run-portia-tools
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Run Portia tools with authentication
Use clarifications to leverage Portia tools' native authentication support.

:::tip[TL;DR]
- All Portia tools come with built-in authentication, typically using Portia OAuth clients for each relevant resource server.
- At the start of a plan run containing Portia tools, `Portia` raises `ActionClarification`s to request user authorization for the subset of tools that require it.
:::

Portia offers a cloud-hosted library of tools to save you development time. You can find the ever-growing list of Portia tools in the next section (<a href="/portia-tools" target="_blank">**Portia tool catalogue ↗**</a>). All Portia tools come with plug and play authentication. Let's delve into how to handle the user authentication flow.

## Handling auth with `Clarification`

We established in the preceding section that clarifications are raised when an agent needs input to progress. This concept lends itself perfectly to tool authentication. Let's break it down:
- All Portia tools come with built-in authentication, typically using Portia OAuth clients for each relevant resource server.
- Portia provisions the required token with the relevant scope when a tool call needs to be made.
- Tokens provisioned by Portia have a user-configurable retention period (see more <a href="/security" target="_blank">**here ↗**</a>). The tokens are scoped to the `end_user` that was passed when running the plan or a default `end_user` if none was provided. You will need to reuse this `end_user_id` across plan runs to leverage token reusability (<a href="/manage-end-users" target="_blank">**Manage multiple end users ↗**</a>).
- When a plan is run, before we start executing the steps, we first check the readiness of all tools contained in the steps of the plan. For Portia tools supporting OAuth, readiness includes validating that we have an access token stored for the `end_user_id` provided. If no OAuth token is found, an `ActionClarification` is raised with an OAuth link as the action URL. This OAuth link uses the relevant Portia authentication client and a Portia redirect URL.
- Portia's OAuth server listens for the authentication result and resolves the concerned clarification, allowing the plan run to resume again.

:::info
Note that there may be multiple tools that require permissions from the same OAuth client. In this case, Portia will combine together the required scopes, reducing the number of `ActionClarification`s that need to be resolved.
:::

Optionally, you can configure a custom URL where users will be redirected after successful authentication. To do so, follow these steps:
1. Log into your Portia <a href="https://app.portialabs.ai" target="_blank">**dashboard ↗**</a>
2. Navigate to the **Manage Org** tab.
3. Enter the custom URL in 'Org Settings'. Ensure that the URL begins with either `https://` or `http://`.

## Bringing the concepts together

Now let's bring this to life by reproducing the experience that you can see on the website's playground (<a href="https://www.portialabs.ai" target="_blank">**↗**</a>). We want to be able to handle a prompt like `Find the github repository of Mastodon and give it a star for me`, so let's take a look at the code below.

<details>
<summary>**Portia API key required**</summary>

We're assuming you already have a Portia API key from the dashboard and set it in your environment variables. If not please refer to the previous section and do that first (<a href="/setup-account" target="_blank">**Set up your account ↗**</a>).

</details>

```python title="main.py"
from dotenv import load_dotenv
from portia import (
    ActionClarification,
    InputClarification,
    MultipleChoiceClarification,
    PlanRunState,
    Portia,
    PortiaToolRegistry,
    default_config,
)

load_dotenv()

# Instantiate a Portia instance. Load it with the default config and with Portia cloud tools above
portia = Portia(tools=PortiaToolRegistry(default_config()))

# Generate the plan from the user query and print it
plan = portia.plan('Find the github repository of PortiaAI and give it a star for me')
print(f"{plan.model_dump_json(indent=2)}")

# Run the plan
plan_run = portia.run_plan(plan)

while plan_run.state == PlanRunState.NEED_CLARIFICATION:
    # If clarifications are needed, resolve them before resuming the plan run
    for clarification in plan_run.get_outstanding_clarifications():
        # Usual handling of Input and Multiple Choice clarifications
        if isinstance(clarification, (InputClarification, MultipleChoiceClarification)):
            print(f"{clarification.user_guidance}")
            user_input = input("Please enter a value:\n" 
                            + (("\n".join(clarification.options) + "\n") if "options" in clarification else ""))
            plan_run = portia.resolve_clarification(clarification, user_input, plan_run)
        
        # Handling of Action clarifications
        # highlight-start
        if isinstance(clarification, ActionClarification):
            print(f"{clarification.user_guidance} -- Please click on the link below to proceed.")
            print(clarification.action_url)
            plan_run = portia.wait_for_ready(plan_run)
        # highlight-end

    # Once clarifications are resolved, resume the plan run
    plan_run = portia.resume(plan_run)

# Serialise into JSON and print the output
print(f"{plan_run.model_dump_json(indent=2)}")
```

Pay attention to the following points:
- We're importing all of Portia's cloud tool library using the `PortiaToolRegistry` import. Portia will (rightly!) identify that executing on this query necessitates both the `SearchGitHubReposTool` and the `StarGitHubRepoTool` in particular. Like all Portia cloud tools, our Github tools are built with plug and play authentication support. Before any steps are executed, Portia will raise an `Action Clarification` with a Github OAuth link as the action URL.
- We're now introducing the `portia.wait_for_ready()` method to handle clarifications of type `ActionClarification`. This method should be used when the resolution to a clarification relies on a third party system and your `Portia` instance needs to listen for a change in its state. In our example, Portia's OAuth server listens for the authentication result and resolves the concerned clarification, allowing the plan run to resume again.

Your plan run will pause and you should see the link in the logs like so
...
```bash
OAuth required -- Please click on the link below to proceed.
https://github.com/login/oauth/authorize/?redirect_uri=https%3A%2F%2Fapi.portialabs.ai%2Fapi%2Fv0%2Foauth%2Fgithub%2F&client_id=Ov23liXuuhY9MOePgG8Q&scope=public_repo+starring&state=APP_NAME%3Dgithub%253A%253Agithub%26PLAN_RUN_ID%3Daa6019e1-0bde-4d76-935d-b1a64707c64e%26ORG_ID%3Dbfc2c945-4c8a-4a02-847a-1672942e8fc9%26CLARIFICATION_ID%3D9e6b8842-dc39-40be-a298-900383dd5e9e%26SCOPES%3Dpublic_repo%2Bstarring&response_type=code
```

In your logs you should be able to see the tools, as well as a plan and final plan run state similar to the output below. Note again how the planner weaved tools from both the cloud and the example registry.

<Tabs>
  <TabItem value="plan" label="Generated plan">
    ```json title="plan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2.json"
    {
        "id": "plan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2",
        "plan_context": {
            "query": "Find the github repository of PortiaAI and give it a star for me",
            "tool_ids": [
            "portia::github::search_repos",
            "portia::github::star_repo",
            "portia::slack::send_message",
            "portia::zendesk::list_groups_for_user",
            ...
            ]
        },
        "steps": [
            {
                "task": "Search for the GitHub repository of PortiaAI",
                "inputs": [],
                "tool_id": "portia:github::search_repos",
                "output": "$portiaai_repository"
            },
            {
            "task": "Star the GitHub repository of PortiaAI",
            "inputs": [
                {
                    "name": "$portiaai_repository",
                    "description": "The GitHub repository of PortiaAI"
                }
            ],
            "tool_id": "portia:github::star_repo",
            "output": "$star_result"
            }
        ]
    }
    ```
  </TabItem>
    <TabItem value="plan run" label="Plan run in final state">
    ```json title="prun-36945fae-1dcc-4b05-9bc4-4b862748e031.json"
    {
        "id": "prun-36945fae-1dcc-4b05-9bc4-4b862748e031",
        "plan_id": "plan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2",
        "current_step_index": 1,
        "state": "COMPLETE",
        "outputs": {
            "clarifications": [
                {
                    "uuid": "clar-f873b9be-10ee-4184-a717-3a7559416499",
                    "category": “Multiple Choice”,
                    "response": “portiaAI/portia-sdk-python",
                    "step": 2, 
                    "user_guidance": "Please select a repository.", 
                    "handled": true,
                    "argument": "$portiaai_repository",
                    "options": "[\"portiaAI/portia-sdk-python\", \"portiaAI/docs\", \"portiaAI/portia-agent-examples\"]",
                }
            ],
            "step_outputs": {
            "$portiaai_repository": {
                "value": "[\"portiaAI/portia-sdk-python\", \"portiaAI/docs\", \"portiaAI/portia-agent-examples\"]",
                "summary": null
            },
            "$star_result": {
                "value": "Successfully starred the repository 'portiaAI/portia-sdk-python'.",
                "summary": null
            }
            },
            "final_output": {
            "value": "Successfully starred the repository 'portiaAI/portia-sdk-python'.",
            "summary": null
            }
        }
    }
    ```
  </TabItem>
</Tabs>

:::info
Now that you're familiar with running Portia tools, why not try your hand at the intro example in our <a href="https://github.com/portiaAI/portia-agent-examples/blob/main/get_started_google_tools/README.md" target="_blank">**examples repo (↗)**</a>. In the example ee use the Google Calendar tools to schedule a meeting and handle the authentication process to execute those tool calls.
:::
</file>

<file path="docs/product/Handle auth and clarifications/Understand clarifications.md">
---
sidebar_position: 1
slug: /understand-clarifications
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Understand clarifications
Define clarifications to bring structured input into a plan run.
Understand the different types of clarifications and how to use them.
:::tip[TL;DR]
- An agent can raise a clarification during a plan run to pause it and solicit human input. This pauses the plan run, serialises and saves its state at the step where clarification was raised.
- We represent a clarification with the `Clarification` class (<a href="/SDK/portia/clarification" target="_blank">**SDK reference ↗**</a>). This includes useful information such as guidance to be surfaced to the user when soliciting their input. Because it is a structured object, you can easily serve it to an end user using a front end of your choosing when it is encountered. 
- The user response is captured in the `Clarification` object itself, which is part of the `PlanRun` state. This means the plan run can be resumed, and the step at which the clarification was required can now be completed.
:::

## Intro to clarifications
Portia introduces the concept of clarifications. An agent can raise a clarification during a plan run to pause it and solicit human input. This is important because:
1. LLM-driven tasks that are multi-step can be brittle and unreliable e.g. if an input is missing the LLM may hallucinate it. Instead we allow you to pause Portia-managed plan run and raise a clarification to the user so they can resolve the missing input for the LLM.
2. During plan run, there may be tasks where your organisation's policies require explicit approvals from specific people e.g. allowing bank transfers over a certain amount. Clarifications allow you to define these conditions so the agent running a particular step knows when to pause the plan run and solicit input in line with your policies.
3. More advanced use cases of clarifications also include hand off to a different part of your system based on certain conditions having been met. The structured nature of clarifications make this handoff easy to manage.

When Portia encounters a clarification and pauses a plan run, it serialises and saves the latest plan run state. Once the clarification is resolved, the obtained human input captured during clarification handling is added to the plan run state and the agent can resume step execution.

![Clarifications at work](/img/clarifications_diagram.png)

## Types of clarifications
Clarifications are represented by the `Clarification` class (<a href="/SDK/portia/clarification" target="_blank">**SDK reference ↗**</a>). Because it is a structured object, you can easily serve it to an end user using a front end of your choosing when it is encountered e.g. a chatbot or app like Slack, email etc.

We offer five categories of clarifications at the moment. You can see the properties and behaviours specific to each type in the tabs below. The common properties across all clarifications are:
- `uuid`: Unique ID for this clarification
- `category`: The type of clarification
- `response`: User's response to the clarification
- `step`: Plan run step where this clarification was raised
- `user_guidance`: Guidance provided to the user to explain the nature of the clarification
- `resolved`: Boolean of the clarification state

<Tabs>
    <TabItem value="action_clar" label="Action clarifications" default>
    Action clarifications are useful when a user action is needed to complete a step e.g. clicking on an `action_url` to complete an authentication flow or to make a payment. You will need to have a way to receive a callback from such a flow in order to confirm whether the clarification was resolved successfully.
    ```json title="action_clarification.json"
    {
        "uuid": "clar-425c8ce9-8fc9-43af-b99e-64903043c5df",
        "plan_run_id": "prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258",
        "category": “Action”,
        "response": “success”,
        "step": 1,
        "user_guidance": "Click here to authenticate",
        "resolved": true,
        "action_url": “https://accounts.google.com/o/oauth2/…”,
    }
    ```
    </TabItem>
    <TabItem value="input_clar" label="Input clarifications" default>
    Input clarifications are used when a tool call is missing one argument and the user needs to provide it e.g. a `send_email` tool needs to be invoked but no email is resolvable from the user query. The `argument` attribute points to the tool argument this clarification resolves.
    ```json title="input_clarification.json"
    {
        "uuid": "clar-425c8ce9-8fc9-43af-b99e-64903043c5df",
        "plan_run_id": "prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258",
        "category": “Input”,
        "response": “avrana@kern.ai”,
        "step": 2, 
        "user_guidance": "Please provide me with Avrana's email address", 
        "resolved": true,
        "argument": "$avrana_email",
    }
    ```
    </TabItem>
    <TabItem value="multi_clar" label="Multiple choice clarifications" default>
    Multiple choice clarifications are raised when a tool argument is restricted to a list of values but the agent attempting to invoke the tool is given an argument that falls outside that list. The clarification can be used to serve the acceptable list of values for the user to choose from via the `options` attribute.
    ```json title="multiple_choice_clarification.json"
    {
        "uuid": "clar-425c8ce9-8fc9-43af-b99e-64903043c5df",
        "plan_run_id": "prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258",
        "category": “Multiple Choice”,
        "response": “ron_swanson@pawnee.com,
        "step": 2, 
        "user_guidance": "Please select a recipient.", 
        "resolved": true,
        "argument": "$recipient",
        "options": [
                "ron_swanson@pawnee.com",
                "ron_burgundy@kvwnchannel4.com",
                "ron@gone_wrong.com"
            ]
    }
    ```
    </TabItem>
    <TabItem value="value_conf" label="Value confirmation clarifications" default>
    Value confirmation clarifications are raised to get the user to confirm or deny if they want to proceed with a particular value. This is particularly useful for 'human in the loop' tasks where you want to get the user to confirm the value before proceeding.
    ```json title="value_confirmation_clarification.json"
    {
        "uuid": "clar-425c8ce9-8fc9-43af-b99e-64903043c5df",
        "plan_run_id": "prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258",
        "category": “Value Confirmation”,
        "step": 2, 
        "user_guidance": "This will email all contacts in your database. Are you sure you want to proceed?", 
        "resolved": true,
        "argument": "$email_all_contacts"
    }
    ```
    </TabItem>
    <TabItem value="custom_clar" label="Custom clarifications" default>
    Custom clarifications enable you to attach arbitrary information to a clarification.
    ```json title="custom_clarification.json"
    {
        "uuid": "clar-425c8ce9-8fc9-43af-b99e-64903043c5df",
        "plan_run_id": "prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258",
        "category": “Custom”,
        "step": 2, 
        "user_guidance": "Which product did you want to buy?", 
        "resolved": true,
        "data": {
            "product_id": "prod-1234567890"
        }
    }
    ```
    </TabItem>
</Tabs>

## Clarification triggers
Clarifications are raised in one of three scenarios:
1. LLM-triggered: During plan run, an agent attempting to complete a step notices that an input is missing, resulting in an Input clarification.
2. Tool-triggered: A clarification is explicitly raised in the python class definition of the tool in specific conditions e.g. if a requisite OAuth token is missing to complete the underlying API call or if a tool argument is invalid, resulting in Action or a Multiple Choice clarification respectively.
3. Starting or resuming a plan run: Before a plan run is started or resumed, the Portia runner checks the readiness of all tools mentioned in the plan. Clarifications are raised if any of the tools are not ready to be used. Portia tools use this mechanism to request user Authorization - see more details <a href="/run-portia-tools" target="_blank">**here ↗**</a>.

## Handle clarifications with your `Portia` instance
:::info[Make a `weather.txt` file for this section]
We're going to see how Portia handles multiple choices with clarifications. In this example we will import our open source tool `FileReaderTool` and ask it to open a non-existent local file `weather.txt`. This should trigger the tool to search for the file across the rest of the project directory and return all matches. Make sure to sprinkle a few copies of a `weather.txt` file around in the project directory. 
Note: Our `weather.txt` file contains "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C."
:::

When the conditions requiring a clarification are met, the relevant tool call returns a `Clarification` object, the plan run is paused and the plan run state becomes `NEED CLARIFICATION`. Portia has now passed control of the plan run to you, the developer, along with the `Clarification` object in order for you to resolve with human or machine input. At this stage we need to make some changes in the `main.py` file to handle clarifications.

```python title="main.py"
from portia import (
    InMemoryToolRegistry,
    # highlight-start
    MultipleChoiceClarification,
    # highlight-end
    Portia,
    # highlight-start
    PlanRunState,
    # highlight-end
    default_config,
)
from portia.open_source_tools.local_file_reader_tool import FileReaderTool
from portia.open_source_tools.local_file_writer_tool import FileWriterTool

# Load open source tools into a tool registry. More on tool registries later in the docs!
my_tool_registry = InMemoryToolRegistry.from_local_tools([FileReaderTool(), FileWriterTool()])
# Instantiate a Portia instance. Load it with the default config and with the tools above
portia = Portia(tools=my_tool_registry)

# Execute the plan from the user query
plan_run = portia.run('Read the contents of the file "weather.txt"')

# highlight-start
# Check if the plan run was paused due to raised clarifications
while plan_run.state == PlanRunState.NEED_CLARIFICATION:
    # If clarifications are needed, resolve them before resuming the plan run
    for clarification in plan_run.get_outstanding_clarifications():
        # For each clarification, prompt the user for input
        print(f"{clarification.user_guidance}")
        user_input = input("Please enter a value:\n" +
                               (("\n".join(clarification.options) + "\n") 
                                if isinstance(clarification, MultipleChoiceClarification)
                                else ""))
        # Resolve the clarification with the user input
        plan_run = portia.resolve_clarification(clarification, user_input, plan_run)

    # Once clarifications are resolved, resume the plan run
    plan_run = portia.resume(plan_run)
# highlight-end

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```
The keen eye may have noticed that we introduced the `InMemoryToolRegistry` class. Fear not, we will discuss tool registries in a later section. For now let's focus on the clarification handling sections highlighted in the code.
Remember to make sure you don't have a `weather.txt` file in the same folder as your python file AND make a few copies of a `weather.txt` file sprinkled around in other folders of the project directory. This will ensure that the prompt triggers the multiple choice clarifications on the `filename` argument of the `FileReaderTool`. The tool call will return a `Clarification` object per changes made in the previous section and pause the plan_run.<br/>

The changes you need to make to our `main.py` in order to enable this behaviour are as follows:
1. Check if the state of the `PlanRun` object returned by the `run` method is `PlanRunState.NEED_CLARIFICATION`. This means the plan run paused before completion due to a clarification.
2. Use the `get_outstanding_clarifications` method of the `PlanRun` object to access all clarifications where `resolved` is false.
3. For each `Clarification`, surface the `user_guidance` to the relevant user and collect their input.
4. Use the `portia.resolve_clarification` method to capture the user input in the `response` attribute of the relevant clarification. Because clarifications are part of the plan run state itself, this means that the plan run now captures the latest human input gathered and can be resumed with the new information.
5. Once this is done you can resume the plan run using the `resume` method. In fact `resume` can take a `PlanRun` in any state as a parameter and will kick off that plan run from that current state. In this particular example, it resumes the plan run from the step where the clarifications were encountered.

For the example query above `Read the contents of the file "weather.txt".`, where the user resolves the clarification by entering one of the options offered by the clarification (in this particular case `demo_runs/weather.txt` in our project directory `momo_sdk_tests`), you should see the following plan run state and notice:
- The multiple choice clarification where the `user_guidance` was generated by Portia based on your clarification definition in the `FileReaderTool` class,
- The `response` in the second plan run snapshot reflecting the user input, and the change in `resolved` to `true` as a result
- The plan run `state` will appear to `NEED_CLARIFICATION` if you look at the logs at the point when the clarification is raised. It then progresses to `COMPLETE` once you respond to the clarification and the plan run is able to resume:
```json title="run_state.json"
{
  "id": "prun-54d157fe-4b99-4dbb-a917-8fd8852df63d",
  "plan_id": "plan-b87de5ac-41d9-4722-8baa-8015327511db",
  "current_step_index": 0,
  "state": "COMPLETE",
  "outputs": {
    "clarifications": [
      {
        "id": "clar-216c13a1-8342-41ca-99e5-59394cbc7008",
        "category": "Multiple Choice",
        "response": "../momo_sdk_tests/demo_runs/weather.txt",
        "step": 0,
        "user_guidance": "Found weather.txt in these location(s). Pick one to continue:\n['../momo_sdk_tests/demo_runs/weather.txt', '../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt']",
        "resolved": true,
        "argument_name": "filename",
        "options": [
          "../momo_sdk_tests/demo_runs/weather.txt",
          "../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt"
        ]
      }
    ],
    "step_outputs": {
      "$file_contents": {
        "value": "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.",
        "summary": null
      }
    },
    "final_output": {
      "value": "The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.",
      "summary": null
    }
  }
}
```

## Handle clarifications with a `ClarificationHandler`

Through the above example, we explicitly handle the clarifications in order to demonstrate the full clarification handling flow.
However, Portia also offers a `ClarificationHandler` class that can be used to simplify the handling of clarifications.
In order to use this, simply create your own class that inherits from `ClarificationHandler` and implement the methods for
handling the types of clarifications you expect to handle. Each method takes an `on_resolution` and `on_error` parameter - 
these can be called either synchronously or asynchronously when the clarification handling is finished. This allows handling
clarifications in many different ways - for example, they could be handled by the user in a UI, or they could be handled in an
email or slack message.

Once you've created your clarifiication handler, it can be passed in as an execution hook when creating the Portia instance:

```python
from portia import Clarification, ClarificationHandler, Config, ExecutionHooks, InputClarification, Portia
from typing import Callable

class CLIClarificationHandler(ClarificationHandler):
    """Handles clarifications by obtaining user input from the CLI."""

    def handle_input_clarification(
        self,
        clarification: InputClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None],  # noqa: ARG002
    ) -> None:
        """Handle a user input clarifications by asking the user for input from the CLI."""
        user_input = input(f"{clarification.user_guidance}\nPlease enter a value:\n")
        on_resolution(clarification, user_input)

portia = Portia(execution_hooks=ExecutionHooks(clarification_handler=CLIClarificationHandler()))
```

Portia also offers some default clarification handling behaviours that can be used out of the box. For example, you don't actually need
to implement your own CLI clarification handler (as done above) because our default CLI execution hooks, `CLIExecutionHooks`, provide a 
clarification handler that allows the user to handle clarifications via the CLI.

```python
from portia import Config, Portia
from portia.cli import CLIExecutionHooks

portia = Portia(execution_hooks=CLIExecutionHooks())
```
</file>

<file path="docs/product/Plan and run workflows/_category_.json">
{
  "label": "Generate and run plans",
  "position": 2,
  "link": {
    "type": "generated-index",
    "slug": "generate-and-run-plans",
    "description": "Learn how to generate plans and run them with Portia AI."
  }
}
</file>

<file path="docs/product/Plan and run workflows/Build a plan.md">
---
sidebar_position: 2
slug: /build-plan
---

# Build a plan manually

:::tip[Alpha]
PlanBuilderV2 is currently in Alpha so please expect changes in this area and we'd love your feedback on our <a href="https://discord.gg/DvAJz9ffaR" target="_blank">**Discord channel (↗)**</a>!
:::

If you prefer to explicitly define a plan step by step rather than rely on our planning agent, e.g. for established processes in your business, you can use the `PlanBuilderV2` interface. This requires outlining all the steps, inputs, outputs and tools for your agent manually.

The `PlanBuilderV2` offers methods to create each part of the plan iteratively:
- `.llm_step()` adds a step that sends a query to the underlying LLM
- `.invoke_tool_step()` adds a step that directly invokes a tool. Requires mapping of step outputs to tool arguments.
- `.single_tool_agent_step()` is similar to `.invoke_tool_step()` but an LLM call is made to map the inputs to the step to what the tool requires creating flexibility.
- `.function_step()` is identical to `.invoke_tool_step()` but calls a Python function rather than a tool with an ID.
- `.if_()`, `.else_if_()`, `.else_()` and `.endif()` are used to add conditional branching to the plan.

## Example

```python title='plan_builder.py'
from portia.builder import PlanBuilderV2, StepOutput, Input

plan = (
    PlanBuilderV2("Write a poem about the price of gold")
    .input(name="purchase_quantity", description="The quantity of gold to purchase in ounces")
    .input(name="currency", description="The currency to purchase the gold in", default_value="GBP")
    .invoke_tool_step(
        step_name="Search gold price",
        tool="search_tool",
        args={
            "search_query": f"What is the price of gold per ounce in {Input('currency')}?",
        },
        output_schema=CommodityPriceWithCurrency,
    )
    .function_step(
        function=lambda price_with_currency, purchase_quantity: (
            price_with_currency.price * purchase_quantity
        ),
        args={
            "price_with_currency": StepOutput("Search gold price"),
            "purchase_quantity": Input("purchase_quantity"),
        },
    )
    .llm_step(
        task="Write a poem about the current price of gold",
        inputs=[StepOutput(0), Input("currency")],
    )
    .single_tool_agent_step(
        task="Send the poem to Robbie in an email at donotemail@portialabs.ai",
        tool="portia:google:gmail:send_email",
        inputs=[StepOutput(2)],
    )
    .final_output(
        output_schema=FinalOutput,
    )
    .build()
)

portia.run_plan(plan, plan_run_inputs={"country_name": "France"})
```

## Available Step Types

### LLM step
Use `.llm_step()` to add a step that directly queries the LLM tool:

```python
builder.llm_step(
    task="Analyze the given data and provide insights",
    inputs=[StepOutput("previous_step")],
    output_schema=AnalysisResult,
    name="analyze_data"
)
```

The `output_schema` is a Pydantic model that is used for the structured output.

### Invoke Tool step
Use `.invoke_tool_step()` to add a step that directly invokes a tool:

```python
builder.invoke_tool_step(
    tool="portia:tavily::search",
    args={"query": "latest news about AI"},
    name="search_news"
)
```

### Function step
Use `.function_step()` to add a step that calls a function. This is useful for manipulating data from other steps using code, streaming updates on the plan as it is run or adding in guardrails.

```python
def process_data(data):
    return {"processed": data.upper()}

builder.function_step(
    function=process_data,
    args={"data": StepOutput(0)},
    name="process_raw_data"
)
```

### Single Tool Agent step
Use `.single_tool_agent_step()` to add a step that calls a tool using arguments that are worked out dynamically from the inputs:

```python
builder.single_tool_agent_step(
    tool="web_scraper",
    task="Extract key information from the webpage provided",
    inputs=[StepOutput("text_blob_with_url")],
    name="scrape_webpage"
)
```

## Conditionals

Use `.if_()` to start a conditional block for advanced control flow:

```python
(
    builder
    .if_(
        condition=lambda web_page: len(web_page) > 100_000,
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )
    .llm_step(
        task="Summarise the web page",
        inputs=[StepOutput("scrape_webpage")],
        name="summarise_webpage"
    )
    .endif()
)
```

`if_()` takes a predicate (named `condition`), which can either be a function, or a natural language string. If it is a function, then the function will be run to return a boolean indicating whether the condition passed. If it is a natural language string, then an LLM will be used to determine whether the string is true or false.

`args` is a dictionary of arguments to pass to the predicate. Like other step types, you can pass references or values (see the [Inputs and Outputs](#inputs-and-outputs) section below for more details).

Also note that you need to add an endif() at the end of the flow to indicate the end of the conditional branch.

Alternative branches can be added to the conditional block using `.else_if_()` and `.else_()`:

```python
(
    builder
    .if_(
        condition=lambda web_page: len(web_page) > 100_000,
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )   # ...
    .else_if_(
        condition=lambda web_page: len(web_page) < 100,
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )
    .function_step(
        function=lambda: raise_exception("Web page is too short"),
    )
    .else_()
    .function_step(
        function=lambda: print("All good!"),
    )
    .endif()
)
```

As mentioned, the condition can be a natural language string. Just write a statement that can be evaluated to true or false and pass the relevant context via the `args`.


```python
(
    builder
    .if_(
        condition="The web page is about large cats",
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )
)
```

Conditional blocks can be nested to create _even_ more complex control flow!

```python
(
    builder
    .if_(
        condition=lambda web_page: len(web_page) > 100_000,
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )
    # Nested conditional block
    .if_(
        condition=lambda web_page: len(web_page) > 1_000_000,
        args={
            "web_page": StepOutput("scrape_webpage")
        }
    )
    .function_step(
        function=lambda: raise_exception("Web page is too long"),
    )
    .endif()
    # ... back to the outer conditional block
)
```


## Inputs and Outputs

### Adding Plan Inputs
Use `.input()` to define inputs that the plan expects:

```python
builder.input(
    name="user_query",
    description="The user's question or request"
)
```

You can also provide the default value for the input, e.g 
```python
builder.input(
    name="user_query",
    description="The user's question or request"
    # Default values can be overriden in plan_run_inputs but will be used as the fallback.
    default_value="What is the capital of France?"
)
```

You can dynamically add the value of the plan at run time, e.g
```python
portia.run_plan(plan, plan_run_inputs={"user_query": "What is the capital of Peru?"})
```

### Referencing Step Outputs
You can reference outputs from previous steps using `StepOutput`:

```python
from portia import StepOutput

builder.invoke_tool_step(
    tool="calculator",
    args={"expression": f"This is some string {StepOutput("previous_step")} interpolation"}
)
```

You can also reference previous step outputs using their index:
```python
from portia import StepOutput

builder.invoke_tool_step(
    tool="calculator",
    args={"expression": StepOutput(1)"}
)
```

:::tip[Note]

The index of a step is the order in which it was added to the plan.

Conditional clauses (`.if_()`, `.else_if_()`, `.else_()` and `.endif()`) _are_ counted as steps and do have an index. Steps within a conditional branch are also counted - the step index is the order the steps appear in the plan, not the runtime index.
:::

### Final Output Configuration
Use `.final_output()` to configure the final output:

```python
plan = builder.final_output(
    output_schema=FinalResult,
    summarize=True
).build()

plan_run = portia.run(plan)
# Will match `FinalResult` schema
final_output_value = plan_run.outputs.final_output.value

# Provides a succinct summary of the outputs (calls LLM to populate)
final_output_summary = plan_run.outputs.final_output.summary
```

## Building the Plan

Once you've defined all your steps, call `.build()` to create the final plan:

```python
plan = builder.build()
```

The returned `PlanV2` object is ready to be executed with your Portia instance.


## [DEPRECATED] Build a plan manually

:::tip[Deprecation warning]

There is an older form of the plan builder described below which is still functional in the SDK but over time we will be replacing it will PlanBuilderV2.

:::

If you prefer to explicitly define a plan step by step rather than rely our planning agent, e.g. for established processes in your business, you can use the PlanBuilder interface. This obviously implies outlining all the steps, inputs, outputs and tools.

The `PlanBuilder` offers methods to create each part of the plan iteratively

- `.step` method adds a step to the end of the plan. It takes a `task`, `tool_id` and `output` name as arguments.
- `.input` and `.condition` methods add to the last step added, but can be overwritten with a `step_index` variable, and map outputs from one step to inputs of chosen (default last step), or considerations
- `.build` finally builds the `Plan` objective

```python title='plan_builder.py'
from portia.plan import PlanBuilder

query = "What is the capital of france and what is the population of the city? If the city has a population of over 1 million, then find the mayor of the city."

plan = PlanBuilder(
  query # optional to provide, as the steps are built below, but provides context for storage and plan purpose
).step(
    task="Find the capital of france", # step task
    tool_id="google_search", # tool id maps to a tool in the tool registry
    output="$capital_of_france", # output variable name maps step output to variable
).step(
    task="Find the population of the capital of france",
    tool_id="google_search",
    output="$population_of_capital",
).input( # add an input to step 2
    name="$capital_of_france", # input variable name maps to a variable in the plan run outputs from step 1
    description="Capital of france" # optional description for the variable
).step(
    task="Find the mayor of the city",
    tool_id="google_search",
    output="$mayor_of_city",
).condition(
    condition="$population_of_capital > 1000000", # adding a condition to the step
).build() # build the plan once finalized

```
</file>

<file path="docs/product/Plan and run workflows/Generate a plan.md">
---
sidebar_position: 1
slug: /generate-plan
---

# Generate a plan

Learn how to create structured, multi-agent plans using your LLM of choice and familiarise yourself with the structure of plans created using Portia.
:::tip[TL;DR]

- A plan is the set of steps an LLM thinks it should take in order to respond to a user prompt.
- A plan is represented by the `Plan` class and can be generated from a user prompt using the `plan` method of the `Portia` class (<a href="/SDK/portia/portia" target="_blank">**SDK reference ↗**</a>). - Portia uses optimised system prompts and structured outputs to ensure adherence to a plan. - You can create your own plans manually or reload existing plans, which is especially useful for repeatable plan runs.
  :::

## Overview of plans in Portia

A plan is the set of steps an LLM thinks it should take in order to respond to a user prompt. Plans are:

- **Immutable**: Once a plan is generated, it cannot be altered. This is important for auditability.
- **Structured**: We use optimised system prompts to guide the LLM along a simple design language when generating a plan. This makes the plan format predictable and easy to process for the purposes of automation.
- **Human-readable**: Our planning language is in a simple, serialisable format. It is easy to render and present to users in a human readable front-end experience. This helps your users easily stay on top of your LLM's reasoning.

While Portia generates a plan in response to a user prompt and then runs it, you also have the option to <a href="/build-plan">**create plans yourself manually↗**</a>. This is especially suitable for your users' more repeatable routines or if you are latency sensitive.

## Introducing a Plan

Let's bring this one to life by looking at an example plan below, created in response to the query `Search for the latest SpaceX news from the past 48 hours and if there are at least 3 articles, email Avrana (avrana@kern.ai) a summary of the top 3 developments with subject 'Latest SpaceX Updates'`.

```json title="plan.json"
{
  "steps": [
    {
      "task": "Search for the latest SpaceX news from the past 48 hours using the search tool.",
      "inputs": [],
      "tool_id": "search_tool",
      "output": "$spacex_news_results"
    },
    {
      "task": "Summarize the top 3 developments from the SpaceX news articles.",
      "inputs": [
        {
          "name": "$spacex_news_results",
          "description": "The list of SpaceX news articles returned by the search tool."
        }
      ],
      "tool_id": "llm_tool",
      "output": "$spacex_summary",
      "condition": "if $spacex_news_results contains at least 3 articles"
    },
    {
      "task": "Email Avrana (avrana@kern.ai) a summary of the top 3 SpaceX developments with the subject 'Latest SpaceX Updates'.",
      "inputs": [
        {
          "name": "$spacex_summary",
          "description": "The summary of the top 3 SpaceX developments."
        }
      ],
      "tool_id": "portia:google:gmail:send_email",
      "output": "$email_sent",
      "condition": "if $spacex_news_results contains at least 3 articles"
    }
  ]
}
```

A plan includes a series of steps defined by

- `"task"` A task describing the objective of that particular step.
- `"input"` The inputs required to achieve the step. Notice how the LLM is guided to weave the outputs of previous steps as inputs to the next ones where applicable e.g. `$spacex_news_results` coming out of the first step acts as an input to the second one.
- `"tool_id"` Any relevant tool needed for the completion of the step. Portia is able to filter for the relevant tools during the multi-shot plan generation process. As we will see later on in this tutorial you can specify the tool registries (directories) you want when handling a user prompt, including local / custom tools and ones provided by third parties. In this example we are referencing tools from Portia's cloud-hosted library, prefixed with `portia:`.
- `"output"` The step's final output. As mentioned above, every step output can be referenced in future steps. As we will see shortly, these outputs are serialised and saved in plan run state as it is being executed.
- `"condition"` An optional condition that's used to control the execution of the step. If the condition is not met, the step will be skipped. This condition will be evaluated by our introspection agent, with the context of the plan and plan run state.

## Create a plan from a user prompt

When responding to a user's prompt with Portia, you can either chain the plan generation process to the subsequent instantiation of a plan run from it, or you can choose to decouple them. The latter option allows you for example to display the plan to the user and tweak it before running a plan.

Let's look at how we generate a plan from a user prompt. Paste the code below into your project and run it:

```python title="main.py"
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    example_tool_registry,
)

load_dotenv()

# Instantiate a Portia instance. Load it with the default config and with the example tools.
portia = Portia(tools=example_tool_registry)

# Generate the plan from the user query
plan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')

# Serialise into JSON and print the output
print(plan.model_dump_json(indent=2))
```

As mentioned earlier in the documentation, the `Portia` instance class is your main entrypoint to interact with Portia's libraries (<a href="/SDK/portia/" target="_blank">**SDK reference ↗**</a>). The `plan` method is available from the `Portia` instance class and allows you to generate a plan from the query. Running the `plan` method per the code above returns a `Plan` object (<a href="/SDK/portia/plan" target="_blank">**SDK reference ↗**</a>) which looks as follows:

```json title="plan.json"
{
  "id": "plan-1dcd74a4-0af5-490a-a7d0-0df4fd983977",
  "plan_context": {
    "query": "Which stock price grew faster, Amazon or Google?",
    "tool_ids": ["calculator_tool", "weather_tool", "search_tool"]
  },
  "steps": [
    {
      "task": "Search for the latest stock price growth data for Amazon.",
      "inputs": [],
      "tool_id": "search_tool",
      "output": "$amazon_stock_growth"
    },
    {
      "task": "Search for the latest stock price growth data for Google.",
      "inputs": [],
      "tool_id": "search_tool",
      "output": "$google_stock_growth"
    },
    {
      "task": "Compare the stock price growth of Amazon and Google.",
      "inputs": [
        {
          "name": "$amazon_stock_growth",
          "value": null,
          "description": "The stock price growth data for Amazon."
        },
        {
          "name": "$google_stock_growth",
          "value": null,
          "description": "The stock price growth data for Google."
        }
      ],
      "tool_id": "llm_tool",
      "output": "$stock_growth_comparison"
    }
  ]
}
```

The `plan` method can take the following additional parameters:

- `tools` in order to confine the plan generation to a narrower set of tools if required (for simplicity or for user-access considerations). In our example above we provided the `example_tool_registry`, which is a collection of three open source tools in our SDK.
- `example_plans` expects a list of `Plan` objects. This allows you to use existing plans as inspiration or templates, which improves repeatability for more routine plan runs.

## User led learning

Example plans can be used to bias the planner towards actions, tool use and behaviours, while also improving the planners ability to generate more complex plans. Broadly, the process for doing this with portia is 3 steps below

- "Like" plans saved to Portia Cloud from the dashboard to signal that they are patterns you want to reinforce.
- Pull "Liked" plans based on semantic similarity to the user intent in a query by using our freshly minted `portia.storage.get_similar_plans` method (<a href="/SDK/portia/storage#get_similar_plans" target="_blank">**SDK reference ↗**</a>).
- Finally, ingest those similar plans as example plans in the Planning agent using the `portia.plan` method's `example_plans` property (<a href="/SDK/portia/" target="_blank">**SDK reference ↗**</a>).

For a deep dive into this feature and a practical example, check out our <a href="https://blog.portialabs.ai/improve-planning-with-user-led-learning" target="_blank">**ULL blog post on example plans ↗**</a>.

Now that you know how to generate plans in response to a user query, let's take a look at how to run a plan in the next section.

## Structured Output Schema

For some plans you might want to have a structured output at the end of a plan, for this we allow the ability to attach a structured output schema to the plan that the summarizer agent will attempt to coerce the results to. This is optional. To use, attach to the Plan object, and any Plan Runs that are created from this will attempt to use structured output for the final result, this can pull information from any point of the plan steps and is not just the final step. To attach a schema, you can do it through the PlanBuilder or the Plan interfaces, as below.

```python title='plan_structured_output.py'
from portia.plan import PlanBuilder
from pydantic import BaseModel
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    example_tool_registry,
)

load_dotenv()
portia = Portia(tools=example_tool_registry)

# Final Output schema type to coerce to
class FinalPlanOutput(BaseModel):
    result: float # result here is an integer output from calculator tool, but will be converted to a float via structured output

# Example via plan builder, attach to the plan at top level
plan = PlanBuilder(
  "Add 1 + 1", structured_output_schema=FinalPlanOutput
).step(
  "Add 1 + 1", tool_id='calculator_tool'
).build()

# Example via plan interface
plan2 = portia.plan("Add 1 + 1", structured_output_schema=FinalPlanOutput)
```

Run the plan as normal and the final output will be an instance of the attached schema.
</file>

<file path="docs/product/Plan and run workflows/Inputs and Outputs.md">
---
sidebar_position: 5
slug: /inputs-outputs
---

# Inputs and Outputs
Inputs and outputs are the core of any agentic workflow, and Portia provides a flexible way to define and use them. Inputs are managed via the plan input interface, while structured outputs are managed via the plan structured output interface in conjunction with Pydantic BaseModels.

## Plan Inputs

So far the starting point for all plan runs is a user query for a specific set of inputs e.g. "get the weather in Beirut". This is in contrast to a generalised query e.g. "get the weather for a given city" where the city is provided dynamically per plan run. The PlanInput abstraction allows you to use a generalised query or plan "template" where the input differs with every plan run.

In the planning stage, you would define the list of plan inputs, providing a name and optional description for each, and pass those along with a generalised query as arguments to the portia.plan method. The planning agent is capable of generating a plan with "placeholders" for each plan input. To run that generalised plan, Portia then expects you to provide specific values for the inputs at each run.

For example, consider a simple agent that tells you the weather in a particular city, with the city provided as a plan input.
To set this up, we define the plan input for the planner as follows:
```python id=plan_with_inputs
from portia import Portia

portia = Portia()

# Specify the inputs you will use in the plan
plan_input = {"name":"$city", "description": "The city to get the temperature for"}
plan = portia.plan("Get the temperature for the provided city", plan_inputs=[plan_input])
```

This will create a single step plan that uses the weather tool with $city as an input to that tool.
Then, when running the plan, we pass in a value for the input. In this case, we select "London".
This value will then be used for the `$city` input in the plan and we will find the temperature in London.

```python depends_on=plan_with_inputs
# Specify the values for those inputs when you run the plan
plan_run_inputs = {"name": "$city", "value": "London"}
plan_run = portia.run("Get the temperature for the provided city", plan_run_inputs=[plan_run_inputs])
```

## Plan Structured Outputs

For some plans you might want to have a structured output at the end of a plan, for this we allow the ability to attach a structured output schema to the plan that the summarizer agent will attempt to coerce the results to. This is optional and is based on <a href="https://docs.pydantic.dev/latest/#pydantic-examples" target="_blank">**Pydantic BaseModels ↗**</a>. To use, attach to the Plan object, and any Plan Runs that are created from this will attempt to use structured output for the final result, this can pull information from any point of the plan steps and is not just the final step. To attach a schema, you can do it through the PlanBuilder or the Plan interfaces, as below.

```python title='plan_structured_output.py'
from portia.plan import PlanBuilder
from pydantic import BaseModel
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    example_tool_registry,
)

load_dotenv()
portia = Portia(tools=example_tool_registry)

# Final output schema type to coerce to
class FinalPlanOutput(BaseModel):
    result: float # result here is an integer output from calculator tool, but will be converted 
    # to a float via structured output you can also add other fields here, and they will be 
    # included in the output, as per any other Pydantic BaseModel

# Example via plan builder, attach to the plan at top level
plan = PlanBuilder(
  "Add 1 + 1", structured_output_schema=FinalPlanOutput
).step(
  "Add 1 + 1", tool_id='calculator_tool'
).build()

# Example via plan interface
plan2 = portia.plan("Add 1 + 1", structured_output_schema=FinalPlanOutput) 
```
Run the plan as normal and the final output will be an instance of the attached schema. It will be coerced to the type of the BaseModel provided and follows all the same rules as a pydantic model, including validation and description for fields.

## LLM Tool Outputs
The LLMTool allows structured outputs to be returned from a tool call, and these will be coerced to the type of the BaseModel provided. This follows all the same rules as a pydantic model, including validation and description for fields in the same way as the plan structured output above, but only for an LLM tool call within the plan. 

```python title='llm_tool_output.py'
from portia import Portia, config, PlanBuilder
from portia.open_source_tools.llm_tool import LLMTool
from portia.open_source_tools.weather import WeatherTool
import dotenv
from pydantic import BaseModel, Field

# basics
dotenv.load_dotenv(override=True)
config = config.Config.from_default()

# structured output schema
class WeatherOutput(BaseModel):
    temperature: float
    description: str = Field(description="A description of the weather")

structured_llm_tool = LLMTool(structured_output_schema=WeatherOutput) # structured output schema attached

tools = [structured_llm_tool, WeatherTool()] # structured_llm_tool has a structured output schema attached
portia = Portia(config, tools=tools) # register the tools with the portia instance, including the structured_llm_tool

plan = PlanBuilder(
  "get the weather in london and summarize the weather"
).step(
  "get the weather in london", tool_id=weather_tool.id
).step(
  "summarize the weather", tool_id=structured_llm_tool.id
).build()
```

## Browser Tool Outputs
The BrowserTool allows structured outputs to be returned from a browser tool call, and these will be coerced to the type of the basemodel provided and follows all the same rules as a pydantic model, including validation and description for fields in the same way as the plan structured output above, but only for a browser tool call within the plan. 

```python title='browser_tool_output.py'
from portia import Portia, config, PlanBuilder
from portia.open_source_tools.browser_tool import BrowserTool
import dotenv
from pydantic import BaseModel, Field

# basics
dotenv.load_dotenv(override=True)

config = config.Config.from_default()


class Recipes(BaseModel):
    recipe_names: list[str] = Field(description="List of recipe names found on the page")

browsertool = BrowserTool(structured_output_schema=Recipes) # structured output schema attached
tools = [browsertool]
portia = Portia(config, tools=tools)

plan = PlanBuilder(
    "Get the top recipes from bbcgoodfood"
).step(
    "get all the names of recipes on the frontpage of bbcgoodfood.com", tool_id=browsertool.id
).build()
```
</file>

<file path="docs/product/Plan and run workflows/Manage plan run states on Portia cloud.md">
---
sidebar_position: 4
slug: /store-retrieve-plan-runs
---

# Plan run states on Portia cloud
Use our Run service to save and retrieve serialised plan run states on our cloud.

Storing and retrieving plan runs on Portia cloud significantly simplifies the management of long lived and / or asynchronous plan runs. For example when a clarification is raised, the state of the plan run is automatically maintained in the Portia cloud and retrieving the plan run once the clarification is handled is a single line of code.


<details>
<summary>**API keys required**</summary>

We're assuming you already have a Portia API key from the dashboard and set it in your environment variables. If not please refer to the previous section and do that first (<a href="/setup-account" target="_blank">**Set up your account ↗**</a>).

We will use a simple GET endpoint from OpenWeatherMap in this section. Please sign up to obtain an API key from them (<a href="https://home.openweathermap.org/users/sign_in" target="_blank">**↗**</a>) and set it in the environment variable `OPENWEATHERMAP_API_KEY`.

</details>

## Store plan runs in the cloud
We have seen how to configure the location where plan runs are stored and retrieved previously (<a href="/manage-config" target="_blank">**Manage config options ↗**</a>). We can simply set the `storage_class` property to `CLOUD` in the config of our `Portia` instance. 
With this config and as long as the API key has been set up appropriately as described in the previous section (<a href="/setup-account" target="_blank">**Set up your account ↗**</a>), you should see plan runs executed by your `Portia` instance appear in the `Plan runs` tab of your Portia dashboard and see a change in the aggregate plan run metrics in the Home page as well.

```python title="main.py"
from dotenv import load_dotenv
from portia import Portia
from portia.config import Config, StorageClass
from portia.open_source_tools.registry import example_tool_registry

load_dotenv()

# Load the default config and override the storage class to point to the Portia cloud
my_config = Config.from_default(storage_class=StorageClass.CLOUD)

# Instantiate a Portia instance. Load it with the default config and an example tool registry
portia = Portia(config=my_config, tools=example_tool_registry)

# Run a plan from the user query
plan_run = portia.run('Get the temperature in London and share it with a light joke')

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```
Take a moment to examine the plan run created by the code above in your dashboard. To do so you will need the plan run ID, appearing in the first attribute of the output e.g. `"id": "prun-f66b141b-5603-4bd9-b827-0c7a41bf5d5c"`.

## Retrieve plan runs from the cloud

You can retrieve both plans and run states for a stored plan run. For that you would use the `get_plan_run` and `get_plan` methods of the `Storage` class. You will need to specify the `PortiaCloudStorage` class in particular here. Go ahead and copy your plan run ID from the dashboard entry created in the previous section into the code below.
<!-- Setup a plan run with the correct id. This won't be rendered on the website
```python id=plan_run_invisible_setup
from portia import Portia
from portia.plan import PlanBuilder, PlanUUID
from portia.plan_run import PlanRunUUID
from uuid import UUID
plan = PlanBuilder("test").build()
plan_run = Portia().run_plan(plan)
plan_run_id = PlanRunUUID(uuid=UUID("229956fb-820d-4099-b69c-0606ca620b86"))
plan_run.id = plan_run_id
try:
  if not Portia().storage.get_plan_run(plan_run_id):
    Portia().storage.save_plan_run(plan_run)
except Exception as e:
  pass
```
-->
```python title="main.py" id=manage_plan_run_intro depends_on=plan_run_invisible_setup
from dotenv import load_dotenv
from portia import Config, StorageClass
from portia.storage import PortiaCloudStorage

load_dotenv()

# Load the default config and override the storage class to point to the Portia cloud
my_config = Config.from_default(storage_class=StorageClass.CLOUD)
# Use the PortiaCloudStorage class to interact with cloud storage
my_store = PortiaCloudStorage(config=my_config)

# Retrieve a plan and its run from the cloud
plan_run = my_store.get_plan_run("229956fb-820d-4099-b69c-0606ca620b86")
plan = my_store.get_plan(plan_run.plan_id)

# Serialise into JSON an print the objects
print(f"Retrieved plan run:\n{plan_run.model_dump_json(indent=2)}")
print(f"Retrieved plan:\n{plan.model_dump_json(indent=2)}")
```
Note that you can also access the `StorageClass` directly from your `Portia` instance. If you have a `Portia` instance with an associated `Config` that uses `CLOUD` storage like the first example on this page, you could simply use `portia.storage.get_plan_run` and `portia.storage.get_plan`.

You should expect to see the following output:
```bash
Retrieved plan run:
{
  "id": "prun-f66b141b-5603-4bd9-b827-0c7a41bf5d5c",
  "plan_id": "plan-1eee4bbf-361a-41be-bab7-6dd86a247f48",
  "current_step_index": 1,
  "clarifications": [],
  "state": "COMPLETE",
  "step_outputs": {
    "$weather_joke": {
      "value": "Why did the weather go to therapy? It had too many issues to cloud its mind!"
    },
    "$london_temperature": {
      "value": "The current weather in London is overcast clouds with a temperature of 0.91°C."
    }
  },
  "final_output": {
    "value": "Why did the weather go to therapy? It had too many issues to cloud its mind!"
  }
}
Retrieved plan:
{
  "id": "plan-1eee4bbf-361a-41be-bab7-6dd86a247f48",
  "query": "Get the temperature in London and share it with a light joke",
  "steps": [
    {
      "task": "Get the current temperature in London.",
      "inputs": [],
      "tool_id": "weather_tool",
      "output": "$london_temperature"
    },
    {
      "task": "Generate a light joke about the weather.",
      "inputs": [
        {
          "name": "$london_temperature",
          "description": "The current temperature in London."
        }
      ],
      "tool_id": "llm_tool",
      "output": "$weather_joke"
    }
  ]
}
```

If you wanted to retrieve plan runs in bulk, you can use the `get_plan_runs` method (plural!) from `StorageClass`. This returns paginated data so you will need to process that information further to cycle through all results. Remember the first page number returned is always 1 (not 0!).

```python depends_on=plan_run_invisible_setup depends_on=manage_plan_run_intro
plan_run_list_init = my_store.get_plan_runs() # again, plural!
total_pages = plan_run_list_init.total_pages

for page in range(1, total_pages+1):
    print(f"Retrieving plan runs from page {page}...")
    plan_run_list = my_store.get_plan_runs(page=page)
    for plan_run in plan_run_list.results:
        print(f"Plan run ID: {plan_run.id}")
```
</file>

<file path="docs/product/Plan and run workflows/Run a plan.md">
---
sidebar_position: 3
slug: /run-plan
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Run a plan
Learn how to run a plan run from an existing plan or end-to-end.
:::tip[TL;DR]
- A plan run is (uncontroversially) a unique run of a plan. It is represented by the `PlanRun` class (<a href="/SDK/portia/plan_run" target="_blank">**SDK reference ↗**</a>).
- An agent is spun up to execute every step in the plan run. The `PlanRun` object tracks the state of the plan run and is enriched at every step by the relevant agent.
- A plan run can be generated from a plan using the `run_plan` method. 
- You can also plan a query response, then create and execute a plan run in one fell swoop using the `run` method of the `Portia` instance class (<a href="/SDK/portia/portia" target="_blank">**SDK reference ↗**</a>).
:::

## Overview of plan runs in Portia
Portia captures the state of a plan run at every step in an auditable way. This includes:
- A step index tracking at which step we are in the plan run.
- The actual plan run state e.g. NOT_STARTED, IN_PROGRESS, COMPLETE, READY_TO_RESUME or NEED_CLARIFICATION.
- A list of step outputs that is populated throughout the plan run.

In a later section we will also see that a plan run state also tracks the list of instances where human input was solicited during plan run, known as `Clarification`.

Plan run states are captured in the `PlanRun` class (<a href="/SDK/portia/plan_run" target="_blank">**SDK reference ↗**</a>). In the previous section (<a href="/generate-plan" target="_blank">**Generate a plan ↗**</a>), we generated a plan in response to the query `Which stock price grew faster in 2024, Amazon or Google?`. Let's examine the final state once we run that plan:
<Tabs>
  <TabItem value="plan" label="Generated plan">
    ```json title="plan-1dcd74a4-0af5-490a-a7d0-0df4fd983977.json"
    {
      "id": "plan-1dcd74a4-0af5-490a-a7d0-0df4fd983977",
      "plan_context": {
        "query": "Which stock price grew faster, Amazon or Google?",
        "tool_ids": [
          "calculator_tool",
          "weather_tool",
          "search_tool"
        ]
      },
      "steps": [
        {
          "task": "Search for the latest stock price growth data for Amazon.",
          "inputs": [],
          "tool_id": "search_tool",
          "output": "$amazon_stock_growth"
        },
        {
          "task": "Search for the latest stock price growth data for Google.",
          "inputs": [],
          "tool_id": "search_tool",
          "output": "$google_stock_growth"
        },
        {
          "task": "Compare the stock price growth of Amazon and Google.",
          "inputs": [
            {
              "name": "$amazon_stock_growth",
              "description": "The stock price growth data for Amazon."
            },
            {
              "name": "$google_stock_growth",
              "description": "The stock price growth data for Google."
            }
          ],
          "tool_id": "llm_tool",
          "output": "$stock_growth_comparison"
        }
      ]
  }
    ```
  </TabItem>
    <TabItem value="plan_run" label="Plan run in final state" default>
    ```json title="prun-18d9aa91-0066-413f-af32-b979bce89821.json"
    {
      "id": "prun-18d9aa91-0066-413f-af32-b979bce89821",
      "plan_id": "plan-a89efeb0-51ef-4f2c-b435-a936c27c3cfc",
      "current_step_index": 2,
      "state": "COMPLETE",
      "outputs": {
        "clarifications": [],
        "step_outputs": {
          "$amazon_stock_growth": {
            "value": "Amazon stock closed at an all-time high of $214.10 in November...",
            "summary": null
          },
          "$google_stock_growth": {
            "value": "In 2024, Google's parent company Alphabet surged 35.5% according to...",
            "summary": null
          },
          "$faster_growth": {
            "value": "In 2024, Amazon's stock price grew by 52%, while Google's parent company Alphabet saw a stock price surge of 35.5%.",
            "summary": null
          }
        },
        "final_output": {
          "value": "In 2024, Amazon's stock price grew by 52%, while Google's parent company Alphabet saw a stock price surge of 35.5%.",
          "summary": null
        }
      }
    }









    ```
  </TabItem>
</Tabs>

Every plan run has a unique `id` and relates to a unique `plan_id`. If you were to attempt running the same plan multiple times, you would generate multiple `PlanRun` objects each with a unique `id` but all with the same `plan_id` property.

## Plan run state changes
As Portia cycles through a plan run, an execution agent is instantiated at every step and that agent will call the tool designated for that. The plan run state is enriched with step outputs at every step of the execution as well. Note that in this example the main tool used is the 'Search Tool' provided in this SDK in the `example_tool_registry`, and wraps around the Tavily API. We will discuss tools in more depth in the next section.
You should be able to inspect the state changes for the above plan run in the logs when you run the code.
<div style={{
  overflow: 'hidden',
  marginLeft: 'auto',
  marginRight: 'auto',
  borderRadius: '10px',
  width: '100%',
  maxWidth: '931px',
  position: 'relative'
}}>
  <div style={{
    width: '100%',
    paddingBottom: '59.07626208378088%'
  }}></div>
  <iframe 
    width="931" 
    height="550" 
    title="Embedded content"
    src="https://snappify.com/embed/c8eb2bee-f784-4d24-b573-39bfca493eda?responsive=1&p=1&autoplay=1&b=0" 
    allow="clipboard-write" 
    allowFullScreen
    loading="lazy" 
    style={{
      background: '#eee',
      position: 'absolute',
      left: 0,
      top: 0,
      width: '100%'
    }} 
    frameBorder="0"
  ></iframe>
</div>
<small>Animation above made on the brilliant <a href="https://snappify.com" target="_blank">**snappify.com ↗**</a>.</small>


## Run from a pre-expressed plan
<details>
<summary>**Tavily API key required**</summary>

We will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (<a href="https://tavily.com/" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.
</details>

To get to an output that looks like the plan run example above, let's expand on the code we used to generate a plan in the previous section (<a href="/generate-plan" target="_blank">**↗**</a>) by adding code to create and execute a plan run from that plan. This approach gives you the opportunity to serve that plan to the user and get their feedback / iterate on it before running the plan run for example. Here is the code to do that:
```python title="main.py"
from dotenv import load_dotenv
from portia import (
    Portia,
    example_tool_registry,
)

load_dotenv()

# Instantiate a Portia instance. Load it with the default config and with the example tools.
portia = Portia(tools=example_tool_registry)

# Generate the plan from the user query
plan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')

# [OPTIONAL] INSERT CODE WHERE YOU SERVE THE PLAN TO THE USER OR ITERATE ON IT IN ANY WAY

# Run the generated plan
plan_run = portia.run_plan(plan)

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```

Here we are storing the `Plan` object returned by the `plan` method. We then use the `run_plan` method to start a `PlanRun`.

:::info
If you want to see an example where a user iterates on a plan before we proceed with plan run, take a look at the intro example in our <a href="https://github.com/portiaAI/portia-agent-examples/blob/main/get_started_google_tools/README.md" target="_blank">**examples repo (↗)**</a>.
:::

## Run directly from a user query
<details>
<summary>**Tavily API key required**</summary>

We will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (<a href="https://tavily.com/" target="_blank">**↗**</a>) and set it in the environment variable `TAVILY_API_KEY`.
</details>

You can also run a plan immediately from the user query, without examining the `Plan` object in between. This would generate a plan as an intermediate step as well but will also immediately spawn a plan run from it. You would simply use the `run` method from your `Portia` instance class like so:
```python title="main.py"
from dotenv import load_dotenv
from portia import (
    Portia,
    example_tool_registry,
)

load_dotenv()

# Instantiate a Portia instance. Load it with the default config and with the example tools.
portia = Portia(tools=example_tool_registry)

# Generate the plan from the user query
plan_run = portia.run('Which stock price grew faster in 2024, Amazon or Google?')

# Serialise into JSON and print the output
print(plan_run.model_dump_json(indent=2))
```
:::note[Track plan run states in logs]
You can track plan run state changes live as they occur through the logs by setting `default_log_level` to DEBUG in the `Config` of your `Portia` instance (<a href="/manage-config#manage-logging" target="_blank">**Manage logging ↗**</a>).
:::

## Run a plan stored in Portia cloud

When you set the storage_class property to CLOUD in the config of your Portia instance (see <a href="/manage-config##manage-storage-options" target="_blank">**Manage storage options ↗**</a> for more details), plans will automatically be stored in the cloud once created. You can then easily retrieve plans from storage in order to run them:

<!-- Setup a plan with the correct id. This won't be rendered on the website
```python id=plan_invisible_setup
from portia.plan import PlanBuilder, PlanUUID
from portia import Portia
from uuid import UUID
portia = Portia()
plan = PlanBuilder("test").build()
plan_id = PlanUUID(uuid=UUID("f8003b53-9b62-44e2-ac67-887146c07949"))
plan.id = plan_id
try:
  if not portia.storage.get_plan(plan_id):
    portia.storage.save_plan(plan)
except Exception as e:
  pass
```
-->

```python depends_on=plan_invisible_setup
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    Config,
    StorageClass,
    PlanUUID
)

# Load the Portia API key
load_dotenv()

# Set up the Portia instance to use cloud storage
config = Config.from_default(storage_class=StorageClass.CLOUD)
portia = Portia(config=config)

# This will create a plan that is stored in Portia Cloud
plan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')

# We can then either run the plan directly from the object...
run = portia.run_plan(plan=plan)

# Or we can use the ID so that the plan is loaded from storage
run = portia.run_plan(plan=PlanUUID.from_string("plan-f8003b53-9b62-44e2-ac67-887146c07949"))
```

This can be very useful if you want to run a plan from a different process to the one that created the plan.
</file>

<file path="docs/product/Running in production/_category_.json">
{
  "label": "Running in production",
  "position": 5,
  "link": {
    "type": "generated-index",
    "slug": "running-in-production",
    "description": "Learn how to run agents in production with Portia."
  }
}
</file>

<file path="docs/product/Running in production/Agent memory.md">
---
sidebar_position: 1
slug: /agent-memory
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Using agent memory

With Portia, agents can leverage memory by default.
This allows them to work efficiently when large pieces of data are produced / processed during plans, avoiding latency, cost and performance issues caused when language model context windows fill up.

When a step of a plan produces a large output, for example if a large document is read or downloaded, agents in Portia will automatically store this output in agent memory.
In their plan run state, they also maintain a reference to this output.
Then, if the large output is needed by future steps when running the plan, the value will be pulled in from agent memory as needed.

![Agent memory](/img/agent_memory.png)

Agent memories are scoped to a particular run of a plan and persist when a plan is paused to handle a clarification and later resumed. If you are running with Portia cloud storage, you can view the values your agents have stored in agent memory by navigating to the <a href="https://app.portialabs.ai/dashboard/agent-memory" target="_blank">**Agent Memory page ↗**</a>.

## Configuring agent memory

Agent memory uses the storage class that you have configured for your Portia client.
This means you can store memories locally, in the Portia cloud or on disk.
For more details on the available storage classes, see our 
<a href="/manage-config#manage-storage-options" target="_blank">storage options section ↗</a>.

You can also configure the size threshold at which step outputs are written to agent memory using the `large_output_threshold_tokens` config value:
```
portia = Portia(Config.from_default(large_output_threshold_tokens=10000))
```

Step outputs longer than this threshold are automatically written to agent memory. 
This threshold is expressed in tokens, which is a unit of text processed by a language model. 
They can be thought of as being roughly equivalent to words, but with some words taking several tokens. 
For more details, see <a href="https://blogs.nvidia.com/blog/ai-tokens-explained/" target="_blank">this explainer on language model tokens ↗</a>.
</file>

<file path="docs/product/Running in production/Agent observability.md">
---
sidebar_position: 2
slug: /agent-observability
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Agent observability

## Using Langsmith

With Portia, you can easily instrument your agents with Langsmith in order to gain observability into the calls to the underlying language models. To do this, simply run your agent with the following environment varibles set:

```
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_PROJECT=<INSERT LANGSMITH PROJECT NAME HERE>
LANGCHAIN_API_KEY=<INSERT LANGSMITH API KEY HERE>
```

If you don't already have one, you can set up a Langsmith account by following <a href="https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key" target="_blank">these instructions ↗</a>. This will provide you with the required project name and API key.

Once these environment variables are set, all calls that your agent makes to the underlying language models will automatically be traced within Langsmith. 

## Other providers

If you are using an alternative language model observability provider, please get in touch with us at hello@portialabs.ai and let us know more about your use-case.
</file>

<file path="docs/product/Running in production/Execution Hooks.md">
---
sidebar_position: 4
slug: /execution-hooks
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Execution hooks

Execution hooks provide the ability for users to extend, intervene in or modify the running of agents in Portia, including allowing human control to be overlayed into the multi-agent plan run deterministically.
This is done by allowing you to run custom code at specific points in the agent run.
This can be very useful in a wide range of circumstances:
* To add human-in-the-loop verification before tool calls. For example, if you're building an agent to verify and then administer product refunds to customers, you likely want to include a human-in-the-loop check before the agent gives out the refund.
* To add guardrails into the system, causing the agent to exit if a bad output is given or skip steps if certain conditions are met
* To modify the args that tools are called with (for example to redact any leaked PII (personally identifiable information))
* To stream updates of the system to a frontend to display to the user
* To add custom logging

## Available hooks

Portia provides several hook points where you can inject custom code:

- **Before plan run**: Run only before the first step of a plan run. This can be useful for any setup steps you need to take at the start of a run.
- **Before step**: Run before each step in the plan is executed. This can be useful if you want add a guardrail before each step.
- **After step**: Run after each step completes. This can be useful for streaming updates on each step to a frontend.
- **After last step**: Run only after the final step of a plan run. This can be useful for any cleanup steps that you need to take at the end of a run.
- **Before tool call**: Run directly before any tool is called. This can be useful if you want to add a human-in-the-loop check before running a particular tool, or if you want to add any checks on tool args before a tool is called. You can also alter the tool args in this hook if required.
- **After tool call**: Executed directly after any tool call completes. This can be useful if you want to add any guardrail that check tool output.

## Implementing an execution hook

To implement a custom hook, simply define the code you want to run and then pass it in as a hook when creating your Portia instance.
We also provide several pre-made execution hooks that can be imported from `portia.execution_hooks`:

```python
from dotenv import load_dotenv
from portia import Plan, PlanRun, Portia, Step, logger
from portia.execution_hooks import ExecutionHooks, clarify_on_all_tool_calls, log_step_outputs

load_dotenv()

def log_before_each_step(plan: Plan, plan_run: PlanRun, step: Step) -> None:  # noqa: ARG001
    """Log the output of a step in the plan."""
    logger().info(f"Running step with task {step.task} using tool {step.tool_id}")


portia = Portia(
    execution_hooks=ExecutionHooks(
        # Out custom hook defined above
        before_step_execution=log_before_each_step,
        # Imported hook to raise a clarification before all tool calls
        before_tool_call=clarify_on_all_tool_calls,
        # Imported hook to log the result of all steps
        after_step_execution=log_step_outputs,
    ),
)
```

### Human-in-the-loop checks

In the 'before tool call' and 'after tool call' hooks, you can raise **clarifications** with the user if you require their input.
As with other clarifications, these clarifications are then handled by the user through your chosen clarification handler (see <a href="/understand-clarifications" target="_blank">the clarification docs ↗</a>. for more details).
This allows you to create powerful human-in-the-loop checks and guardrails.
As an example, the below code uses a `UserVerificationClarification` to ensure that the user verifies all calls to the refund tool.

```python
from typing import Any
from portia import Clarification, ClarificationCategory, ExecutionHooks, PlanRun, Portia, Step, Tool, ToolHardError
from portia.clarification import UserVerificationClarification

def clarify_before_refunds(
    tool: Tool,
    args: dict[str, Any],
    plan_run: PlanRun,
    step: Step,
) -> Clarification | None:
    # Only raise a clarification for the refund tool
    if tool.id != "refund_tool":
        return None

    # Find if the clarification if we already raised it
    previous_clarification = plan_run.get_clarification_for_step(ClarificationCategory.USER_VERIFICATION)

    # If we haven't raised it, or it has been resolved, raise a clarification
    if not previous_clarification or not previous_clarification.resolved:
        return UserVerificationClarification(
            plan_run_id=plan_run.id,
            user_guidance=f"Are you happy to proceed with the call to {tool.name} with args {args}? "
            "Enter 'y' or 'yes' to proceed",
        )

    # If the user didn't verify the tool call, error out
    if str(previous_clarification.response).lower() not in ["y", "yes"]:
        raise ToolHardError("User rejected tool call to {tool.name} with args {args}")

    # If the user did verify the tool call, continue to the call
    return None

portia = Portia(execution_hooks=ExecutionHooks(before_tool_call=clarify_before_refunds))
```

This is a common use-case so you don't actually need to write this yourself - you can use our pre-made `clarify_on_tool_calls` hook.
</file>

<file path="docs/product/Running in production/Manage end users.md">
---
sidebar_position: 3
slug: /manage-end-users
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Managing end users

Whilst building an agent for yourself can be very rewarding most agentic use cases run for many users. For example you may be an engineer creating a new agent for all the staff in your business. It may be important for the agent to know information about the specific member of staff that the agent is running for. Imagine a query like "Send me a summary of the latest results". This requires information about who the "me" is.

Portia has been built from the ground up for production deployments and so has a first class representation of your users within Portia. We call these entities end users, the people or companies that you are running agentic workflows for. 


:::tip[TL;DR]
The `EndUser` class can be used to represent your users within `Portia`.
- The `external_id` field in an `EndUser` object uniquely represents the end user in your system e.g. an internal ID or an email address.
- `names`, `emails` and `phone_numbers` can all be stored against this object. They can dynamically be updated in tools with changes made to `end_user` models being persisted in storage.
- `additional_data` can be used to pass user specific info that may be relevant to the response such as title and department.
- Authentication is tied to the end user you use when executing a `plan_run`. This allows us to re-use Oauth tokens (subject to your token retention policy) improving user experience.
:::

:::info[Important]
- If you don't provide an `end_user` the system will generate an `end_user` to represent you as the developer. This is useful if you're building a system with only one user. You'll see this represented as users with the prefix `portia::`.
:::


## End users at Portia

In Production, you will be running plans for many stakeholders including customers, employees and partners. You may want to pass information specific to these individuals when they submit a prompt and / or information specific to the current context they are operating in (e.g. the particular app they are using when they submit their prompt to initiate a plan run).

We refer to these "person" entities as **end users** and represent them through the `EndUser` model.
- You can pass either a string or a full `EndUser` to the plan + run endpoints. The string or external ID can be any value that uniquely represents the end user in your system e.g. an internal ID or an email address.
- Alongside the `end_user_id` you can also provide a set of additional attributes in the `additional_data` field.

## Pass the EndUser to the plan run

```python title="main.py"
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    example_tool_registry,
)
from portia.end_user import EndUser

load_dotenv()

portia = Portia(tools=example_tool_registry)

# We can provide it as a string
# highlight-start
plan_run = portia.run(
    "Get the temperature in Svalbard and write me a personalized greeting with the result.",
    end_user="my_user_id_123"
)
# highlight-end

# Or provide additional information through the model:
# highlight-start
plan_run = portia.run(
    "Get the temperature in Svalbard and write me a personalized greeting with the result.",
    end_user=EndUser(external_id="my_user_id_123", name="Nicholas of Patara")
)
# highlight-end

print(plan_run.model_dump_json(indent=2))
```

The result of this code block will be the addition of an `end_user_id` within the `PlanRun` state, and a `final_output` that is indeed personalised to Saint Nicholas (known by his stage name Santa Claus):
```json title="plan_run_state.json"
{
  "id": "prun-d9991518-92d7-447f-bf28-4f7b9b8110ce",
  "plan_id": "plan-4f497c60-c33e-40ea-95b4-cd2054559fff",
  "current_step_index": 1,
  "clarifications": [],
  "state": "COMPLETE",
  # highlight-start
  "end_user_id":  "DemoUser123",
  # highlight-end
  "step_outputs": {
    "$svalbard_temperature": {
      "value": "The current weather in Svalbard is light snow with a temperature of -11.53°C."
    },
    "$personalized_greeting": {
      "value": "Hello Nicholas of Patara, I hope you are keeping warm. With the current weather in Svalbard showing light snow and a temperature of -11.53°C, make sure to bundle up and stay cozy!"
    }
  },
  # highlight-start
  "final_output": {
    "value": "Hello Nicholas of Patara, I hope you are keeping warm. With the current weather in Svalbard showing light snow and a temperature of -11.53°C, make sure to bundle up and stay cozy!"
  }
  # highlight-end
}
```


## Accessing end users in a tool

End User objects are passed through to the tool run function as part of the `ToolRunContext`. This allows you to access attributes for your users in tools.

You can also update attributes in tools, which will be persisted to storage upon completion of the tool call. This provides a way of storing useful data about the user.

```python title="main.py"
from pydantic import BaseModel, Field
from portia.tool import Tool, ToolRunContext

class EndUserUpdateToolSchema(BaseModel):
    """Input for EndUserUpdateTool."""

    name: str | None = Field(default=None, description="The new name for the end user.")


class EndUserUpdateTool(Tool):
    """Updates the name of the plan runs end user."""

    id: str = "end_user_update"
    name: str = "End User Update Tool"
    description: str = "Updates the name of the end user"
    args_schema: type[BaseModel] = EndUserUpdateToolSchema
    output_schema: tuple[str, str] = ("str", "str: The new name")

    def run(self, ctx: ToolRunContext, name: str) -> str:
        """Change the name."""
        ctx.end_user.name = name
        ctx.end_user.set_attribute("has_name_update", "true")
        return name
```

## End user state management

As we mentioned above End Users are first class citizens in the Portia Ecosystem. This means they are independent entities with their own state. Changes you make to them are persisted in storage and we refresh the state before commencing `plan_runs`. 

This is particularly relevant for the `additional_data` field on the End User. This field allows you to store any additional data you like against users. This can either be done through the cloud interface, by providing it when running a plan, or by updating it in a tool. 

```python title="main.py"
from dotenv import load_dotenv
from portia import (
    Portia,
    default_config,
    example_tool_registry,
)
from portia.end_user import EndUser

load_dotenv()

portia = Portia(tools=example_tool_registry)

plan_run = portia.run(
    "Get the temperature in Svalbard and write me a personalized greeting with the result.",
    end_user=EndUser(external_id="my_user_id_123", name="Nicholas of Patara", additional_data={"weather_preferences": "I prefer my weather in the form of a Haiku"})
)
```

## End user and OAuth tokens

If you are using Portia Cloud Tools which support user level OAuth tokens, these tokens are stored against the EndUser of the `plan_run`. If you have the setting enabled (see Security), tokens will be reused for each end user reducing the number of authentication flows they must do.
This makes setting an `end_user` correctly important in this case to avoid token collision issues.
</file>

<file path="docs/product/Security/_category_.json">
{
  "label": "Security",
  "position": 7,
  "link": {
    "type": "generated-index",
    "slug": "security",
    "description": "Understand how Portia stores sensitive material and the controls you have."
  }
}
</file>

<file path="docs/product/Security/Security Overview.md">
---
sidebar_position: 1
slug: /security
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Portia cloud security

Understanding the security of your agentic system is critical to deploying agents in production. Portia uses production-grade security and encryption and offers granular customization of security policies to ensure your data is secure within our systems. 

# OAuth token handling

All OAuth tokens provided to Portia from third parties are securely encrypted within the application using a unique Google KMS key per organization. No internal staff member can view decrypted token data. Once a token is expired or consumed (depending on the retention policy - see below) it is deleted from all Portia systems.

# OAuth token retention

Additionally, you can control how long Portia retains these OAuth tokens for. Within the org settings tab in the dashboard you can update your organization retention policy to one of the below options.

![Token Retention Policies](/img/token_retention.png)

### Default

Under the default policy, Portia will store the encrypted token until it expires. We will also store any refresh tokens provided by the third party if they support this. 

This retention policy is best for usability as it minimizes the number of times users will need to go through the OAuth authentication flow. 

### No refresh

Under the No Refresh policy, Portia will store the encrypted tokens until they expire. However no refresh tokens will be stored. 

This policy offers a blend of security and usability, with tokens being stored for a far shorter length of time (usually 24 hours though it depends on the third party).
</file>

<file path="docs/product/Telemetry/_category_.json">
{
  "label": "Telemetry",
  "position": 8,
  "link": {
    "type": "generated-index",
    "slug": "telemetry",
    "description": "Understand Portia's telemetry and privacy settings"
  }
}
</file>

<file path="docs/product/Telemetry/Telemetry Overview.md">
---
sidebar_position: 1
slug: /telemetry
---

:::tip
By default, the telemetry data collected by the library is not personally identifiable information under GDPR and other privacy regulations as the data is deliberately anonymized.

The anonymized data collected is described in detail below. Collecting this data helps us understand how the library is being used and to improve the user experience. It also helps us fix bugs faster and prioritize feature development.
:::

# Data collection
We use **PostHog** for telemetry collection. The data is completely anonymized and contains no personally identifiable information.

We track the following events.

### Portia function calls
We track the following Portia function calls:
- `Portia.run`
- `Portia.plan`
- `Portia.run_plan`
- `Portia.resume`
- `Portia.execute_plan_run_and_handle_clarifications`
- `Portia.resolve_clarification`
- `Portia.wait_for_ready`
- `Portia.create_plan_run`

For each of these, we track usage of features and tool IDs, e.g for `Portia.run`:

```python skip=true skip_reason=not_expecting_code_to_be_run
self.telemetry.capture(PortiaFunctionCallTelemetryEvent(
    function_name='portia_run', function_args={
        'tools': ",".join([tool.id if isinstance(tool, Tool) else tool for tool in tools]) if tools else None,
        'example_plans_provided': example_plans != None, # Whether examples plan were provided.
        'end_user_provided': end_user != None, # Whether an end user was used.
        'plan_run_inputs_provided': plan_run_inputs != None # Whether plan inputs were used.
    }
))
```

### Portia tool calls
We also track when a tool call happens and the name of the tool that was executed. None of the arguments to the tool are tracked.

# Opting out
You can disable telemetry by setting the environment variable:

```.env
ANONYMIZED_TELEMETRY=false
```
</file>

<file path="docs/SDK/portia/builder/conditionals.md">
---
sidebar_label: conditionals
title: portia.builder.conditionals
---

Types to support Conditionals.

## ConditionalBlock Objects

```python
class ConditionalBlock(BaseModel)
```

A conditional block in the plan.

This object is used to track the position of steps
in the conditional tree, if one is present.

**Arguments**:

- `clause_step_indexes` - The indexes of the conditional steps
  (i.e. the if_, else_if_, else_, endif steps).
- `parent_conditional_block` - The parent branch of this branch. If None,
  this is a root branch.

## ConditionalBlockClauseType Objects

```python
class ConditionalBlockClauseType(StrEnum)
```

The type of conditional block clause.

## ConditionalStepResult Objects

```python
class ConditionalStepResult(BaseModel)
```

Output of a conditional step.

**Arguments**:

- `type` - The type of conditional block clause that was executed.
- `conditional_result` - The result of the conditional predicate evaluation.
- `next_clause_step_index` - The step index of the next clause conditional to
  jump to if the conditional result is false.
- `end_condition_block_step_index` - The step index of the end condition block (endif).
</file>

<file path="docs/SDK/portia/builder/plan_builder_v2.md">
---
sidebar_label: plan_builder_v2
title: portia.builder.plan_builder_v2
---

Builder for Portia plans.

## PlanBuilderError Objects

```python
class PlanBuilderError(ValueError)
```

Error in Plan definition.

## PlanBuilderV2 Objects

```python
class PlanBuilderV2()
```

Builder for Portia plans.

#### \_\_init\_\_

```python
def __init__(label: str = "Run the plan built with the Plan Builder") -> None
```

Initialize the builder.

**Arguments**:

- `label` - The label of the plan. This is used to identify the plan in the Portia dashboard.

#### input

```python
def input(*,
          name: str,
          description: str | None = None,
          default_value: Any | None = None) -> PlanBuilderV2
```

Add an input to the plan.

**Arguments**:

- `name` - The name of the input.
- `description` - The description of the input.
- `default_value` - The default value of the input.

#### if\_

```python
def if_(condition: Callable[..., bool] | str,
        args: dict[str, Any] | None = None) -> PlanBuilderV2
```

Add a step that checks a condition.

#### else\_if\_

```python
def else_if_(condition: Callable[..., bool],
             args: dict[str, Any] | None = None) -> PlanBuilderV2
```

Add a step that checks a condition.

#### else\_

```python
def else_() -> PlanBuilderV2
```

Add a step that checks a condition.

#### endif

```python
def endif() -> PlanBuilderV2
```

Exit a conditional block.

#### llm\_step

```python
def llm_step(*,
             task: str,
             inputs: list[Any] | None = None,
             output_schema: type[BaseModel] | None = None,
             step_name: str | None = None) -> PlanBuilderV2
```

Add a step that sends a query to the underlying LLM.

**Arguments**:

- `task` - The task to perform.
- `inputs` - The inputs to the task. The inputs can be references to previous step outputs /
  plan inputs (using StepOutput / Input) or just plain values. They are passed in as
  additional context to the LLM when it is completing the task.
- `output_schema` - The schema of the output.
- `step_name` - Optional name for the step. If not provided, will be auto-generated.

#### invoke\_tool\_step

```python
def invoke_tool_step(*,
                     tool: str | Tool,
                     args: dict[str, Any] | None = None,
                     output_schema: type[BaseModel] | None = None,
                     step_name: str | None = None) -> PlanBuilderV2
```

Add a step that directly invokes a tool.

**Arguments**:

- `tool` - The tool to invoke. Should either be the id of the tool to call, the Tool instance
  to call, or a python function that should be called.
- `args` - The arguments to the tool. If any of these values are instances of StepOutput or
  Input, the corresponding values will be substituted in when the plan is run.
- `output_schema` - The schema of the output.
- `step_name` - Optional name for the step. If not provided, will be auto-generated.

#### function\_step

```python
def function_step(*,
                  function: Callable[..., Any],
                  args: dict[str, Any] | None = None,
                  output_schema: type[BaseModel] | None = None,
                  step_name: str | None = None) -> PlanBuilderV2
```

Add a step that directly invokes a function.

**Arguments**:

- `function` - The function to invoke.
- `args` - The arguments to the function. If any of these values are instances of StepOutput
  or Input, the corresponding values will be substituted in when the plan is run.
- `output_schema` - The schema of the output.
- `step_name` - Optional name for the step. If not provided, will be auto-generated.

#### single\_tool\_agent\_step

```python
def single_tool_agent_step(*,
                           tool: str,
                           task: str,
                           inputs: list[Any] | None = None,
                           output_schema: type[BaseModel] | None = None,
                           step_name: str | None = None) -> PlanBuilderV2
```

Add a step that uses the execution agent with a tool.

**Arguments**:

- `tool` - The tool to use.
- `task` - The task to perform.
- `inputs` - The inputs to the task. If any of these values are instances of StepOutput or
  Input, the corresponding values will be substituted in when the plan is run.
- `output_schema` - The schema of the output.
- `step_name` - Optional name for the step. If not provided, will be auto-generated.

#### final\_output

```python
def final_output(output_schema: type[BaseModel] | None = None,
                 summarize: bool = False) -> PlanBuilderV2
```

Set the final output of the plan.

**Arguments**:

- `output_schema` - The schema for the final output. If provided, an LLM will be used to
  coerce the output to this schema.
- `summarize` - Whether to summarize the final output. If True, a summary of the final output
  will be provided along with the value.

#### build

```python
def build() -> PlanV2
```

Return the plan, ready to run.
</file>

<file path="docs/SDK/portia/builder/plan_v2.md">
---
sidebar_label: plan_v2
title: portia.builder.plan_v2
---

A plan built using the PlanBuilder.

## PlanV2 Objects

```python
class PlanV2(BaseModel)
```

A sequence of steps to be run by Portia.

#### validate\_plan

```python
@model_validator(mode="after")
def validate_plan() -> PlanV2
```

Validate the plan.

#### to\_legacy\_plan

```python
def to_legacy_plan(plan_context: PlanContext) -> Plan
```

Convert the Portia plan to a legacy plan.

#### step\_output\_name

```python
def step_output_name(step: int | str | StepV2) -> str
```

Get the name of the output of a step in the plan.

#### idx\_by\_name

```python
def idx_by_name(name: str) -> int
```

Get the index of a step by name.
</file>

<file path="docs/SDK/portia/builder/reference.md">
---
sidebar_label: reference
title: portia.builder.reference
---

References to values in a plan.

#### default\_step\_name

```python
def default_step_name(step_index: int) -> str
```

Return the default name for the step.

## Reference Objects

```python
class Reference(BaseModel, ABC)
```

A reference to a value.

#### get\_legacy\_name

```python
@abstractmethod
def get_legacy_name(plan: PlanV2) -> str
```

Get the name of the reference to use with legacy Portia plans.

#### get\_value

```python
@abstractmethod
def get_value(run_data: RunContext) -> ReferenceValue | None
```

Get the value of the reference.

## StepOutput Objects

```python
class StepOutput(Reference)
```

A reference to the output of a previous step.

When building your plan, you can use this class to reference the output of a previous step.
The output from the specified step will then be substituted in when the plan is run.

See the example usage in example_builder.py for more details.

#### \_\_init\_\_

```python
def __init__(step: str | int) -> None
```

Initialize the step output.

#### get\_legacy\_name

```python
@override
def get_legacy_name(plan: PlanV2) -> str
```

Get the name of the reference to use with legacy Portia plans.

#### \_\_str\_\_

```python
def __str__() -> str
```

Get the string representation of the step output.

#### get\_value

```python
@override
def get_value(run_data: RunContext) -> ReferenceValue | None
```

Get the value of the step output.

## Input Objects

```python
class Input(Reference)
```

A reference to a plan input.

When building your plan, you can specify plan inputs using the PlanBuilder.input() method. These
are inputs whose values you provide when running the plan, rather than when building the plan.
You can then use this to reference those inputs later in your plan. When you do this, the values
will be substituted in when the plan is run.

See the example usage in example_builder.py for more details.

#### \_\_init\_\_

```python
def __init__(name: str) -> None
```

Initialize the input.

#### get\_legacy\_name

```python
@override
def get_legacy_name(plan: PlanV2) -> str
```

Get the name of the reference to use with legacy Portia plans.

#### get\_value

```python
@override
def get_value(run_data: RunContext) -> ReferenceValue | None
```

Get the value of the input.

#### \_\_str\_\_

```python
def __str__() -> str
```

Get the string representation of the input.

## ReferenceValue Objects

```python
class ReferenceValue(BaseModel)
```

Value that can be referenced.
</file>

<file path="docs/SDK/portia/builder/step_v2.md">
---
sidebar_label: step_v2
title: portia.builder.step_v2
---

Interface for steps that are run as part of a PlanV2.

## StepV2 Objects

```python
class StepV2(BaseModel, ABC)
```

Interface for steps that are run as part of a plan.

#### run

```python
@abstractmethod
async def run(run_data: RunContext) -> Any
```

Execute the step.

#### describe

```python
@abstractmethod
def describe() -> str
```

Return a description of this step for logging purposes.

#### to\_legacy\_step

```python
@abstractmethod
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this step to a Step from plan.py.

A Step is the legacy representation of a step in the plan, and is still used in the
Portia backend. If this step doesn&#x27;t need to be represented in the plan sent to the Portia
backend, return None.

## LLMStep Objects

```python
class LLMStep(StepV2)
```

A step that runs a given task through an LLM (without any tools).

#### describe

```python
@override
def describe() -> str
```

Return a description of this step for logging purposes.

#### run

```python
@override
@traceable(name="LLM Step - Run")
async def run(run_data: RunContext) -> str | BaseModel
```

Run the LLM query.

#### to\_legacy\_step

```python
@override
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this LLMStep to a Step.

## InvokeToolStep Objects

```python
class InvokeToolStep(StepV2)
```

A step that calls a tool with the given args (no LLM involved, just a direct tool call).

#### describe

```python
@override
def describe() -> str
```

Return a description of this step for logging purposes.

#### run

```python
@override
@traceable(name="Invoke Tool Step - Run")
async def run(run_data: RunContext) -> Any
```

Run the tool.

#### to\_legacy\_step

```python
@override
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this InvokeToolStep to a legacy Step.

## FunctionStep Objects

```python
class FunctionStep(StepV2)
```

Calls a function with the given args (no LLM involved, just a direct function call).

#### describe

```python
@override
def describe() -> str
```

Return a description of this step for logging purposes.

#### run

```python
@override
@traceable(name="Function Step - Run")
async def run(run_data: RunContext) -> Any
```

Run the function.

#### to\_legacy\_step

```python
@override
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this FunctionStep to a legacy Step.

## SingleToolAgentStep Objects

```python
class SingleToolAgentStep(StepV2)
```

A step where an LLM agent uses a single tool (calling it only once) to complete a task.

#### describe

```python
@override
def describe() -> str
```

Return a description of this step for logging purposes.

#### run

```python
@override
@traceable(name="Single Tool Agent Step - Run")
async def run(run_data: RunContext) -> None
```

Run the agent step.

#### to\_legacy\_step

```python
@override
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this SingleToolAgentStep to a Step.

## ConditionalStep Objects

```python
class ConditionalStep(StepV2)
```

A step that represents a conditional clause in a conditional block.

I.E. if, else-if, else, end-if clauses.

#### validate\_conditional\_block

```python
@field_validator("conditional_block", mode="after")
@classmethod
def validate_conditional_block(cls,
                               v: ConditionalBlock | None) -> ConditionalBlock
```

Validate the conditional block.

#### block

```python
@property
def block() -> ConditionalBlock
```

Get the conditional block for this step.

#### describe

```python
@override
def describe() -> str
```

Return a description of this step for logging purposes.

#### run

```python
@override
@traceable(name="Conditional Step - Run")
async def run(run_data: RunContext) -> Any
```

Run the conditional step.

#### to\_legacy\_step

```python
@override
def to_legacy_step(plan: PlanV2) -> Step
```

Convert this ConditionalStep to a PlanStep.
</file>

<file path="docs/SDK/portia/execution_agents/utils/final_output_summarizer.md">
---
sidebar_label: final_output_summarizer
title: portia.execution_agents.utils.final_output_summarizer
---

Utility class for final output summarizer.

## FinalOutputSummarizer Objects

```python
class FinalOutputSummarizer()
```

Utility class responsible for summarizing the run outputs for final output&#x27;s summary.

**Attributes**:

- `config` _Config_ - The configuration for the llm.
- `agent_memory` _AgentMemory_ - The agent memory to use for the summarizer.

#### \_\_init\_\_

```python
def __init__(config: Config, agent_memory: AgentMemory) -> None
```

Initialize the summarizer agent.

**Arguments**:

- `config` _Config_ - The configuration for the llm.
- `agent_memory` _AgentMemory_ - The agent memory to use for the summarizer.

#### get\_output\_value

```python
def get_output_value(output: Output) -> str | None
```

Get the value to use for the specified output.

This ensures that introspection outputs and outputs that are too large for the LLM context
window are handled correctly.

#### create\_summary

```python
def create_summary(plan: Plan, plan_run: PlanRun) -> str | BaseModel | None
```

Execute the summarizer llm and return the summary as a string.

**Arguments**:

- `plan` _Plan_ - The plan containing the steps.
- `plan_run` _PlanRun_ - The run to summarize.
  

**Returns**:

  str | BaseModel | None: The generated summary or None if generation fails.
</file>

<file path="docs/SDK/portia/execution_agents/utils/step_summarizer.md">
---
sidebar_label: step_summarizer
title: portia.execution_agents.utils.step_summarizer
---

StepSummarizer implementation.

The StepSummarizer can be used by agents to summarize the output of a given tool.

## SummarizerOutputModel Objects

```python
class SummarizerOutputModel(BaseModel)
```

Protocol for the summarizer output model.

## StepSummarizer Objects

```python
class StepSummarizer()
```

Class to summarize the output of a tool using llm.

This is used only on the tool output message.

**Attributes**:

- `summarizer_prompt` _ChatPromptTemplate_ - The prompt template used to generate the summary.
- `model` _GenerativeModel_ - The language model used for summarization.
- `summary_max_length` _int_ - The maximum length of the summary.
- `step` _Step_ - The step that produced the output.

#### \_\_init\_\_

```python
def __init__(config: Config,
             model: GenerativeModel,
             tool: Tool,
             step: Step,
             summary_max_length: int = 500) -> None
```

Initialize the model.

**Arguments**:

- `config` _Config_ - The configuration for the run.
- `model` _GenerativeModel_ - The language model used for summarization.
- `tool` _Tool_ - The tool used for summarization.
- `step` _Step_ - The step that produced the output.
- `summary_max_length` _int_ - The maximum length of the summary. Default is 500 characters.

#### invoke

```python
def invoke(state: MessagesState) -> dict[str, Any]
```

Invoke the model with the given message state.

This method processes the last message in the state, checks if it&#x27;s a tool message with an
output, and if so, generates a summary of the tool&#x27;s output. The summary is then added to
the artifact of the last message.

**Arguments**:

- `state` _MessagesState_ - The current state of the messages, which includes the output.
  

**Returns**:

  dict[str, Any]: A dict containing the updated message state, including the summary.
  

**Raises**:

- `Exception` - If an error occurs during the invocation of the summarizer model.

#### ainvoke

```python
async def ainvoke(state: MessagesState) -> dict[str, Any]
```

Async implementation of invoke.

This method processes the last message in the state, checks if it&#x27;s a tool message with an
output, and if so, generates a summary of the tool&#x27;s output. The summary is then added to
the artifact of the last message.

**Arguments**:

- `state` _MessagesState_ - The current state of the messages, which includes the output.
  

**Returns**:

  dict[str, Any]: A dict containing the updated message state, including the summary.
  

**Raises**:

- `Exception` - If an error occurs during the invocation of the summarizer model.
</file>

<file path="docs/SDK/portia/execution_agents/base_execution_agent.md">
---
sidebar_label: base_execution_agent
title: portia.execution_agents.base_execution_agent
---

Agents are responsible for executing steps of a PlanRun.

The BaseAgent class is the base class that all agents must extend.

## BaseExecutionAgent Objects

```python
class BaseExecutionAgent()
```

An ExecutionAgent is responsible for carrying out the task defined in the given Step.

This BaseExecutionAgent is the class all ExecutionAgents must extend. Critically,
ExecutionAgents must implement the execute_sync function which is responsible for
actually carrying out the task as given in the step. They have access to copies of the
step, plan_run and config but changes to those objects are forbidden.

Optionally, new execution agents may also override the get_context function, which is
responsible for building the system context for the agent. This should be done with
thought, as the details of the system context are critically important for LLM
performance.

#### \_\_init\_\_

```python
def __init__(plan: Plan,
             plan_run: PlanRun,
             config: Config,
             end_user: EndUser,
             agent_memory: AgentMemory,
             tool: Tool | None = None,
             execution_hooks: ExecutionHooks | None = None) -> None
```

Initialize the base agent with the given args.

Importantly, the models here are frozen copies of those used by the Portia instance.
They are meant as read-only references, useful for execution of the task
but cannot be edited. The agent should return output via the response
of the execute_sync method.

**Arguments**:

- `plan` _Plan_ - The plan containing the steps.
- `plan_run` _PlanRun_ - The run that contains the step and related data.
- `config` _Config_ - The configuration settings for the agent.
- `end_user` _EndUser_ - The end user for the execution.
- `agent_memory` _AgentMemory_ - The agent memory for persisting outputs.
- `tool` _Tool | None_ - An optional tool associated with the agent (default is None).
- `execution_hooks` - Optional hooks for extending execution functionality.

#### step

```python
@property
def step() -> Step
```

Get the current step from the plan.

#### execute\_sync

```python
@abstractmethod
def execute_sync() -> Output
```

Run the core execution logic of the task synchronously.

Implementation of this function is deferred to individual agent implementations,
making it simple to write new ones.

**Returns**:

- `Output` - The output of the task execution.

#### execute\_async

```python
async def execute_async() -> Output
```

Run the core execution logic of the task asynchronously.

Implementation of this function is deferred to individual agent implementations,
making it simple to write new ones. If not implemented, the agent will return a threaded
version of the execute_sync method.

**Returns**:

- `Output` - The output of the task execution.

#### get\_system\_context

```python
def get_system_context(ctx: ToolRunContext,
                       step_inputs: list[StepInput]) -> str
```

Build a generic system context string from the step and run provided.

This function retrieves the execution context and generates a system context
based on the step and run provided to the agent.

**Arguments**:

- `ctx` _ToolRunContext_ - The tool run ctx.
- `step_inputs` _list[StepInput]_ - The inputs for the step.
  

**Returns**:

- `str` - A string containing the system context for the agent.

#### next\_state\_after\_tool\_call

```python
def next_state_after_tool_call(
    config: Config,
    state: MessagesState,
    tool: Tool | None = None
) -> Literal[AgentNode.TOOL_AGENT, AgentNode.SUMMARIZER, END]
```

Determine the next state after a tool call.

This function checks the state after a tool call to determine if the run
should proceed to the tool agent again, to the summarizer, or end.

**Arguments**:

- `config` _Config_ - The configuration for the run.
- `state` _MessagesState_ - The current state of the messages.
- `tool` _Tool | None_ - The tool involved in the call, if any.
  

**Returns**:

  Literal[AgentNode.TOOL_AGENT, AgentNode.SUMMARIZER, END]: The next state to transition
  to.
  

**Raises**:

- `ToolRetryError` - If the tool has an error and the maximum retry limit has not been
  reached.
</file>

<file path="docs/SDK/portia/execution_agents/clarification_tool.md">
---
sidebar_label: clarification_tool
title: portia.execution_agents.clarification_tool
---

Tool for raising clarifications if unsure on an arg.

## ClarificationToolSchema Objects

```python
class ClarificationToolSchema(BaseModel)
```

Schema defining the inputs for the ClarificationTool.

## ClarificationTool Objects

```python
class ClarificationTool(Tool[str])
```

Raises a clarification if the agent is unsure of an argument.

#### run

```python
def run(ctx: ToolRunContext, argument_name: str) -> str
```

Run the ClarificationTool.
</file>

<file path="docs/SDK/portia/execution_agents/conditional_evaluation_agent.md">
---
sidebar_label: conditional_evaluation_agent
title: portia.execution_agents.conditional_evaluation_agent
---

Conditional evaluation agent for PlanV2.

## BooleanResponse Objects

```python
class BooleanResponse(BaseModel)
```

Boolean response for conditional evaluation.

## ConditionalEvaluationAgent Objects

```python
class ConditionalEvaluationAgent()
```

Conditional evaluation agent for PlanV2.

#### \_\_init\_\_

```python
def __init__(config: Config) -> None
```

Initialize the conditional evaluation agent.

#### execute

```python
@traceable(name="Conditional Evaluation Agent - Execute")
async def execute(conditional: str, arguments: dict[str, Any]) -> bool
```

Execute the conditional evaluation agent.
</file>

<file path="docs/SDK/portia/execution_agents/context.md">
---
sidebar_label: context
title: portia.execution_agents.context
---

Context builder that generates contextual information for the PlanRun.

This module defines a set of functions that build various types of context
required for the run execution. It takes information about inputs,
outputs, clarifications, and execution metadata to build context strings
used by the agent to perform tasks. The context can be extended with
additional system or user-provided data.

#### generate\_main\_system\_context

```python
def generate_main_system_context() -> list[str]
```

Generate the main system context.

**Returns**:

- `list[str]` - A list of strings representing the system context.

## StepInput Objects

```python
class StepInput(BaseModel)
```

An input for a step being executed by an execution agent.

#### generate\_input\_context

```python
def generate_input_context(step_inputs: list[StepInput],
                           previous_outputs: dict[str, Output]) -> list[str]
```

Generate context for the inputs and indicate which ones were used.

**Arguments**:

- `step_inputs` _list[StepInput]_ - The list of inputs for the current step.
- `previous_outputs` _dict[str, Output]_ - A dictionary of previous step outputs.
  

**Returns**:

- `list[str]` - A list of strings representing the input context.

#### generate\_clarification\_context

```python
def generate_clarification_context(clarifications: ClarificationListType,
                                   step: int) -> list[str]
```

Generate context from clarifications for the given step.

**Arguments**:

- `clarifications` _ClarificationListType_ - A list of clarification objects.
- `step` _int_ - The step index for which clarifications are being generated.
  

**Returns**:

- `list[str]` - A list of strings representing the clarification context.

#### generate\_context\_from\_run\_context

```python
def generate_context_from_run_context(context: ToolRunContext) -> list[str]
```

Generate context from the execution context.

**Arguments**:

- `context` _ExecutionContext_ - The execution context containing metadata and additional data.
  

**Returns**:

- `list[str]` - A list of strings representing the execution context.

#### build\_context

```python
def build_context(ctx: ToolRunContext, plan_run: PlanRun,
                  step_inputs: list[StepInput]) -> str
```

Build the context string for the agent using inputs/outputs/clarifications/ctx.

**Arguments**:

- `ctx` _ToolRunContext_ - The tool run context containing agent and system metadata.
- `plan_run` _PlanRun_ - The current run containing outputs and clarifications.
- `step_inputs` _list[StepInput]_ - The inputs for the current step.
  

**Returns**:

- `str` - A string containing all relevant context information.
</file>

<file path="docs/SDK/portia/execution_agents/default_execution_agent.md">
---
sidebar_label: default_execution_agent
title: portia.execution_agents.default_execution_agent
---

The Default execution agent for hardest problems.

This agent uses multiple models (verifier, parser etc) to achieve the highest accuracy
in completing tasks.

## ExecutionState Objects

```python
class ExecutionState(MessagesState)
```

State for the execution agent.

## ToolArgument Objects

```python
class ToolArgument(BaseModel)
```

Represents an argument for a tool as extracted from the goal and context.

**Attributes**:

- `name` _str_ - The name of the argument, as requested by the tool.
- `explanation` _str_ - Explanation of the source for the value of the argument.
- `value` _Any | None_ - The value of the argument, as provided in the goal or context.
- `valid` _bool_ - Whether the value is a valid type and/or format for the given argument.

## ToolInputs Objects

```python
class ToolInputs(BaseModel)
```

Represents the inputs for a tool.

**Attributes**:

- `args` _list[ToolArgument]_ - Arguments for the tool.

## VerifiedToolArgument Objects

```python
class VerifiedToolArgument(BaseModel)
```

Represents an argument for a tool after being verified by an agent.

**Attributes**:

- `name` _str_ - The name of the argument, as requested by the tool.
- `value` _Any | None_ - The value of the argument, as provided in the goal or context.
- `made_up` _bool_ - Whether the value was made up or not. Should be false if the value was
  provided by the user.

## VerifiedToolInputs Objects

```python
class VerifiedToolInputs(BaseModel)
```

Represents the inputs for a tool after being verified by an agent.

**Attributes**:

- `args` _list[VerifiedToolArgument]_ - Arguments for the tool.

## ParserModel Objects

```python
class ParserModel()
```

Model to parse the arguments for a tool.

**Arguments**:

- `model` _Model_ - The language model used for argument parsing.
- `context` _str_ - The context for argument generation.
- `agent` _DefaultExecutionAgent_ - The agent using the parser model.
  

**Attributes**:

- `arg_parser_prompt` _ChatPromptTemplate_ - The prompt template for argument parsing.
- `model` _Model_ - The language model used.
- `context` _str_ - The context for argument generation.
- `agent` _DefaultExecutionAgent_ - The agent using the parser model.
- `previous_errors` _list[str]_ - A list of previous errors encountered during parsing.
- `retries` _int_ - The number of retries attempted for parsing.

#### \_\_init\_\_

```python
def __init__(model: GenerativeModel, agent: DefaultExecutionAgent,
             tool_context: ToolRunContext) -> None
```

Initialize the model.

**Arguments**:

- `model` _Model_ - The language model used for argument parsing.
- `agent` _DefaultExecutionAgent_ - The agent using the parser model.
- `tool_context` _ToolRunContext_ - The context for the tool.

#### invoke

```python
def invoke(state: ExecutionState) -> dict[str, Any]
```

Invoke the model with the given message state.

**Arguments**:

- `state` _ExecutionState_ - The current state of the conversation.
  

**Returns**:

  dict[str, Any]: The response after invoking the model.
  

**Raises**:

- `InvalidRunStateError` - If the agent&#x27;s tool is not available.

## VerifierModel Objects

```python
class VerifierModel()
```

A model to verify the arguments for a tool.

This model ensures that the arguments passed to a tool are valid, determining whether they are
&quot;made up&quot; or not based on the context and specific rules. The verification process uses an LLM
to analyze the context and tool arguments and returns a structured validation output.

**Attributes**:

- `arg_verifier_prompt` _ChatPromptTemplate_ - The prompt template used for arg verification.
- `model` _Model_ - The model used to invoke the verification process.
- `agent` _DefaultExecutionAgent_ - The agent responsible for handling the verification process.

#### \_\_init\_\_

```python
def __init__(model: GenerativeModel, agent: DefaultExecutionAgent,
             tool_context: ToolRunContext) -> None
```

Initialize the model.

**Arguments**:

- `model` _Model_ - The model used for argument verification.
- `context` _str_ - The context for argument generation.
- `agent` _DefaultExecutionAgent_ - The agent using the verifier model.
- `tool_context` _ToolRunContext_ - The context for the tool.

#### invoke

```python
def invoke(state: ExecutionState) -> dict[str, Any]
```

Invoke the model with the given message state.

**Arguments**:

- `state` _ExecutionState_ - The current state of the conversation.
  

**Returns**:

  dict[str, Any]: The response after invoking the model.
  

**Raises**:

- `InvalidRunStateError` - If the agent&#x27;s tool is not available.

## ToolCallingModel Objects

```python
class ToolCallingModel()
```

Model to call the tool with the verified arguments.

#### \_\_init\_\_

```python
def __init__(model: GenerativeModel, tools: list[StructuredTool],
             agent: DefaultExecutionAgent) -> None
```

Initialize the model.

**Arguments**:

- `model` _GenerativeModel_ - The language model used for argument parsing.
- `agent` _DefaultExecutionAgent_ - The agent using the parser model.
- `tools` _list[StructuredTool]_ - The tools to pass to the model.

#### invoke

```python
def invoke(state: ExecutionState) -> dict[str, Any]
```

Invoke the model with the given message state.

**Arguments**:

- `state` _ExecutionState_ - The current state of the conversation.
  

**Returns**:

  dict[str, Any]: The response after invoking the model.
  

**Raises**:

- `InvalidRunStateError` - If the agent&#x27;s tool is not available.

## DefaultExecutionAgent Objects

```python
class DefaultExecutionAgent(BaseExecutionAgent)
```

Agent responsible for achieving a task by using verification.

This agent does the following things:
 1. It uses an LLM to make sure that we have the right arguments for the tool, with
    explanations of the values and where they come from.
 2. It uses an LLM to make sure that the arguments are correct, and that they are labeled
    as provided, inferred or assumed.
 3. If any of the arguments are assumed, it will request a clarification.
 4. If the arguments are correct, it will call the tool and return the result to the user.
 5. If the tool fails, it will try again at least 3 times.

Also, if the agent is being called a second time, it will just jump to step 4.

Possible improvements:
 1. This approach (as well as the other agents) could be improved for arguments that are lists

#### \_\_init\_\_

```python
def __init__(plan: Plan,
             plan_run: PlanRun,
             config: Config,
             agent_memory: AgentMemory,
             end_user: EndUser,
             tool: Tool | None = None,
             execution_hooks: ExecutionHooks | None = None) -> None
```

Initialize the agent.

**Arguments**:

- `plan` _Plan_ - The plan containing the steps.
- `plan_run` _PlanRun_ - The run that defines the task execution process.
- `config` _Config_ - The configuration settings for the agent.
- `agent_memory` _AgentMemory_ - The agent memory to be used for the task.
- `end_user` _EndUser_ - The end user for this execution
- `tool` _Tool | None_ - The tool to be used for the task (optional).
- `execution_hooks` _ExecutionHooks | None_ - The execution hooks for the agent.

#### clarifications\_or\_continue

```python
def clarifications_or_continue(
        state: ExecutionState) -> Literal[AgentNode.TOOL_AGENT, END]
```

Determine if we should continue with the tool call or request clarifications instead.

**Arguments**:

- `state` _ExecutionState_ - The current state of the conversation.
  

**Returns**:

  Literal[AgentNode.TOOL_AGENT, END]: The next node we should route to.

#### get\_last\_resolved\_clarification

```python
def get_last_resolved_clarification(arg_name: str) -> Clarification | None
```

Return the last argument clarification that matches the given arg_name.

**Arguments**:

- `arg_name` _str_ - The name of the argument to match clarifications for
  

**Returns**:

  Clarification | None: The matched clarification

#### execute\_sync

```python
def execute_sync() -> Output
```

Run the core execution logic of the task.

This method will invoke the tool with arguments that are parsed and verified first.

**Returns**:

- `Output` - The result of the agent&#x27;s execution, containing the tool call result.
</file>

<file path="docs/SDK/portia/execution_agents/execution_utils.md">
---
sidebar_label: execution_utils
title: portia.execution_agents.execution_utils
---

Agent execution utilities.

This module contains utility functions for managing agent execution flow.

## AgentNode Objects

```python
class AgentNode(str, Enum)
```

Nodes for agent execution.

This enumeration defines the different types of nodes that can be encountered
during the agent execution process.

**Attributes**:

- `TOOL_AGENT` _str_ - A node representing the tool agent.
- `SUMMARIZER` _str_ - A node representing the summarizer.
- `TOOLS` _str_ - A node representing the tools.
- `ARGUMENT_VERIFIER` _str_ - A node representing the argument verifier.
- `ARGUMENT_PARSER` _str_ - A node representing the argument parser.
- `MEMORY_EXTRACTION` _str_ - A node representing the memory extraction step.

#### is\_clarification

```python
def is_clarification(artifact: Any) -> bool
```

Check if the artifact is a clarification or list of clarifications.

#### tool\_call\_or\_end

```python
def tool_call_or_end(state: MessagesState) -> Literal[AgentNode.TOOLS, END]
```

Determine if tool execution should continue.

This function checks if the current state indicates that the tool execution
should continue, or if the run should end.

**Arguments**:

- `state` _MessagesState_ - The current state of the messages.
  

**Returns**:

  Literal[AgentNode.TOOLS, END]: The next state to transition to.

#### get\_arg\_value\_with\_templating

```python
def get_arg_value_with_templating(step_inputs: list[StepInput],
                                  arg: Any) -> Any
```

Return the value of an argument, handling any templating required.

#### template\_in\_required\_inputs

```python
def template_in_required_inputs(response: BaseMessage,
                                step_inputs: list[StepInput]) -> BaseMessage
```

Template any required inputs into the tool calls.

#### process\_output

```python
def process_output(
        step: Step,
        messages: list[BaseMessage],
        tool: Tool | None = None,
        clarifications: list[Clarification] | None = None) -> Output
```

Process the output of the agent.

This function processes the agent&#x27;s output based on the type of message received.
It raises errors if the tool encounters issues and returns the appropriate output.

**Arguments**:

- `step` _Step_ - The step that produced the output.
- `messages` _list[BaseMessage]_ - The set of messages received from the agent&#x27;s plan_run.
- `tool` _Tool | None_ - The tool associated with the agent, if any.
- `clarifications` _list[Clarification] | None_ - A list of clarifications, if any.
  

**Returns**:

- `Output` - The processed output, which can be an error, tool output, or clarification.
  

**Raises**:

- `ToolRetryError` - If there was a soft error with the tool and retries are allowed.
- `ToolFailedError` - If there was a hard error with the tool.
- `InvalidAgentOutputError` - If the output from the agent is invalid.

#### is\_soft\_tool\_error

```python
def is_soft_tool_error(message: BaseMessage) -> bool
```

Check if the message is a soft tool error.
</file>

<file path="docs/SDK/portia/execution_agents/memory_extraction.md">
---
sidebar_label: memory_extraction
title: portia.execution_agents.memory_extraction
---

Memory extraction step for execution agents.

This module provides a step that extracts memory from previous outputs for use in execution agents.

## MemoryExtractionStep Objects

```python
class MemoryExtractionStep()
```

A step that extracts memory from the context.

#### \_\_init\_\_

```python
def __init__(agent: BaseExecutionAgent) -> None
```

Initialize the memory extraction step.

**Arguments**:

- `agent` _BaseExecutionAgent_ - The agent using the memory extraction step.

#### invoke

```python
def invoke(_: dict[str, Any]) -> dict[str, Any]
```

Invoke the model with the given message state.

**Returns**:

  dict[str, Any]: The LangGraph state update to step_inputs
</file>

<file path="docs/SDK/portia/execution_agents/one_shot_agent.md">
---
sidebar_label: one_shot_agent
title: portia.execution_agents.one_shot_agent
---

A simple OneShotAgent optimized for simple tool calling tasks.

This agent invokes the OneShotToolCallingModel up to four times, but each individual
attempt is a one-shot call. It is useful when the tool call is simple, minimizing cost.
However, for more complex tool calls, the DefaultExecutionAgent is recommended as it will
be more successful than the OneShotAgent.

## ExecutionState Objects

```python
class ExecutionState(MessagesState)
```

State for the execution agent.

## OneShotToolCallingModel Objects

```python
class OneShotToolCallingModel()
```

One-shot model for calling a given tool.

This model directly passes the tool and context to the language model (LLM)
to generate a response. It is suitable for simple tasks where the arguments
are already correctly formatted and complete. This model does not validate
arguments (e.g., it will not catch missing arguments).

It is recommended to use the DefaultExecutionAgent for more complex tasks.

**Arguments**:

- `model` _GenerativeModel_ - The language model to use for generating responses.
- `tools` _list[StructuredTool]_ - A list of tools that can be used during the task.
- `agent` _OneShotAgent_ - The agent responsible for managing the task.
  

**Methods**:

- `invoke(MessagesState)` - Invokes the LLM to generate a response based on the query, context,
  and past errors.

#### \_\_init\_\_

```python
def __init__(model: GenerativeModel, tools: list[StructuredTool],
             agent: OneShotAgent, tool_context: ToolRunContext) -> None
```

Initialize the OneShotToolCallingModel.

**Arguments**:

- `model` _GenerativeModel_ - The language model to use for generating responses.
- `tools` _list[StructuredTool]_ - A list of tools that can be used during the task.
- `agent` _OneShotAgent_ - The agent that is managing the task.
- `tool_context` _ToolRunContext_ - The context for the tool.

#### invoke

```python
def invoke(state: ExecutionState) -> dict[str, Any]
```

Invoke the model with the given message state.

This method formats the input for the language model using the query, context,
and past errors, then generates a response by invoking the model.

**Arguments**:

- `state` _ExecutionState_ - The state containing the messages and other necessary data.
  

**Returns**:

  dict[str, Any]: A dictionary containing the model&#x27;s generated response.

#### ainvoke

```python
async def ainvoke(state: ExecutionState) -> dict[str, Any]
```

Async implementation of invoke.

This method formats the input for the language model using the query, context,
and past errors, then generates a response by invoking the model.

**Arguments**:

- `state` _ExecutionState_ - The state containing the messages and other necessary data.
  

**Returns**:

  dict[str, Any]: A dictionary containing the model&#x27;s generated response.

## OneShotAgent Objects

```python
class OneShotAgent(BaseExecutionAgent)
```

Agent responsible for achieving a task by using langgraph.

This agent performs the following steps:
1. Extracts inputs from agent memory (if applicable)
2. Calls the tool with unverified arguments.
3. Retries tool calls up to 4 times.

**Methods**:

- `execute_sync()` - Executes the core logic of the agent&#x27;s task, using the provided tool

#### \_\_init\_\_

```python
def __init__(plan: Plan,
             plan_run: PlanRun,
             config: Config,
             agent_memory: AgentMemory,
             end_user: EndUser,
             tool: Tool | None = None,
             execution_hooks: ExecutionHooks | None = None) -> None
```

Initialize the OneShotAgent.

**Arguments**:

- `plan` _Plan_ - The plan containing the steps.
- `plan_run` _PlanRun_ - The run that defines the task execution process.
- `config` _Config_ - The configuration settings for the agent.
- `agent_memory` _AgentMemory_ - The agent memory for persisting outputs.
- `end_user` _EndUser_ - The end user for the execution.
- `tool` _Tool | None_ - The tool to be used for the task (optional).
- `execution_hooks` _ExecutionHooks | None_ - The execution hooks for the agent.

#### execute\_sync

```python
def execute_sync() -> Output
```

Run the core execution logic of the task.

This method will invoke the tool with arguments

**Returns**:

- `Output` - The result of the agent&#x27;s execution, containing the tool call result.

#### execute\_async

```python
async def execute_async() -> Output
```

Run the core execution logic of the task.

This method will invoke the tool with arguments

**Returns**:

- `Output` - The result of the agent&#x27;s execution, containing the tool call result.
</file>

<file path="docs/SDK/portia/execution_agents/output.md">
---
sidebar_label: output
title: portia.execution_agents.output
---

Outputs from a plan run step.

These are stored and can be used as inputs to future steps

## BaseOutput Objects

```python
class BaseOutput(BaseModel)
```

Base interface for concrete output classes to implement.

#### get\_value

```python
@abstractmethod
def get_value() -> Serializable | None
```

Return the value of the output.

This should not be so long that it is an issue for LLM prompts.

#### serialize\_value

```python
@abstractmethod
def serialize_value() -> str
```

Serialize the value to a string.

#### full\_value

```python
@abstractmethod
def full_value(agent_memory: AgentMemory) -> Serializable | None
```

Get the full value, fetching from remote storage or file if necessary.

This value may be long and so is not suitable for use in LLM prompts.

#### get\_summary

```python
@abstractmethod
def get_summary() -> str | None
```

Return the summary of the output.

## LocalDataValue Objects

```python
class LocalDataValue(BaseOutput)
```

Output that is stored locally.

#### get\_value

```python
def get_value() -> Serializable | None
```

Get the value of the output.

#### serialize\_value

```python
def serialize_value() -> str
```

Serialize the value to a string.

#### full\_value

```python
def full_value(agent_memory: AgentMemory) -> Serializable | None
```

Return the full value.

As the value is stored locally, this is the same as get_value() for this type of output.

#### get\_summary

```python
def get_summary() -> str | None
```

Return the summary of the output.

#### serialize\_value\_field

```python
@field_serializer("value")
def serialize_value_field(value: Serializable | None) -> str
```

Serialize the value to a string.

**Arguments**:

- `value` _SERIALIZABLE_TYPE_VAR | None_ - The value to serialize.
  

**Returns**:

- `str` - The serialized value as a string.

## AgentMemoryValue Objects

```python
class AgentMemoryValue(BaseOutput)
```

Output that is stored in agent memory.

#### get\_value

```python
def get_value() -> Serializable | None
```

Return the summary of the output as the value is too large to be retained locally.

#### serialize\_value

```python
def serialize_value() -> str
```

Serialize the value to a string.

We use the summary as the value is too large to be retained locally.

#### full\_value

```python
def full_value(agent_memory: AgentMemory) -> Serializable | None
```

Get the full value, fetching from remote storage or file if necessary.

#### get\_summary

```python
def get_summary() -> str
```

Return the summary of the output.

## LocalOutput Objects

```python
@deprecated(
    "LocalOutput is deprecated and will be removed in the 0.4 release - "
    "use LocalDataValue instead"
)
class LocalOutput(LocalDataValue)
```

Alias of LocalDataValue kept for backwards compatibility.

## AgentMemoryOutput Objects

```python
@deprecated(
    "AgentMemoryOutput is deprecated and will be removed in the 0.4 release - "
    "use AgentMemoryValue instead"
)
class AgentMemoryOutput(AgentMemoryValue)
```

Alias of AgentMemoryValue kept for backwards compatibility.
</file>

<file path="docs/SDK/portia/introspection_agents/default_introspection_agent.md">
---
sidebar_label: default_introspection_agent
title: portia.introspection_agents.default_introspection_agent
---

The default introspection agent.

This agent looks at the state of a plan run between steps
and makes decisions about whether execution should continue.

## DefaultIntrospectionAgent Objects

```python
class DefaultIntrospectionAgent(BaseIntrospectionAgent)
```

Default Introspection Agent.

Implements the BaseIntrospectionAgent interface using an LLM to make decisions about what to do.

**Attributes**:

- `config` _Config_ - Configuration settings for the DefaultIntrospectionAgent.

#### \_\_init\_\_

```python
def __init__(config: Config, agent_memory: AgentMemory) -> None
```

Initialize the DefaultIntrospectionAgent with configuration.

**Arguments**:

- `config` _Config_ - The configuration to initialize the DefaultIntrospectionAgent.
- `agent_memory` _AgentMemory_ - The agent memory to use

#### pre\_step\_introspection

```python
def pre_step_introspection(plan: Plan,
                           plan_run: PlanRun) -> PreStepIntrospection
```

Ask the LLM whether to continue, skip or fail the plan_run.

#### apre\_step\_introspection

```python
async def apre_step_introspection(plan: Plan,
                                  plan_run: PlanRun) -> PreStepIntrospection
```

pre_step_introspection is introspection run before a plan happens..
</file>

<file path="docs/SDK/portia/introspection_agents/introspection_agent.md">
---
sidebar_label: introspection_agent
title: portia.introspection_agents.introspection_agent
---

BaseIntrospectionAgent is the interface for all introspection agents.

## PreStepIntrospectionOutcome Objects

```python
class PreStepIntrospectionOutcome(PortiaEnum)
```

The Outcome of the introspection.

## PreStepIntrospection Objects

```python
class PreStepIntrospection(BaseModel)
```

The outcome of a pre-step introspection.

## BaseIntrospectionAgent Objects

```python
class BaseIntrospectionAgent(ABC)
```

Interface for introspection.

This class defines the interface for introspection.
By introspection we mean looking at the state of a plan run and making decisions
about whether to continue.

**Attributes**:

- `config` _Config_ - Configuration settings for the PlanningAgent.

#### \_\_init\_\_

```python
def __init__(config: Config, agent_memory: AgentMemory) -> None
```

Initialize the BaseIntrospectionAgent with configuration.

**Arguments**:

- `config` _Config_ - The configuration to initialize the BaseIntrospectionAgent.
- `agent_memory` _AgentMemory_ - The agent memory to use

#### pre\_step\_introspection

```python
@abstractmethod
def pre_step_introspection(plan: Plan,
                           plan_run: PlanRun) -> PreStepIntrospection
```

pre_step_introspection is introspection run before a plan happens..

#### apre\_step\_introspection

```python
async def apre_step_introspection(plan: Plan,
                                  plan_run: PlanRun) -> PreStepIntrospection
```

pre_step_introspection is introspection run before a plan happens..
</file>

<file path="docs/SDK/portia/open_source_tools/browser_tool.md">
---
sidebar_label: browser_tool
title: portia.open_source_tools.browser_tool
---

Browser tools.

This module contains tools that can be used to navigate to a URL, authenticate the user,
and complete tasks.

The browser tool can run locally or using [Browserbase](https://browserbase.com/). If using
Browserbase, a Browserbase API key is required and project ID is required, and the tool can handle
separate end user authentication.

The browser tool can be used to navigate to a URL and complete tasks. If authentication is
required, the tool will return an ActionClarification with the user guidance and login URL.
If authentication is not required, the tool will return the task output. It uses
(BrowserUse)[https://browser-use.com/] for the task navigation.

## BrowserToolForUrlSchema Objects

```python
class BrowserToolForUrlSchema(BaseModel)
```

Input schema for the BrowserToolForUrl.

This schema defines the expected input parameters for the BrowserToolForUrl class.

**Attributes**:

- `task` _str_ - The task description that should be performed by the browser tool.
  This is a required field that specifies what actions should be taken
  on the predefined URL.
- `task_data` _list[Any] | str | None_ - Task data that should be used to complete the task.
  Can be a string, a list of strings, or a list of objects that will be converted to
  strings. Important: This should include all relevant data in their entirety,
  from the first to the last character (i.e. NOT a summary).

## BrowserToolSchema Objects

```python
class BrowserToolSchema(BaseModel)
```

Input schema for the BrowserTool.

This schema defines the expected input parameters for the BrowserTool class.

**Attributes**:

- `url` _str_ - The URL that the browser tool should navigate to.
  This is a required field specifying the target webpage.
- `task` _str_ - The task description that should be performed by the browser tool.
  This is a required field that specifies what actions should be taken
  on the provided URL.
- `task_data` _list[Any] | str | None_ - Task data that should be used to complete the task.
  Can be a string, a list of strings, or a list of objects that will be converted to
  strings. Important: This should include all relevant data in their entirety,
  from the first to the last character (i.e. NOT a summary).

## BrowserTaskOutput Objects

```python
class BrowserTaskOutput(BaseModel, Generic[T])
```

Output schema for browser task execution.

This class represents the response from executing a browser task,
including both the task result and any authentication requirements.

**Attributes**:

- `task_output` _T_ - The result or output from executing the requested task.
- `human_login_required` _bool_ - Indicates if manual user authentication is needed.
  Defaults to False.
- `login_url` _str, optional_ - The URL where the user needs to go to authenticate.
  Only provided when human_login_required is True.
- `user_login_guidance` _str, optional_ - Instructions for the user on how to complete
  the login process. Only provided when human_login_required is True.

## BrowserInfrastructureOption Objects

```python
class BrowserInfrastructureOption(Enum)
```

Enumeration of supported browser infrastructure providers.

This enum defines the available options for running browser automation tasks.

**Attributes**:

- `LOCAL` - Uses a local Chrome browser instance for automation.
  Suitable for development and testing.
- `BROWSERBASE` - Uses the Browserbase cloud service for automation.
  Provides better scalability and isolation between users.

## BrowserTool Objects

```python
class BrowserTool(Tool[str | BaseModel])
```

General purpose browser tool. Customizable to user requirements.

This tool is designed to be used for tasks that require a browser. If authentication is
required, the tool will return an ActionClarification with the user guidance and login URL.
If authentication is not required, the tool will return the task output. It uses
(BrowserUse)[https://browser-use.com/] for the task navigation.

When using the tool, you should ensure that once the user has authenticated, that they
indicate that authentication is completed and resume the plan run.

The tool supports both local and BrowserBase infrastructure providers for running the web
based tasks. If using local, a local Chrome instance will be used, and the tool will not
support end_user_id. If using BrowserBase, a BrowserBase API key is required and the tool
can handle separate end users. The infrastructure provider can be specified using the
`infrastructure_option` argument.

**Arguments**:

- `id` _str, optional_ - Custom identifier for the tool. Defaults to &quot;browser_tool&quot;.
- `name` _str, optional_ - Display name for the tool. Defaults to &quot;Browser Tool&quot;.
- `description` _str, optional_ - Custom description of the tool&#x27;s purpose. Defaults to a
  general description of the browser tool&#x27;s capabilities.
- `infrastructure_option` _BrowserInfrastructureOption, optional_ - The infrastructure
  provider to use. Can be either `BrowserInfrastructureOption.LOCAL` or
  `BrowserInfrastructureOption.REMOTE`. Defaults to
  `BrowserInfrastructureOption.REMOTE`.
- `custom_infrastructure_provider` _BrowserInfrastructureProvider, optional_ - A custom
  infrastructure provider to use. If not provided, the infrastructure provider will be
  resolved from the `infrastructure_option` argument.
- `id`0 _BaseModel, optional_ - A Pydantic model to use for structured
  output. If not provided, the tool will return a string.

#### infrastructure\_provider

```python
@cached_property
def infrastructure_provider() -> BrowserInfrastructureProvider
```

Get the infrastructure provider instance (cached).

#### process\_task\_data

```python
@staticmethod
def process_task_data(task_data: list[Any] | str | None) -> str
```

Process task_data into a string, handling different input types.

**Arguments**:

- `task_data` - Data that can be a None, a string or a list of objects.
  

**Returns**:

  A string representation of the data, with list items joined by newlines.

#### run

```python
def run(
    ctx: ToolRunContext,
    url: str,
    task: str,
    task_data: list[Any] | str | None = None
) -> str | BaseModel | ActionClarification
```

Run the BrowserTool.

## BrowserToolForUrl Objects

```python
class BrowserToolForUrl(BrowserTool)
```

Browser tool for a specific URL.

This tool is designed to be used for browser-based tasks on the specified URL.
If authentication is required, the tool will return an ActionClarification with the user
guidance and login URL. If authentication is not required, the tool will return the task
output. It uses (BrowserUse)[https://browser-use.com/] for the task navigation.

When using the tool, the developer should ensure that once the user has completed
authentication, that they resume the plan run.

The tool supports both local and BrowserBase infrastructure providers for running the web
based tasks. If using local, a local Chrome instance will be used, and the tool will not
support end_user_id. If using BrowserBase, a BrowserBase API key is required and the tool
can handle separate end users. The infrastructure provider can be specified using the
`infrastructure_option` argument.

**Arguments**:

- `url` _str_ - The URL that this browser tool will navigate to for all tasks.
- `id` _str, optional_ - Custom identifier for the tool. If not provided, will be generated
  based on the URL&#x27;s domain.
- `name` _str, optional_ - Display name for the tool. If not provided, will be generated
  based on the URL&#x27;s domain.
- `description` _str, optional_ - Custom description of the tool&#x27;s purpose. If not provided,
  will be generated with the URL.
- `infrastructure_option` _BrowserInfrastructureOption, optional_ - The infrastructure
  provider to use. Can be either `BrowserInfrastructureOption.LOCAL` or
  `BrowserInfrastructureOption.REMOTE`. Defaults to
  `BrowserInfrastructureOption.REMOTE`.
- `custom_infrastructure_provider` _BrowserInfrastructureProvider, optional_ - A custom
  infrastructure provider to use. If not provided, the infrastructure provider will be
  resolved from the `infrastructure_option` argument.

#### \_\_init\_\_

```python
def __init__(
    url: str,
    id: str | None = None,
    name: str | None = None,
    description: str | None = None,
    model: GenerativeModel | None | str = NotSet,
    infrastructure_option: BrowserInfrastructureOption | None = NotSet
) -> None
```

Initialize the BrowserToolForUrl.

#### run

```python
def run(
    ctx: ToolRunContext,
    task: str,
    task_data: list[Any] | str | None = None
) -> str | BaseModel | ActionClarification
```

Run the BrowserToolForUrl.

## BrowserInfrastructureProvider Objects

```python
class BrowserInfrastructureProvider(ABC)
```

Abstract base class for browser infrastructure providers.

#### setup\_browser

```python
@abstractmethod
def setup_browser(ctx: ToolRunContext) -> Browser
```

Get a Browser instance.

This is called at the start of every step using this tool.

#### construct\_auth\_clarification\_url

```python
@abstractmethod
def construct_auth_clarification_url(ctx: ToolRunContext,
                                     sign_in_url: str) -> HttpUrl
```

Construct the URL for the auth clarification.

#### step\_complete

```python
@abstractmethod
def step_complete(ctx: ToolRunContext) -> None
```

Call when the step is complete to e.g. release the session if needed.

## BrowserInfrastructureProviderLocal Objects

```python
class BrowserInfrastructureProviderLocal(BrowserInfrastructureProvider)
```

Browser infrastructure provider for local browser instances.

#### \_\_init\_\_

```python
def __init__(chrome_path: str | None = None,
             extra_chromium_args: list[str] | None = None) -> None
```

Initialize the BrowserInfrastructureProviderLocal.

#### setup\_browser

```python
def setup_browser(ctx: ToolRunContext) -> Browser
```

Get a Browser instance.

Note: This provider does not support end_user_id.

**Arguments**:

- `ctx` _ToolRunContext_ - The context for the tool run, containing execution context
  and other relevant information.
  

**Returns**:

- `Browser` - A configured Browser instance for local browser automation.

#### construct\_auth\_clarification\_url

```python
def construct_auth_clarification_url(ctx: ToolRunContext,
                                     sign_in_url: str) -> HttpUrl
```

Construct the URL for the auth clarification.

**Arguments**:

- `ctx` _ToolRunContext_ - The context for the tool run, containing execution context
  and other relevant information.
- `sign_in_url` _str_ - The URL that the user needs to sign in to.
  

**Returns**:

- `HttpUrl` - The URL for the auth clarification, which in this case is simply the sign-in
  URL passed directly through.

#### get\_chrome\_instance\_path

```python
def get_chrome_instance_path() -> str
```

Get the path to the Chrome instance based on the operating system or env variable.

**Returns**:

- `str` - The path to the Chrome executable. First checks for the
  PORTIA_BROWSER_LOCAL_CHROME_EXEC environment variable, then falls back to default
  locations based on the operating system.
  

**Raises**:

- `RuntimeError` - If the platform is not supported (not macOS, Windows, or Linux) and the
  env variable isn&#x27;t set.

#### step\_complete

```python
def step_complete(ctx: ToolRunContext) -> None
```

Call when the step is complete to e.g release the session.

#### get\_extra\_chromium\_args

```python
def get_extra_chromium_args() -> list[str] | None
```

Get the extra Chromium arguments.

**Returns**:

  list[str] | None: A list of extra Chromium arguments if the environment variable
  is set, otherwise None.
</file>

<file path="docs/SDK/portia/open_source_tools/calculator_tool.md">
---
sidebar_label: calculator_tool
title: portia.open_source_tools.calculator_tool
---

Simple Calculator Implementation.

#### safe\_eval

```python
def safe_eval(node: Any) -> Any
```

Walk expression safely.

#### safe\_evaluate

```python
def safe_evaluate(expression: str) -> float
```

Use ast.safe_eval to evaluate expression.

## CalculatorToolSchema Objects

```python
class CalculatorToolSchema(BaseModel)
```

Input for the CalculatorTool.

## CalculatorTool Objects

```python
class CalculatorTool(Tool[float])
```

Takes a basic maths question in natural language and returns the result.

Works best for maths expressions containing only numbers and the operators +, -, *, x, /.

#### run

```python
def run(_: ToolRunContext, math_question: str) -> float
```

Run the CalculatorTool.

#### math\_expression

```python
def math_expression(prompt: str) -> str
```

Convert words and phrases to standard operators.
</file>

<file path="docs/SDK/portia/open_source_tools/crawl_tool.md">
---
sidebar_label: crawl_tool
title: portia.open_source_tools.crawl_tool
---

Tool to crawl websites.

## CrawlToolSchema Objects

```python
class CrawlToolSchema(BaseModel)
```

Input for CrawlTool.

## CrawlTool Objects

```python
class CrawlTool(Tool[str])
```

Crawls websites using graph-based traversal tool.

#### run

```python
def run(_: ToolRunContext,
        url: str,
        instructions: str | None = None,
        max_depth: int = DEFAULT_MAX_DEPTH,
        max_breadth: int = DEFAULT_MAX_BREADTH,
        limit: int = DEFAULT_LIMIT,
        select_paths: list[str] | None = None,
        select_domains: list[str] | None = None,
        exclude_paths: list[str] | None = None,
        exclude_domains: list[str] | None = None,
        allow_external: bool = False) -> str
```

Run the crawl tool.
</file>

<file path="docs/SDK/portia/open_source_tools/extract_tool.md">
---
sidebar_label: extract_tool
title: portia.open_source_tools.extract_tool
---

Tool to extract web page content from one or more URLs.

## ExtractToolSchema Objects

```python
class ExtractToolSchema(BaseModel)
```

Input for ExtractTool.

## ExtractTool Objects

```python
class ExtractTool(Tool[str])
```

Extracts the web page content from one or more URLs provided.

#### run

```python
def run(_: ToolRunContext,
        urls: list[str],
        include_images: bool = True,
        include_favicon: bool = True,
        extract_depth: str = "basic",
        format: str = "markdown") -> str
```

Run the extract tool.
</file>

<file path="docs/SDK/portia/open_source_tools/image_understanding_tool.md">
---
sidebar_label: image_understanding_tool
title: portia.open_source_tools.image_understanding_tool
---

Tool for responding to prompts and completing tasks that are related to image understanding.

## ImageUnderstandingToolSchema Objects

```python
class ImageUnderstandingToolSchema(BaseModel)
```

Input for Image Understanding Tool.

#### check\_image\_url\_or\_file

```python
@model_validator(mode="after")
def check_image_url_or_file() -> Self
```

Check that only one of image_url or image_file is provided.

## ImageUnderstandingTool Objects

```python
class ImageUnderstandingTool(Tool[str])
```

General purpose image understanding tool. Customizable to user requirements.

#### run

```python
def run(ctx: ToolRunContext, **kwargs: Any) -> str
```

Run the ImageTool.
</file>

<file path="docs/SDK/portia/open_source_tools/llm_tool.md">
---
sidebar_label: llm_tool
title: portia.open_source_tools.llm_tool
---

Tool for responding to prompts and completing tasks that don&#x27;t require other tools.

## LLMToolSchema Objects

```python
class LLMToolSchema(BaseModel)
```

Input for LLM Tool.

## LLMTool Objects

```python
class LLMTool(Tool[str | BaseModel])
```

General purpose LLM tool. Customizable to user requirements. Won&#x27;t call other tools.

#### process\_task\_data

```python
@staticmethod
def process_task_data(task_data: list[Any] | str | None) -> str
```

Process task_data into a string, handling different input types.

**Arguments**:

- `task_data` - Data that can be a None, a string or a list of objects.
  

**Returns**:

  A string representation of the data, with list items joined by newlines.

#### run

```python
def run(ctx: ToolRunContext,
        task: str,
        task_data: list[Any] | str | None = None) -> str | BaseModel
```

Run the LLMTool.

#### arun

```python
async def arun(ctx: ToolRunContext,
               task: str,
               task_data: list[Any] | str | None = None) -> str | BaseModel
```

Run the LLMTool asynchronously.
</file>

<file path="docs/SDK/portia/open_source_tools/local_file_reader_tool.md">
---
sidebar_label: local_file_reader_tool
title: portia.open_source_tools.local_file_reader_tool
---

Tool for reading files from disk.

## FileReaderToolSchema Objects

```python
class FileReaderToolSchema(BaseModel)
```

Schema defining the inputs for the FileReaderTool.

## FileReaderTool Objects

```python
class FileReaderTool(Tool[str])
```

Finds and reads content from a local file on Disk.

#### run

```python
def run(ctx: ToolRunContext, filename: str) -> str | Clarification
```

Run the FileReaderTool.

#### find\_file

```python
def find_file(file_path: Path) -> list[str]
```

Return a full file path or None.
</file>

<file path="docs/SDK/portia/open_source_tools/local_file_writer_tool.md">
---
sidebar_label: local_file_writer_tool
title: portia.open_source_tools.local_file_writer_tool
---

Local file writer tool.

## FileWriterToolSchema Objects

```python
class FileWriterToolSchema(BaseModel)
```

Schema defining the inputs for the FileWriterTool.

## FileWriterTool Objects

```python
class FileWriterTool(Tool[str])
```

Writes content to a file.

#### run

```python
def run(_: ToolRunContext, filename: str, content: str) -> str
```

Run the FileWriterTool.
</file>

<file path="docs/SDK/portia/open_source_tools/map_tool.md">
---
sidebar_label: map_tool
title: portia.open_source_tools.map_tool
---

Tool to map websites.

## MapToolSchema Objects

```python
class MapToolSchema(BaseModel)
```

Input for MapTool.

## MapTool Objects

```python
class MapTool(Tool[str])
```

Maps websites using Tavily&#x27;s graph-based traversal to generate comprehensive site maps.

#### run

```python
def run(_: ToolRunContext,
        url: str,
        max_depth: int = 1,
        max_breadth: int = 20,
        limit: int = 50,
        instructions: str | None = None,
        **kwargs: Any) -> str
```

Run the map tool.
</file>

<file path="docs/SDK/portia/open_source_tools/pdf_reader_tool.md">
---
sidebar_label: pdf_reader_tool
title: portia.open_source_tools.pdf_reader_tool
---

Tool for reading PDF files and extracting text content using Mistral OCR.

## PDFReaderToolSchema Objects

```python
class PDFReaderToolSchema(BaseModel)
```

Input for PDFReaderTool.

## PDFReaderTool Objects

```python
class PDFReaderTool(Tool[str])
```

Read a PDF file and extract its text content using Mistral OCR.

#### run

```python
def run(_: ToolRunContext, file_path: str) -> str
```

Run the PDFReaderTool.
</file>

<file path="docs/SDK/portia/open_source_tools/search_tool.md">
---
sidebar_label: search_tool
title: portia.open_source_tools.search_tool
---

Simple Search Tool.

## SearchToolSchema Objects

```python
class SearchToolSchema(BaseModel)
```

Input for SearchTool.

## SearchTool Objects

```python
class SearchTool(Tool[str])
```

Searches the internet to find answers to the search query provided..

#### run

```python
def run(_: ToolRunContext, search_query: str) -> str
```

Run the Search Tool.

#### arun

```python
async def arun(_: ToolRunContext, search_query: str) -> str
```

Run the Search Tool asynchronously.
</file>

<file path="docs/SDK/portia/open_source_tools/weather.md">
---
sidebar_label: weather
title: portia.open_source_tools.weather
---

Tool to get the weather from openweathermap.

## WeatherToolSchema Objects

```python
class WeatherToolSchema(BaseModel)
```

Input for WeatherTool.

## WeatherTool Objects

```python
class WeatherTool(Tool[str])
```

Get the weather for a given city.

#### run

```python
def run(_: ToolRunContext, city: str) -> str
```

Run the WeatherTool.

#### arun

```python
async def arun(_: ToolRunContext, city: str) -> str
```

Run the WeatherTool asynchronously.
</file>

<file path="docs/SDK/portia/planning_agents/base_planning_agent.md">
---
sidebar_label: base_planning_agent
title: portia.planning_agents.base_planning_agent
---

PlanningAgents module creates plans from queries.

This module contains the PlanningAgent interfaces and implementations used for generating plans
based on user queries. It supports the creation of plans using tools and example plans, and
leverages LLMs to generate detailed step-by-step plans. It also handles errors gracefully and
provides feedback in the form of error messages when the plan cannot be created.

## BasePlanningAgent Objects

```python
class BasePlanningAgent(ABC)
```

Interface for planning.

This class defines the interface for PlanningAgents that generate plans based on queries.
A PlanningAgent will implement the logic to generate a plan or an error given a query,
a list of tools, and optionally, some example plans.

**Attributes**:

- `config` _Config_ - Configuration settings for the PlanningAgent.

#### \_\_init\_\_

```python
def __init__(config: Config) -> None
```

Initialize the PlanningAgent with configuration.

**Arguments**:

- `config` _Config_ - The configuration to initialize the PlanningAgent.

#### generate\_steps\_or\_error

```python
@abstractmethod
def generate_steps_or_error(
        query: str,
        tool_list: list[Tool],
        end_user: EndUser,
        examples: list[Plan] | None = None,
        plan_inputs: list[PlanInput] | None = None) -> StepsOrError
```

Generate a list of steps for the given query.

This method should be implemented to generate a list of steps to accomplish the query based
on the provided query and tools.

**Arguments**:

- `query` _str_ - The user query to generate a list of steps for.
- `tool_list` _list[Tool]_ - A list of tools available for the plan.
- `end_user` _EndUser_ - The end user for this plan
- `examples` _list[Plan] | None_ - Optional list of example plans to guide the PlanningAgent.
- `plan_inputs` _list[PlanInput] | None_ - Optional list of PlanInput objects defining
  the inputs required for the plan.
  

**Returns**:

- `StepsOrError` - A StepsOrError instance containing either the generated steps or an error.

#### agenerate\_steps\_or\_error

```python
async def agenerate_steps_or_error(
        query: str,
        tool_list: list[Tool],
        end_user: EndUser,
        examples: list[Plan] | None = None,
        plan_inputs: list[PlanInput] | None = None) -> StepsOrError
```

Generate a list of steps for the given query asynchronously.

This method should be implemented to generate a list of steps to accomplish the query based
on the provided query and tools.

**Arguments**:

- `query` _str_ - The user query to generate a list of steps for.
- `tool_list` _list[Tool]_ - A list of tools available for the plan.
- `end_user` _EndUser_ - The end user for this plan
- `examples` _list[Plan] | None_ - Optional list of example plans to guide the PlanningAgent.
- `plan_inputs` _list[PlanInput] | None_ - Optional list of PlanInput objects defining
  the inputs required for the plan.
  

**Returns**:

- `StepsOrError` - A StepsOrError instance containing either the generated steps or an error.

## StepsOrError Objects

```python
class StepsOrError(BaseModel)
```

A list of steps or an error.

This model represents either a list of steps for a plan or an error message if
the steps could not be created.

**Attributes**:

- `steps` _list[Step]_ - The generated steps if successful.
- `error` _str | None_ - An error message if the steps could not be created.
</file>

<file path="docs/SDK/portia/planning_agents/context.md">
---
sidebar_label: context
title: portia.planning_agents.context
---

Context helpers for PlanningAgents.

#### render\_prompt\_insert\_defaults

```python
def render_prompt_insert_defaults(
        query: str,
        tool_list: list[Tool],
        end_user: EndUser,
        examples: list[Plan] | None = None,
        plan_inputs: list[PlanInput] | None = None,
        previous_errors: list[str] | None = None) -> str
```

Render the prompt for the PlanningAgent with defaults inserted if not provided.

#### default\_query\_system\_context

```python
def default_query_system_context() -> list[str]
```

Return the default system context.

#### get\_tool\_descriptions\_for\_tools

```python
def get_tool_descriptions_for_tools(
        tool_list: list[Tool]) -> list[dict[str, str]]
```

Given a list of tool names, return the descriptions of the tools.
</file>

<file path="docs/SDK/portia/planning_agents/default_planning_agent.md">
---
sidebar_label: default_planning_agent
title: portia.planning_agents.default_planning_agent
---

DefaultPlanningAgent is a single best effort attempt at planning based on the given query + tools.

## DefaultPlanningAgent Objects

```python
class DefaultPlanningAgent(BasePlanningAgent)
```

DefaultPlanningAgent class.

#### \_\_init\_\_

```python
def __init__(config: Config,
             planning_prompt: str | None = None,
             retries: int = 3) -> None
```

Init with the config.

#### generate\_steps\_or\_error

```python
def generate_steps_or_error(
        query: str,
        tool_list: list[Tool],
        end_user: EndUser,
        examples: list[Plan] | None = None,
        plan_inputs: list[PlanInput] | None = None) -> StepsOrError
```

Generate a plan or error using an LLM from a query and a list of tools.

#### agenerate\_steps\_or\_error

```python
async def agenerate_steps_or_error(
        query: str,
        tool_list: list[Tool],
        end_user: EndUser,
        examples: list[Plan] | None = None,
        plan_inputs: list[PlanInput] | None = None) -> StepsOrError
```

Generate a plan or error using an LLM from a query and a list of tools.
</file>

<file path="docs/SDK/portia/telemetry/telemetry_service.md">
---
sidebar_label: telemetry_service
title: portia.telemetry.telemetry_service
---

Telemetry service for capturing anonymized usage data.

#### xdg\_cache\_home

```python
def xdg_cache_home() -> Path
```

Get the XDG cache home directory path.

**Returns**:

- `Path` - The path to the cache directory, either from XDG_CACHE_HOME environment variable
  or the default ~/.portia location.

#### get\_project\_id\_key

```python
def get_project_id_key() -> str
```

Get the project ID key.

**Returns**:

- `str` - The project ID key

## BaseProductTelemetry Objects

```python
class BaseProductTelemetry(ABC)
```

Base interface for capturing anonymized telemetry data.

This class handles the collection and transmission of anonymized usage data to PostHog.
Telemetry can be disabled by setting the environment variable `ANONYMIZED_TELEMETRY=False`.

#### capture

```python
@abstractmethod
def capture(event: BaseTelemetryEvent) -> None
```

Capture and send a telemetry event.

**Arguments**:

- `event` _BaseTelemetryEvent_ - The telemetry event to capture

## ProductTelemetry Objects

```python
@singleton
class ProductTelemetry(BaseProductTelemetry)
```

Service for capturing anonymized telemetry data.

This class handles the collection and transmission of anonymized usage data to PostHog.
Telemetry can be disabled by setting the environment variable `ANONYMIZED_TELEMETRY=False`.

**Attributes**:

- `USER_ID_PATH` _str_ - Path where the user ID is stored
- `PROJECT_API_KEY` _str_ - PostHog project API key
- `HOST` _str_ - PostHog server host URL
- `UNKNOWN_USER_ID` _str_ - Default user ID when user identification fails

#### \_\_init\_\_

```python
def __init__() -> None
```

Initialize the telemetry service.

Sets up the PostHog client if telemetry is enabled and configures logging.

#### capture

```python
def capture(event: BaseTelemetryEvent) -> None
```

Capture and send a telemetry event.

**Arguments**:

- `event` _BaseTelemetryEvent_ - The telemetry event to capture

#### user\_id

```python
@property
def user_id() -> str
```

Get the current user ID, generating a new one if it doesn&#x27;t exist.

**Returns**:

- `str` - The user ID, either from cache or newly generated
</file>

<file path="docs/SDK/portia/telemetry/views.md">
---
sidebar_label: views
title: portia.telemetry.views
---

Portia telemetry views.

## BaseTelemetryEvent Objects

```python
@dataclass
class BaseTelemetryEvent(ABC)
```

Base class for all telemetry events.

This abstract class defines the interface that all telemetry events must implement.
It provides a common structure for event name and properties.

#### name

```python
@property
@abstractmethod
def name() -> str
```

Get the name of the telemetry event.

**Returns**:

- `str` - The name of the telemetry event.

#### properties

```python
@property
def properties() -> dict[str, Any]
```

Get the properties of the telemetry event.

**Returns**:

  dict[str, Any]: A dictionary containing all properties of the event,
  excluding the &#x27;name&#x27; property.

## PortiaFunctionCallTelemetryEvent Objects

```python
@dataclass
class PortiaFunctionCallTelemetryEvent(BaseTelemetryEvent)
```

Telemetry event for tracking Portia function calls.

**Attributes**:

- `function_name` - The name of the function being called.
- `function_call_details` - Additional details about the function call.

#### name

type: ignore reportIncompatibleMethodOverride

## ToolCallTelemetryEvent Objects

```python
@dataclass
class ToolCallTelemetryEvent(BaseTelemetryEvent)
```

Telemetry event for tracking tool calls.

**Attributes**:

- `tool_id` - The identifier of the tool being called, if any.

#### name

type: ignore reportIncompatibleMethodOverride
</file>

<file path="docs/SDK/portia/clarification_handler.md">
---
sidebar_label: clarification_handler
title: portia.clarification_handler
---

Clarification Handler.

This module defines the base ClarificationHandler interface that determines how to handle
clarifications that arise during the run of a plan.

## ClarificationHandler Objects

```python
class ClarificationHandler(ABC)
```

Handles clarifications that arise during the execution of a plan run.

#### handle

```python
def handle(clarification: Clarification,
           on_resolution: Callable[[Clarification, object], None],
           on_error: Callable[[Clarification, object], None]) -> None
```

Handle a clarification by routing it to the appropriate handler.

**Arguments**:

- `clarification` - The clarification object to handle
- `on_resolution` - Callback function that should be invoked once the clarification has been
  handled, prompting the plan run to resume. This can either be called synchronously
  in this function or called async after returning from this function. The callback
  takes two arguments: the clarification object and the response to the clarification.
- `on_error` - Callback function that should be invoked if the clarification handling has
  failed. This can either be called synchronously in this function or called async
  after returning from this function. The callback takes two arguments: the
  clarification object and the error.

#### handle\_action\_clarification

```python
def handle_action_clarification(
        clarification: ActionClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle an action clarification.

#### handle\_input\_clarification

```python
def handle_input_clarification(
        clarification: InputClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle a user input clarification.

#### handle\_multiple\_choice\_clarification

```python
def handle_multiple_choice_clarification(
        clarification: MultipleChoiceClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle a multi-choice clarification.

#### handle\_value\_confirmation\_clarification

```python
def handle_value_confirmation_clarification(
        clarification: ValueConfirmationClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle a value confirmation clarification.

#### handle\_user\_verification\_clarification

```python
def handle_user_verification_clarification(
        clarification: UserVerificationClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle a user verification clarification.

#### handle\_custom\_clarification

```python
def handle_custom_clarification(
        clarification: CustomClarification,
        on_resolution: Callable[[Clarification, object], None],
        on_error: Callable[[Clarification, object], None]) -> None
```

Handle a custom clarification.
</file>

<file path="docs/SDK/portia/clarification.md">
---
sidebar_label: clarification
title: portia.clarification
---

Clarification Primitives.

This module defines base classes and utilities for handling clarifications in the Portia system.
Clarifications represent questions or actions requiring user input to resolve, with different types
of clarifications for various use cases such as arguments, actions, inputs, multiple choices,
and value confirmations.

## ClarificationCategory Objects

```python
class ClarificationCategory(PortiaEnum)
```

The category of a clarification.

This enum defines the different categories of clarifications that can exist, such as arguments,
actions, inputs, and more. It helps to categorize clarifications for easier
handling and processing.

## Clarification Objects

```python
class Clarification(BaseModel, ABC)
```

Base Model for Clarifications.

A Clarification represents a question or action that requires user input to resolve. For example
it could indicate the need for OAuth authentication, missing arguments for a tool
or a user choice from a list.

**Attributes**:

- `id` _ClarificationUUID_ - A unique identifier for this clarification.
- `category` _ClarificationCategory_ - The category of this clarification, indicating its type.
- `response` _SERIALIZABLE_TYPE_VAR | None_ - The user&#x27;s response to this clarification, if any.
- `step` _int | None_ - The step this clarification is associated with, if applicable.
- `user_guidance` _str_ - Guidance provided to the user to assist with the clarification.
- `resolved` _bool_ - Whether the clarification has been resolved by the user.

## ActionClarification Objects

```python
class ActionClarification(Clarification)
```

Action-based clarification.

Represents a clarification that involves an action, such as clicking a link. The response is set
to `True` once the user has completed the action associated with the link.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification, &#x27;Action&#x27;.
- `action_url` _HttpUrl_ - The URL for the action that the user needs to complete.
- `require_confirmation` _bool_ - Whether the user needs to confirm once the action has been
  completed.

#### serialize\_action\_url

```python
@field_serializer("action_url")
def serialize_action_url(action_url: HttpUrl) -> str
```

Serialize the action URL to a string.

**Arguments**:

- `action_url` _HttpUrl_ - The URL to be serialized.
  

**Returns**:

- `str` - The serialized string representation of the URL.

## InputClarification Objects

```python
class InputClarification(Clarification)
```

Input-based clarification.

Represents a clarification where the user needs to provide a value for a specific argument.
This type of clarification is used when the user is prompted to enter a value.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification, &#x27;Input&#x27;.

## MultipleChoiceClarification Objects

```python
class MultipleChoiceClarification(Clarification)
```

Multiple choice-based clarification.

Represents a clarification where the user needs to select an option for a specific argument.
The available options are provided, and the user must select one.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification &#x27;Multiple Choice&#x27;.
- `options` _list[Serializable]_ - The available options for the user to choose from.
  

**Methods**:

- `validate_response` - Ensures that the user&#x27;s response is one of the available options.

#### validate\_response

```python
@model_validator(mode="after")
def validate_response() -> Self
```

Ensure the provided response is an option.

This method checks that the response provided by the user is one of the options. If not,
it raises an error.

**Returns**:

- `Self` - The validated instance.
  

**Raises**:

- `ValueError` - If the response is not one of the available options.

## ValueConfirmationClarification Objects

```python
class ValueConfirmationClarification(Clarification)
```

Value confirmation clarification.

Represents a clarification where the user is presented with a value and must confirm or deny it.
The clarification should be created with the response field already set, and the user indicates
acceptance by setting the resolved flag to `True`.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification, &#x27;Value Confirmation&#x27;.

## UserVerificationClarification Objects

```python
class UserVerificationClarification(Clarification)
```

User verification clarification.

Represents a clarification where the user some information that they must verify.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification, &#x27;User Verification&#x27;.

#### validate\_response

```python
@field_validator("response")
@classmethod
def validate_response(cls, v: Any) -> Any
```

Validate that response is a boolean value or None.

**Arguments**:

- `v` - The value to validate.
  

**Returns**:

- `Any` - The validated value.
  

**Raises**:

- `ValueError` - If the response is not a boolean.

#### user\_confirmed

```python
@property
def user_confirmed() -> bool
```

Whether the user has confirmed the verification.

Returns the response attribute as a boolean value.

## CustomClarification Objects

```python
class CustomClarification(Clarification)
```

Custom clarifications.

Allows the user to extend clarifications with arbitrary data.
The user is responsible for handling this clarification type.

**Attributes**:

- `category` _ClarificationCategory_ - The category for this clarification, &#x27;Custom&#x27;.

#### ClarificationType

A list of clarifications of any type.
</file>

<file path="docs/SDK/portia/cloud.md">
---
sidebar_label: cloud
title: portia.cloud
---

Core client for interacting with portia cloud.

## PortiaCloudClient Objects

```python
class PortiaCloudClient()
```

Base HTTP client builder for interacting with portia cloud.

#### \_\_init\_\_

```python
def __init__(config: Config) -> None
```

Initialize the PortiaCloudClient instance.

**Arguments**:

- `config` _Config_ - The Portia Configuration instance, containing the API key and endpoint.
</file>

<file path="docs/SDK/portia/config.md">
---
sidebar_label: config
title: portia.config
---

Configuration module for the SDK.

This module defines the configuration classes and enumerations used in the SDK,
including settings for storage, API keys, LLM providers, logging, and agent options.
It also provides validation for configuration values and loading mechanisms for
default settings.

## StorageClass Objects

```python
class StorageClass(Enum)
```

Enum representing locations plans and runs are stored.

**Attributes**:

- `MEMORY` - Stored in memory.
- `DISK` - Stored on disk.
- `CLOUD` - Stored in the cloud.

## Model Objects

```python
class Model(NamedTuple)
```

Provider and model name tuple.

**DEPRECATED** Use new model configuration options on Config class instead.

**Attributes**:

- `provider` - The provider of the model.
- `model_name` - The name of the model in the provider&#x27;s API.

## LLMModel Objects

```python
class LLMModel(Enum)
```

Enum for supported LLM models.

**DEPRECATED** Use new model configuration options on Config class instead.

Models are grouped by provider, with the following providers:
- OpenAI
- Anthropic
- MistralAI
- Google Generative AI
- Azure OpenAI

**Attributes**:

- `GPT_4_O` - GPT-4 model by OpenAI.
- `GPT_4_O_MINI` - Mini GPT-4 model by OpenAI.
- `GPT_3_5_TURBO` - GPT-3.5 Turbo model by OpenAI.
- `CLAUDE_3_5_SONNET` - Claude 3.5 Sonnet model by Anthropic.
- `CLAUDE_3_5_HAIKU` - Claude 3.5 Haiku model by Anthropic.
- `CLAUDE_3_OPUS` - Claude 3.0 Opus model by Anthropic.
- `CLAUDE_3_7_SONNET` - Claude 3.7 Sonnet model by Anthropic.
- `MISTRAL_LARGE` - Mistral Large Latest model by MistralAI.
- `GEMINI_2_0_FLASH` - Gemini 2.0 Flash model by Google Generative AI.
- `GEMINI_2_0_FLASH_LITE` - Gemini 2.0 Flash Lite model by Google Generative AI.
- `GPT_4_O_MINI`0 - Gemini 1.5 Flash model by Google Generative AI.
- `GPT_4_O_MINI`1 - GPT-4 model by Azure OpenAI.
- `GPT_4_O_MINI`2 - Mini GPT-4 model by Azure OpenAI.
- `GPT_4_O_MINI`3 - O3 Mini model by Azure OpenAI.
  
  Can be instantiated from a string with the following format:
  - provider/model_name  [e.g. LLMModel(&quot;openai/gpt-4o&quot;)]
  - model_name           [e.g. LLMModel(&quot;gpt-4o&quot;)]
  
  In the cases where the model name is not unique across providers, the earlier values in the enum
  definition will take precedence.

#### \_missing\_

```python
@classmethod
def _missing_(cls, value: object) -> LLMModel
```

Get the LLM model from the model name.

#### api\_name

```python
@property
def api_name() -> str
```

Override the default value to return the model name.

#### provider

```python
def provider() -> LLMProvider
```

Get the associated provider for the model.

**Returns**:

- `LLMProvider` - The provider associated with the model.

#### to\_model\_string

```python
def to_model_string() -> str
```

Get the model string for the model.

**Returns**:

- `str` - The model string.

## \_AllModelsSupportedWithDeprecation Objects

```python
class _AllModelsSupportedWithDeprecation(Container)
```

A type that returns True for any contains check.

#### \_\_contains\_\_

```python
def __contains__(item: object) -> bool
```

Check if the item is in the container.

## ExecutionAgentType Objects

```python
class ExecutionAgentType(Enum)
```

Enum for types of agents used for executing a step.

**Attributes**:

- `ONE_SHOT` - The one-shot agent.
- `DEFAULT` - The default agent.

## PlanningAgentType Objects

```python
class PlanningAgentType(Enum)
```

Enum for planning agents used for planning queries.

**Attributes**:

- `DEFAULT` - The default planning agent.

## LogLevel Objects

```python
class LogLevel(Enum)
```

Enum for available log levels.

**Attributes**:

- `DEBUG` - Debug log level.
- `INFO` - Info log level.
- `WARNING` - Warning log level.
- `ERROR` - Error log level.
- `CRITICAL` - Critical log level.

#### parse\_str\_to\_enum

```python
def parse_str_to_enum(value: str | E, enum_type: type[E]) -> E
```

Parse a string to an enum or return the enum as is.

**Arguments**:

- `value` _str | E_ - The value to parse.
- `enum_type` _type[E]_ - The enum type to parse the value into.
  

**Raises**:

- `InvalidConfigError` - If the value cannot be parsed into the enum.
  

**Returns**:

- `E` - The corresponding enum value.

## GenerativeModelsConfig Objects

```python
class GenerativeModelsConfig(BaseModel)
```

Configuration for a Generative Models.

These models do not all need to be specified manually. If an LLM provider is configured,
Portia will use default models that are selected for the particular use-case.

**Attributes**:

- `default_model` - The default generative model to use. This model is used as the fallback
  model if no other model is specified. It is also used by default in the Portia SDK
  tool that require an LLM.
  
- `planning_model` - The model to use for the PlanningAgent. Reasoning models are a good choice
  here, as they are able to reason about the problem and the possible solutions. If not
  specified, the default_model will be used.
  
- `execution_model` - The model to use for the ExecutionAgent. This model is used for the
  distilling context from the plan run into tool calls. If not specified, the
  default_model will be used.
  
- `introspection_model` - The model to use for the IntrospectionAgent. This model is used to
  introspect the problem and the plan. If not specified, the default_model will be used.
  
- `summarizer_model` - The model to use for the SummarizerAgent. This model is used to
  summarize output from the plan run. If not specified, the default_model will be used.

#### parse\_models

```python
@model_validator(mode="before")
@classmethod
def parse_models(cls, data: dict[str, Any]) -> dict[str, Any]
```

Convert legacy LLMModel values to str with deprecation warning.

## Config Objects

```python
class Config(BaseModel)
```

General configuration for the SDK.

This class holds the configuration for the SDK, including API keys, LLM
settings, logging options, and storage settings. It also provides validation
for configuration consistency and offers methods for loading configuration
from files or default values.

**Attributes**:

- `portia_api_endpoint` - The endpoint for the Portia API.
- `portia_api_key` - The API key for Portia.
- `openai_api_key` - The API key for OpenAI.
- `anthropic_api_key` - The API key for Anthropic.
- `mistralai_api_key` - The API key for MistralAI.
- `google_api_key` - The API key for Google Generative AI.
- `aws_access_key_id` - The AWS access key ID.
- `aws_secret_access_key` - The AWS secret access key.
- `aws_default_region` - The AWS default region.
- `aws_credentials_profile_name` - The AWS credentials profile name.
- `portia_api_key`0 - The API key for Azure OpenAI.
- `portia_api_key`1 - The endpoint for Azure OpenAI.
- `portia_api_key`2 - The LLM provider. If set, Portia uses this to select the best models
  for each agent. Can be None if custom models are provided.
- `portia_api_key`3 - A configuration for the LLM models for Portia to use.
- `portia_api_key`4 - The storage class used (e.g., MEMORY, DISK, CLOUD).
- `portia_api_key`5 - The directory for storage, if applicable.
- `portia_api_key`6 - The default log level (e.g., DEBUG, INFO).
- `portia_api_key`7 - The default destination for logs (e.g., sys.stdout).
- `portia_api_key`8 - Whether to serialize logs in JSON format.
- `portia_api_key`9 - The planning agent type.
- `openai_api_key`0 - The execution agent type.
- `openai_api_key`1 - A dictionary of feature flags for the SDK.
- `openai_api_key`2 - Whether to enable clarifications for the execution agent.

#### parse\_feature\_flags

```python
@model_validator(mode="after")
def parse_feature_flags() -> Self
```

Add feature flags if not provided.

#### setup\_cache

```python
@model_validator(mode="after")
def setup_cache() -> Self
```

Set up LLM cache if Redis URL is provided.

#### parse\_storage\_class

```python
@field_validator("storage_class", mode="before")
@classmethod
def parse_storage_class(cls, value: str | StorageClass) -> StorageClass
```

Parse storage class to enum if string provided.

#### parse\_default\_log\_level

```python
@field_validator("default_log_level", mode="before")
@classmethod
def parse_default_log_level(cls, value: str | LogLevel) -> LogLevel
```

Parse default_log_level to enum if string provided.

#### parse\_execution\_agent\_type

```python
@field_validator("execution_agent_type", mode="before")
@classmethod
def parse_execution_agent_type(
        cls, value: str | ExecutionAgentType) -> ExecutionAgentType
```

Parse execution_agent_type to enum if string provided.

#### parse\_planning\_agent\_type

```python
@field_validator("planning_agent_type", mode="before")
@classmethod
def parse_planning_agent_type(
        cls, value: str | PlanningAgentType) -> PlanningAgentType
```

Parse planning_agent_type to enum if string provided.

#### exceeds\_output\_threshold

```python
def exceeds_output_threshold(value: str | list[str | dict]) -> bool
```

Determine whether the provided output value exceeds the large output threshold.

#### get\_agent\_default\_model

```python
def get_agent_default_model(
        agent_key: str,
        llm_provider: LLMProvider | None = None
) -> GenerativeModel | str | None
```

Get the default model for the given agent key.

#### fill\_default\_models

```python
@model_validator(mode="after")
def fill_default_models() -> Self
```

Fill in default models for the LLM provider if not provided.

#### check\_config

```python
@model_validator(mode="after")
def check_config() -> Self
```

Validate Config is consistent.

#### from\_default

```python
@classmethod
def from_default(cls, **kwargs) -> Config
```

Create a Config instance with default values, allowing overrides.

**Returns**:

- `Config` - The default config

#### has\_api\_key

```python
def has_api_key(name: str) -> bool
```

Check if the given API Key is available.

#### must\_get\_api\_key

```python
def must_get_api_key(name: str) -> SecretStr
```

Retrieve the required API key for the configured provider.

**Raises**:

- `ConfigNotFoundError` - If no API key is found for the provider.
  

**Returns**:

- `SecretStr` - The required API key.

#### must\_get

```python
def must_get(name: str, expected_type: type[T]) -> T
```

Retrieve any value from the config, ensuring its of the correct type.

**Arguments**:

- `name` _str_ - The name of the config record.
- `expected_type` _type[T]_ - The expected type of the value.
  

**Raises**:

- `ConfigNotFoundError` - If no API key is found for the provider.
- `InvalidConfigError` - If the config isn&#x27;t valid
  

**Returns**:

- `T` - The config value

#### get\_default\_model

```python
def get_default_model() -> GenerativeModel
```

Get or build the default model from the config.

The default model will always be present. It is a general purpose model that is used
for the SDK&#x27;s LLM-based Tools, such as the ImageUnderstandingTool and the LLMTool.

Additionally, unless specified all other specific agent models will default to this model.

#### get\_planning\_model

```python
def get_planning_model() -> GenerativeModel
```

Get or build the planning model from the config.

See the GenerativeModelsConfig class for more information

#### get\_execution\_model

```python
def get_execution_model() -> GenerativeModel
```

Get or build the execution model from the config.

See the GenerativeModelsConfig class for more information

#### get\_introspection\_model

```python
def get_introspection_model() -> GenerativeModel
```

Get or build the introspection model from the config.

See the GenerativeModelsConfig class for more information

#### get\_summarizer\_model

```python
def get_summarizer_model() -> GenerativeModel
```

Get or build the summarizer model from the config.

See the GenerativeModelsConfig class for more information

#### get\_generative\_model

```python
def get_generative_model(
        model: str | GenerativeModel | None) -> GenerativeModel | None
```

Get a GenerativeModel instance.

**Arguments**:

- `model` _str | GenerativeModel | None_ - The model to get, either specified as a
  string in the form of &quot;provider/model_name&quot;, or as a GenerativeModel instance.
  Also accepts None, in which case None is returned.
  

**Returns**:

  GenerativeModel | None: The model instance or None.

#### llm\_provider\_default\_from\_api\_keys

```python
def llm_provider_default_from_api_keys(**kwargs) -> LLMProvider | None
```

Get the default LLM provider from the API keys.

**Returns**:

- `LLMProvider` - The default LLM provider.
- `None` - If no API key is found.

#### default\_config

```python
def default_config(**kwargs) -> Config
```

Return default config with values that can be overridden.

**Returns**:

- `Config` - The default config
</file>

<file path="docs/SDK/portia/end_user.md">
---
sidebar_label: end_user
title: portia.end_user
---

Models for end user management.

## EndUser Objects

```python
class EndUser(BaseModel)
```

Represents an actual user of the system.

#### set\_additional\_data

```python
def set_additional_data(key_name: str, key_value: str) -> None
```

Set a field in the additional data blob.

#### remove\_additional\_data

```python
def remove_additional_data(key_name: str) -> None
```

Set a field in the additional data blob.

#### get\_additional\_data

```python
def get_additional_data(key_name: str) -> str | None
```

Get a field from the additional data blob.
</file>

<file path="docs/SDK/portia/errors.md">
---
sidebar_label: errors
title: portia.errors
---

Central definition of error classes.

This module defines custom exception classes used throughout the application. These exceptions
help identify specific error conditions, particularly related to configuration, planning, runs,
tools, and storage. They provide more context and clarity than generic exceptions.

Classes in this file include:

- `ConfigNotFoundError`: Raised when a required configuration value is not found.
- `InvalidConfigError`: Raised when a configuration value is invalid.
- `PlanError`: A base class for exceptions in the query planning_agent module.
- `PlanNotFoundError`: Raised when a plan is not found.
- `PlanRunNotFoundError`: Raised when a PlanRun is not found.
- `ToolNotFoundError`: Raised when a tool is not found.
- `DuplicateToolError`: Raised when a tool is registered with the same name.
- `InvalidToolDescriptionError`: Raised when a tool description is invalid.
- `ToolRetryError`: Raised when a tool fails after retries.
- `ToolFailedError`: Raised when a tool fails with a hard error.
- `InvalidConfigError`0: Raised when a plan run is in an invalid state.
- `InvalidConfigError`1: Raised when the agent produces invalid output.
- `InvalidConfigError`2: Raised when a tool encounters an unrecoverable error.
- `InvalidConfigError`3: Raised when a tool encounters an error that can be retried.
- `InvalidConfigError`4: Raised when an issue occurs with storage.

## PortiaBaseError Objects

```python
class PortiaBaseError(Exception)
```

Base class for all our errors.

## SkipExecutionError Objects

```python
class SkipExecutionError(PortiaBaseError)
```

Raised when a Portia execution should be stopped or a step should be skipped.

#### \_\_init\_\_

```python
def __init__(reason: str, should_return: bool = False) -> None
```

Set custom error message.

**Arguments**:

- `reason` _str_ - The reason for skipping the step.
- `should_return` _bool_ - Whether to return the plan run and stop execution entirely,
  or just skip the step.

## ConfigNotFoundError Objects

```python
class ConfigNotFoundError(PortiaBaseError)
```

Raised when a required configuration value is not found.

**Arguments**:

- `value` _str_ - The name of the configuration value that is missing.

#### \_\_init\_\_

```python
def __init__(value: str) -> None
```

Set custom error message.

## InvalidConfigError Objects

```python
class InvalidConfigError(PortiaBaseError)
```

Raised when a configuration value is invalid.

**Arguments**:

- `value` _str_ - The name of the invalid configuration value.
- `issue` _str_ - A description of the issue with the configuration value.

#### \_\_init\_\_

```python
def __init__(value: str, issue: str) -> None
```

Set custom error message.

## PlanError Objects

```python
class PlanError(PortiaBaseError)
```

Base class for exceptions in the query planning_agent module.

This exception indicates an error that occurred during the planning phase.

**Arguments**:

- `error_string` _str_ - A description of the error encountered during planning.

#### \_\_init\_\_

```python
def __init__(error_string: str) -> None
```

Set custom error message.

## PlanNotFoundError Objects

```python
class PlanNotFoundError(PortiaBaseError)
```

Raised when a plan with a specific ID is not found.

**Arguments**:

- `plan_id` _PlanUUID_ - The ID of the plan that was not found.

#### \_\_init\_\_

```python
def __init__(plan_id: PlanUUID) -> None
```

Set custom error message.

## PlanRunNotFoundError Objects

```python
class PlanRunNotFoundError(PortiaBaseError)
```

Raised when a PlanRun with a specific ID is not found.

**Arguments**:

- `plan_run_id` _UUID | str | None_ - The ID or name of the PlanRun that was not found.

#### \_\_init\_\_

```python
def __init__(plan_run_id: PlanRunUUID | str | None) -> None
```

Set custom error message.

## ToolNotFoundError Objects

```python
class ToolNotFoundError(PortiaBaseError)
```

Raised when a tool with a specific ID is not found.

**Arguments**:

- `tool_id` _str_ - The ID of the tool that was not found.

#### \_\_init\_\_

```python
def __init__(tool_id: str) -> None
```

Set custom error message.

## DuplicateToolError Objects

```python
class DuplicateToolError(PortiaBaseError)
```

Raised when a tool is registered with the same name.

**Arguments**:

- `tool_id` _str_ - The ID of the tool that already exists.

#### \_\_init\_\_

```python
def __init__(tool_id: str) -> None
```

Set custom error message.

## InvalidToolDescriptionError Objects

```python
class InvalidToolDescriptionError(PortiaBaseError)
```

Raised when a tool description is invalid.

**Arguments**:

- `tool_id` _str_ - The ID of the tool with an invalid description.

#### \_\_init\_\_

```python
def __init__(tool_id: str) -> None
```

Set custom error message.

## ToolRetryError Objects

```python
class ToolRetryError(PortiaBaseError)
```

Raised when a tool fails after retrying.

**Arguments**:

- `tool_id` _str_ - The ID of the tool that failed.
- `error_string` _str_ - A description of the error that occurred.

#### \_\_init\_\_

```python
def __init__(tool_id: str, error_string: str) -> None
```

Set custom error message.

## ToolFailedError Objects

```python
class ToolFailedError(PortiaBaseError)
```

Raised when a tool fails with a hard error.

**Arguments**:

- `tool_id` _str_ - The ID of the tool that failed.
- `error_string` _str_ - A description of the error that occurred.

#### \_\_init\_\_

```python
def __init__(tool_id: str, error_string: str) -> None
```

Set custom error message.

## InvalidPlanRunStateError Objects

```python
class InvalidPlanRunStateError(PortiaBaseError)
```

Raised when a plan run is in an invalid state.

## InvalidAgentError Objects

```python
class InvalidAgentError(PortiaBaseError)
```

Raised when an agent is in an invalid state.

#### \_\_init\_\_

```python
def __init__(state: str) -> None
```

Set custom error message.

## InvalidAgentOutputError Objects

```python
class InvalidAgentOutputError(PortiaBaseError)
```

Raised when the agent produces invalid output.

**Arguments**:

- `content` _str_ - The invalid content returned by the agent.

#### \_\_init\_\_

```python
def __init__(content: str) -> None
```

Set custom error message.

## ToolHardError Objects

```python
class ToolHardError(PortiaBaseError)
```

Raised when a tool encounters an error it cannot retry.

**Arguments**:

- `cause` _Exception | str_ - The underlying exception or error message.

#### \_\_init\_\_

```python
def __init__(cause: Exception | str) -> None
```

Set custom error message.

## ToolSoftError Objects

```python
class ToolSoftError(PortiaBaseError)
```

Raised when a tool encounters an error that can be retried.

**Arguments**:

- `cause` _Exception | str_ - The underlying exception or error message.

#### \_\_init\_\_

```python
def __init__(cause: Exception | str) -> None
```

Set custom error message.

## StorageError Objects

```python
class StorageError(PortiaBaseError)
```

Raised when there&#x27;s an issue with storage.

**Arguments**:

- `cause` _Exception | str_ - The underlying exception or error message.

#### \_\_init\_\_

```python
def __init__(cause: Exception | str) -> None
```

Set custom error message.
</file>

<file path="docs/SDK/portia/execution_hooks.md">
---
sidebar_label: execution_hooks
title: portia.execution_hooks
---

Execution hooks for customizing the behavior of portia during execution.

## BeforeStepExecutionOutcome Objects

```python
class BeforeStepExecutionOutcome(PortiaEnum)
```

The Outcome of the before step execution hook.

## ExecutionHooks Objects

```python
class ExecutionHooks(BaseModel)
```

Hooks that can be used to modify or add extra functionality to the run of a plan.

Hooks can be registered for various execution events:
- clarification_handler: A handler for clarifications raised during execution
- before_step_execution: Called before executing each step
- after_step_execution: Called after executing each step. When there&#x27;s an error, this is
    called with the error as the output value.
- before_plan_run: Called before executing the first step of the plan run.
- after_plan_run: Called after executing the plan run. This is not called if a clarification
    is raised, as it is expected that the plan will be resumed after the clarification is
    handled.
- before_tool_call: Called before the tool is called
- after_tool_call: Called after the tool is called

#### clarification\_handler

Handler for clarifications raised during execution.

#### before\_step\_execution

Called before executing each step.

**Arguments**:

- `plan` - The plan being executed
- `plan_run` - The current plan run
- `step` - The step about to be executed
  

**Returns**:

  BeforeStepExecutionOutcome | None: Whether to continue with the step execution or skip it.
  If None is returned, the default behaviour is to continue with the step execution.

#### after\_step\_execution

Called after executing each step.

When there&#x27;s an error, this is called with the error as the output value.

**Arguments**:

- `plan` - The plan being executed
- `plan_run` - The current plan run
- `step` - The step that was executed
- `output` - The output from the step execution

#### before\_plan\_run

Called before executing the first step of the plan run.

**Arguments**:

- `plan` - The plan being executed
- `plan_run` - The current plan run

#### after\_plan\_run

Called after executing the plan run.

This is not called if a clarification is raised, as it is expected that the plan
will be resumed after the clarification is handled.

**Arguments**:

- `plan` - The plan that was executed
- `plan_run` - The completed plan run
- `output` - The final output from the plan execution

#### before\_tool\_call

Called before the tool is called.

**Arguments**:

- `tool` - The tool about to be called
- `args` - The args for the tool call. These are mutable and so can be modified in place as
  required.
- `plan_run` - The current plan run
- `step` - The step being executed
  

**Returns**:

  Clarification | None: A clarification to raise, or None to proceed with the tool call

#### after\_tool\_call

Called after the tool is called.

**Arguments**:

- `tool` - The tool that was called
- `output` - The output returned from the tool call
- `plan_run` - The current plan run
- `step` - The step being executed
  

**Returns**:

  Clarification | None: A clarification to raise, or None to proceed. If a clarification
  is raised, when we later resume the plan, the same step will be executed again

#### clarify\_on\_all\_tool\_calls

```python
def clarify_on_all_tool_calls(tool: Tool, args: dict[str,
                                                     Any], plan_run: PlanRun,
                              step: Step) -> Clarification | None
```

Raise a clarification to check the user is happy with all tool calls before proceeding.

Example usage:
    portia = Portia(
        execution_hooks=ExecutionHooks(
            before_tool_call=clarify_on_all_tool_calls,
        )
    )

#### clarify\_on\_tool\_calls

```python
def clarify_on_tool_calls(
    tool: str | Tool | list[str] | list[Tool]
) -> Callable[[Tool, dict[str, Any], PlanRun, Step], Clarification | None]
```

Return a hook that raises a clarification before calls to the specified tool.

**Arguments**:

- `tool` - The tool or tools to raise a clarification for before running
  
  Example usage:
  portia = Portia(
  execution_hooks=ExecutionHooks(
  before_tool_call=clarify_on_tool_calls(&quot;my_tool_id&quot;),
  )
  )
  # Or with Tool objects:
  portia = Portia(
  execution_hooks=ExecutionHooks(
  before_tool_call=clarify_on_tool_calls([tool1, tool2]),
  )
  )

#### log\_step\_outputs

```python
def log_step_outputs(plan: Plan, plan_run: PlanRun, step: Step,
                     output: Output) -> None
```

Log the output of a step in the plan.
</file>

<file path="docs/SDK/portia/gemini_langsmith_wrapper.md">
---
sidebar_label: gemini_langsmith_wrapper
title: portia.gemini_langsmith_wrapper
---

Custom LangSmith wrapper for Google Generative AI (Gemini).

#### wrap\_gemini

```python
def wrap_gemini(client: genai.Client) -> genai.Client
```

Wrap a Google Generative AI model to enable LangSmith tracing.
</file>

<file path="docs/SDK/portia/logger.md">
---
sidebar_label: logger
title: portia.logger
---

Logging functions for managing and configuring loggers.

This module defines functions and classes to manage logging within the application. It provides a
`LoggerManager` class that manages the package-level logger and allows customization.
The `LoggerInterface` defines the general interface for loggers, and the default logger is provided
by `loguru`. The `logger` function returns the active logger, and the `LoggerManager` can be used
to configure logging behavior.

Classes in this file include:

- `LoggerInterface`: A protocol defining the common logging methods (`debug`, `info`, `warning`,
`error`, `LoggerInterface`0).
- `LoggerManager`: A class for managing the logger, allowing customization and configuration from
the application&#x27;s settings.

This module ensures flexible and configurable logging, supporting both default and custom loggers.

## LoggerInterface Objects

```python
class LoggerInterface(Protocol)
```

General Interface for loggers.

This interface defines the common methods that any logger should implement. The methods are:

- `debug`: For logging debug-level messages.
- `info`: For logging informational messages.
- `warning`: For logging warning messages.
- `error`: For logging error messages.
- `critical`: For logging critical error messages.

These methods are used throughout the application for logging messages at various levels.

## Formatter Objects

```python
class Formatter()
```

A class used to format log records.

Attributes
----------
max_lines : int
    The maximum number of lines to include in the formatted log message.

Methods
-------
format(record)
    Formats a log record into a string.

#### \_\_init\_\_

```python
def __init__() -> None
```

Initialize the logger with default settings.

**Attributes**:

- `max_lines` _int_ - The maximum number of lines the logger can handle, default is 30.

#### format

```python
def format(record: Any) -> str
```

Format a log record into a string with specific formatting.

**Arguments**:

- `record` _dict_ - A dictionary containing log record information.
  Expected keys are &quot;message&quot;, &quot;extra&quot;, &quot;time&quot;, &quot;level&quot;, &quot;name&quot;,
  &quot;function&quot;, and &quot;line&quot;.
  

**Returns**:

- `str` - The formatted log record string.

#### \_sanitize\_message\_

```python
def _sanitize_message_(msg: str, truncate: bool = True) -> str
```

Sanitize a message to be used in a log record.

#### \_get\_function\_color\_

```python
def _get_function_color_(record: Any) -> str
```

Get color based on function/module name. Default is white.

## SafeLogger Objects

```python
class SafeLogger(LoggerInterface)
```

A logger that catches exceptions and logs them to the child logger.

#### \_\_init\_\_

```python
def __init__(child_logger: LoggerInterface) -> None
```

Initialize the SafeLogger.

#### debug

```python
def debug(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s debug method to catch exceptions.

#### info

```python
def info(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s info method to catch exceptions.

#### warning

```python
def warning(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s warning method to catch exceptions.

#### error

```python
def error(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s error method to catch exceptions.

#### exception

```python
def exception(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s exception method to catch exceptions.

#### critical

```python
def critical(msg: str, *args: Any, **kwargs: Any) -> None
```

Wrap the child logger&#x27;s critical method to catch exceptions.

## LoggerManager Objects

```python
class LoggerManager()
```

Manages the package-level logger.

The `LoggerManager` is responsible for initializing and managing the logger used throughout
the application. It provides functionality to configure the logger, set a custom logger,
and adjust logging settings based on the application&#x27;s configuration.

**Arguments**:

- `custom_logger` _LoggerInterface | None_ - A custom logger to be used. If not provided,
  the default `loguru` logger will be used.
  

**Attributes**:

- `logger` _LoggerInterface_ - The current active logger.
- `custom_logger` _bool_ - A flag indicating whether a custom logger is in use.
  

**Methods**:

- `logger` - Returns the active logger.
- `set_logger` - Sets a custom logger.
- `configure_from_config` - Configures the logger based on the provided configuration.

#### \_\_init\_\_

```python
def __init__(custom_logger: LoggerInterface | None = None) -> None
```

Initialize the LoggerManager.

**Arguments**:

- `custom_logger` _LoggerInterface | None_ - A custom logger to use. Defaults to None.

#### logger

```python
@property
def logger() -> LoggerInterface
```

Get the current logger.

**Returns**:

- `LoggerInterface` - The active logger being used.

#### set\_logger

```python
def set_logger(custom_logger: LoggerInterface) -> None
```

Set a custom logger.

**Arguments**:

- `custom_logger` _LoggerInterface_ - The custom logger to be used.

#### configure\_from\_config

```python
def configure_from_config(config: Config) -> None
```

Configure the global logger based on the library&#x27;s configuration.

This method configures the logger&#x27;s log level and output sink based on the application&#x27;s
settings. If a custom logger is in use, it will skip the configuration and log a warning.

**Arguments**:

- `config` _Config_ - The configuration object containing the logging settings.

#### logger

```python
def logger() -> LoggerInterface
```

Return the active logger.

**Returns**:

- `LoggerInterface` - The current active logger being used.
</file>

<file path="docs/SDK/portia/mcp_session.md">
---
sidebar_label: mcp_session
title: portia.mcp_session
---

Configuration and client code for interactions with Model Context Protocol (MCP) servers.

This module provides a context manager for creating MCP ClientSessions, which are used to
interact with MCP servers. It supports SSE, stdio, and StreamableHTTP transports.

NB. The MCP Python SDK is asynchronous, so care must be taken when using MCP functionality
from this module in an async context.

Classes:
    SseMcpClientConfig: Configuration for an MCP client that connects via SSE.
    StdioMcpClientConfig: Configuration for an MCP client that connects via stdio.
    StreamableHttpMcpClientConfig: Configuration for an MCP client that connects via StreamableHTTP.
    McpClientConfig: The configuration to connect to an MCP server.

## SseMcpClientConfig Objects

```python
class SseMcpClientConfig(BaseModel)
```

Configuration for an MCP client that connects via SSE.

## StdioMcpClientConfig Objects

```python
class StdioMcpClientConfig(BaseModel)
```

Configuration for an MCP client that connects via stdio.

#### from\_raw

```python
@classmethod
def from_raw(cls, config: str | dict[str, Any]) -> StdioMcpClientConfig
```

Create a StdioMcpClientConfig from a string.

This method is used to create a StdioMcpClientConfig from a string. It supports
mcpServers and servers keys methods commonly used in MCP client configs.

**Arguments**:

- `config` - The string or dict to parse.
  

**Returns**:

  A StdioMcpClientConfig.
  

**Raises**:

- `ValueError` - If the string is not valid JSON or does not contain a valid MCP config.

## StreamableHttpMcpClientConfig Objects

```python
class StreamableHttpMcpClientConfig(BaseModel)
```

Configuration for an MCP client that connects via StreamableHTTP.

#### get\_mcp\_session

```python
@asynccontextmanager
async def get_mcp_session(
        mcp_client_config: McpClientConfig) -> AsyncIterator[ClientSession]
```

Context manager for an MCP ClientSession.

**Arguments**:

- `mcp_client_config` - The configuration to connect to an MCP server
  

**Returns**:

  An MCP ClientSession
</file>

<file path="docs/SDK/portia/model.md">
---
sidebar_label: model
title: portia.model
---

LLM provider model classes for Portia Agents.

## Message Objects

```python
class Message(BaseModel)
```

Portia LLM message class.

#### from\_langchain

```python
@classmethod
def from_langchain(cls, message: BaseMessage) -> Message
```

Create a Message from a LangChain message.

**Arguments**:

- `message` _BaseMessage_ - The LangChain message to convert.
  

**Returns**:

- `Message` - The converted message.

#### to\_langchain

```python
def to_langchain() -> BaseMessage
```

Convert to LangChain BaseMessage sub-type.

**Returns**:

- `BaseMessage` - The converted message, subclass of LangChain&#x27;s BaseMessage.

## LLMProvider Objects

```python
class LLMProvider(Enum)
```

Enum for supported LLM providers.

**Attributes**:

- `OPENAI` - OpenAI provider.
- `ANTHROPIC` - Anthropic provider.
- `MISTRALAI` - MistralAI provider.
- `GOOGLE` - Google Generative AI provider.
- `AZURE_OPENAI` - Azure OpenAI provider.

#### GOOGLE\_GENERATIVE\_AI

noqa: PIE796 - Alias for GOOGLE member

## GenerativeModel Objects

```python
class GenerativeModel(ABC)
```

Base class for all generative model clients.

#### \_\_init\_\_

```python
def __init__(model_name: str) -> None
```

Initialize the model.

**Arguments**:

- `model_name` - The name of the model.

#### get\_response

```python
@abstractmethod
def get_response(messages: list[Message]) -> Message
```

Given a list of messages, call the model and return its response as a new message.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
  

**Returns**:

- `Message` - The response from the model.

#### get\_structured\_response

```python
@abstractmethod
def get_structured_response(messages: list[Message],
                            schema: type[BaseModelT]) -> BaseModelT
```

Get a structured response from the model, given a Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### aget\_response

```python
@abstractmethod
async def aget_response(messages: list[Message]) -> Message
```

Given a list of messages, call the model and return its response as a new message async.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.

#### aget\_structured\_response

```python
@abstractmethod
async def aget_structured_response(messages: list[Message],
                                   schema: type[BaseModelT]) -> BaseModelT
```

Get a structured response from the model, given a Pydantic model asynchronously.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.

#### get\_context\_window\_size

```python
def get_context_window_size() -> int
```

Get the context window size of the model.

Falls back to 100k tokens if the model is not found.

#### \_\_str\_\_

```python
def __str__() -> str
```

Get the string representation of the model.

#### \_\_repr\_\_

```python
def __repr__() -> str
```

Get the string representation of the model.

#### to\_langchain

```python
@abstractmethod
def to_langchain() -> BaseChatModel
```

Get the LangChain client.

## LangChainGenerativeModel Objects

```python
class LangChainGenerativeModel(GenerativeModel)
```

Base class for LangChain-based models.

#### \_\_init\_\_

```python
def __init__(client: BaseChatModel, model_name: str) -> None
```

Initialize with LangChain client.

**Arguments**:

- `client` - LangChain chat model instance
- `model_name` - The name of the model

#### to\_langchain

```python
def to_langchain() -> BaseChatModel
```

Get the LangChain client.

#### get\_response

```python
def get_response(messages: list[Message]) -> Message
```

Get response using LangChain model.

#### get\_structured\_response

```python
def get_structured_response(messages: list[Message], schema: type[BaseModelT],
                            **kwargs: Any) -> BaseModelT
```

Get structured response using LangChain model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the with_structured_output method.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### aget\_response

```python
async def aget_response(messages: list[Message]) -> Message
```

Get response using LangChain model asynchronously.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.

#### aget\_structured\_response

```python
async def aget_structured_response(messages: list[Message],
                                   schema: type[BaseModelT],
                                   **kwargs: Any) -> BaseModelT
```

Get structured response using LangChain model asynchronously.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the with_structured_output method.

#### set\_cache

```python
@classmethod
def set_cache(cls, cache: BaseCache) -> None
```

Set the cache for the model.

## OpenAIGenerativeModel Objects

```python
class OpenAIGenerativeModel(LangChainGenerativeModel)
```

OpenAI model implementation.

#### \_\_init\_\_

```python
def __init__(*,
             model_name: str,
             api_key: SecretStr,
             seed: int = 343,
             max_retries: int = 3,
             temperature: float = 0,
             **kwargs: Any) -> None
```

Initialize with OpenAI client.

**Arguments**:

- `model_name` - OpenAI model to use
- `api_key` - API key for OpenAI
- `seed` - Random seed for model generation
- `max_retries` - Maximum number of retries
- `temperature` - Temperature parameter
- `**kwargs` - Additional keyword arguments to pass to ChatOpenAI

#### get\_structured\_response

```python
def get_structured_response(messages: list[Message], schema: type[BaseModelT],
                            **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### get\_structured\_response\_instructor

```python
def get_structured_response_instructor(messages: list[Message],
                                       schema: type[BaseModelT]) -> BaseModelT
```

Get structured response using instructor.

#### aget\_structured\_response

```python
async def aget_structured_response(messages: list[Message],
                                   schema: type[BaseModelT],
                                   **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### aget\_structured\_response\_instructor

```python
async def aget_structured_response_instructor(
        messages: list[Message], schema: type[BaseModelT]) -> BaseModelT
```

Get structured response using instructor asynchronously.

## AzureOpenAIGenerativeModel Objects

```python
class AzureOpenAIGenerativeModel(LangChainGenerativeModel)
```

Azure OpenAI model implementation.

#### \_\_init\_\_

```python
def __init__(*,
             model_name: str,
             api_key: SecretStr,
             azure_endpoint: str,
             api_version: str = "2025-01-01-preview",
             seed: int = 343,
             max_retries: int = 3,
             temperature: float = 0,
             **kwargs: Any) -> None
```

Initialize with Azure OpenAI client.

**Arguments**:

- `model_name` - OpenAI model to use
- `azure_endpoint` - Azure OpenAI endpoint
- `api_version` - Azure API version
- `seed` - Random seed for model generation
- `api_key` - API key for Azure OpenAI
- `max_retries` - Maximum number of retries
- `temperature` - Temperature parameter (defaults to 1 for O_3_MINI, 0 otherwise)
- `**kwargs` - Additional keyword arguments to pass to AzureChatOpenAI

#### get\_structured\_response

```python
def get_structured_response(messages: list[Message], schema: type[BaseModelT],
                            **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### get\_structured\_response\_instructor

```python
def get_structured_response_instructor(messages: list[Message],
                                       schema: type[BaseModelT]) -> BaseModelT
```

Get structured response using instructor.

#### aget\_structured\_response

```python
async def aget_structured_response(messages: list[Message],
                                   schema: type[BaseModelT],
                                   **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

## AnthropicGenerativeModel Objects

```python
class AnthropicGenerativeModel(LangChainGenerativeModel)
```

Anthropic model implementation.

#### \_\_init\_\_

```python
def __init__(*,
             model_name: str = "claude-3-7-sonnet-latest",
             api_key: SecretStr,
             timeout: int = 120,
             max_retries: int = 3,
             max_tokens: int = 8096,
             **kwargs: Any) -> None
```

Initialize with Anthropic client.

**Arguments**:

- `model_name` - Name of the Anthropic model
- `timeout` - Request timeout in seconds
- `max_retries` - Maximum number of retries
- `max_tokens` - Maximum number of tokens to generate
- `api_key` - API key for Anthropic
- `**kwargs` - Additional keyword arguments to pass to ChatAnthropic

#### get\_response

```python
def get_response(messages: list[Message]) -> Message
```

Get response from Anthropic model, handling list content.

#### get\_structured\_response

```python
def get_structured_response(messages: list[Message], schema: type[BaseModelT],
                            **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### get\_structured\_response\_instructor

```python
def get_structured_response_instructor(messages: list[Message],
                                       schema: type[BaseModelT]) -> BaseModelT
```

Get structured response using instructor.

#### aget\_response

```python
async def aget_response(messages: list[Message]) -> Message
```

Get response from Anthropic model asynchronously, handling list content.

#### aget\_structured\_response

```python
async def aget_structured_response(messages: list[Message],
                                   schema: type[BaseModelT],
                                   **kwargs: Any) -> BaseModelT
```

Call the model in structured output mode targeting the given Pydantic model async.

**Arguments**:

- `messages` _list[Message]_ - The list of messages to send to the model.
- `schema` _type[BaseModelT]_ - The Pydantic model to use for the response.
- `**kwargs` - Additional keyword arguments to pass to the model.
  

**Returns**:

- `BaseModelT` - The structured response from the model.

#### aget\_structured\_response\_instructor

```python
async def aget_structured_response_instructor(
        messages: list[Message], schema: type[BaseModelT]) -> BaseModelT
```

Get structured response using instructor asynchronously.

#### map\_message\_to\_instructor

```python
def map_message_to_instructor(message: Message) -> ChatCompletionMessageParam
```

Map a Message to ChatCompletionMessageParam.

**Arguments**:

- `message` _Message_ - The message to map.
  

**Returns**:

- `ChatCompletionMessageParam` - Message in the format expected by instructor.
</file>

<file path="docs/SDK/portia/plan_run.md">
---
sidebar_label: plan_run
title: portia.plan_run
---

Plan runs are executing instances of a Plan.

A plan run encapsulates all execution state, serving as the definitive record of its progress.
As the run runs, its `PlanRunState`, `current_step_index`, and `outputs` evolve to reflect
the current execution state.

The run also retains an `ExecutionContext`, which provides valuable insights for debugging
and analytics, capturing contextual information relevant to the run&#x27;s execution.

Key Components
--------------
- **RunState**: Tracks the current status of the run (e.g., NOT_STARTED, IN_PROGRESS).
- **current_step_index**: Represents the step within the plan currently being executed.
- **outputs**: Stores the intermediate and final results of the PlanRun.
- **ExecutionContext**: Provides contextual metadata useful for logging and performance analysis.

## PlanRunState Objects

```python
class PlanRunState(PortiaEnum)
```

The current state of the Plan Run.

**Attributes**:

- `NOT_STARTED` - The run has not been started yet.
- `IN_PROGRESS` - The run is currently in progress.
- `NEED_CLARIFICATION` - The run requires further clarification before proceeding.
- `READY_TO_RESUME` - The run is ready to resume after clarifications have been resolved.
- `COMPLETE` - The run has been successfully completed.
- `FAILED` - The run has encountered an error and failed.

## PlanRunOutputs Objects

```python
class PlanRunOutputs(BaseModel)
```

Outputs of a Plan Run including clarifications.

**Attributes**:

- `clarifications` _ClarificationListType_ - Clarifications raised by this plan run.
- `step_outputs` _dict[str, Output]_ - A dictionary containing outputs of individual steps.
  Outputs are indexed by the value given by the `step.output` field of the plan.
- `final_output` _Output | None_ - The final consolidated output of the PlanRun if available.

## PlanRun Objects

```python
class PlanRun(BaseModel)
```

A plan run represents a running instance of a Plan.

**Attributes**:

- `id` _PlanRunUUID_ - A unique ID for this plan_run.
- `plan_id` _PlanUUID_ - The ID of the Plan this run uses.
- `current_step_index` _int_ - The current step that is being executed.
- `state` _PlanRunState_ - The current state of the PlanRun.
- `outputs` _PlanRunOutputs_ - Outputs of the PlanRun including clarifications.
- `plan_run_inputs` _dict[str, LocalDataValue]_ - Dict mapping plan input names to their values.

#### get\_outstanding\_clarifications

```python
def get_outstanding_clarifications() -> ClarificationListType
```

Return all outstanding clarifications.

**Returns**:

- `ClarificationListType` - A list of outstanding clarifications that have not been resolved.

#### get\_clarifications\_for\_step

```python
def get_clarifications_for_step(
        step: int | None = None) -> ClarificationListType
```

Return clarifications for the given step.

**Arguments**:

- `step` _int | None_ - the step to get clarifications for. Defaults to current step.
  

**Returns**:

- `ClarificationListType` - A list of clarifications for the given step.

#### get\_clarification\_for\_step

```python
def get_clarification_for_step(
        category: ClarificationCategory,
        step: int | None = None) -> Clarification | None
```

Return a clarification of the given category for the given step if it exists.

**Arguments**:

- `step` _int | None_ - the step to get a clarification for. Defaults to current step.
- `category` _ClarificationCategory | None_ - the category of the clarification to get.

#### get\_potential\_step\_inputs

```python
def get_potential_step_inputs() -> dict[str, Output]
```

Return a dictionary of potential step inputs for future steps.

#### \_\_str\_\_

```python
def __str__() -> str
```

Return the string representation of the PlanRun.

**Returns**:

- `str` - A string representation containing key run attributes.

## ReadOnlyPlanRun Objects

```python
class ReadOnlyPlanRun(PlanRun)
```

A read-only copy of a Plan Run passed to agents for reference.

This class provides a non-modifiable view of a plan run instance,
ensuring that agents can access run details without altering them.

#### from\_plan\_run

```python
@classmethod
def from_plan_run(cls, plan_run: PlanRun) -> ReadOnlyPlanRun
```

Create a read-only plan run from a normal PlanRun.

**Arguments**:

- `plan_run` _PlanRun_ - The original run instance to create a read-only copy from.
  

**Returns**:

- `ReadOnlyPlanRun` - A new read-only instance of the provided PlanRun.
</file>

<file path="docs/SDK/portia/plan.md">
---
sidebar_label: plan
title: portia.plan
---

Plan primitives used to define and execute runs.

This module defines the core objects that represent the plan for executing a PlanRun.
The `Plan` class is the main structure that holds a series of steps (`Step`) to be executed by an
agent in response to a query. Each step can have inputs, an associated tool, and an output.
Variables can be used within steps to reference other parts of the plan or constants.

Classes in this file include:

- `Variable`: A variable used in the plan, referencing outputs of previous steps or constants.
- `Step`: Defines a single task that an agent will execute, including inputs and outputs.
- `ReadOnlyStep`: A read-only version of a `Step` used for passing steps to agents.
- `PlanContext`: Provides context about the plan, including the original query and available tools.
- `Plan`: Represents the entire series of steps required to execute a query.

These classes facilitate the definition of runs that can be dynamically adjusted based on the
tools, inputs, and outputs defined in the plan.

## PlanBuilder Objects

```python
class PlanBuilder()
```

A builder for creating plans.

This class provides an interface for constructing plans step by step. Requires a step to be
added to the plan before building it.

**Example**:

  plan = PlanBuilder()                 .step(&quot;Step 1&quot;, &quot;tool_id_1&quot;, &quot;output_1&quot;)                 .step(&quot;Step 2&quot;, &quot;tool_id_2&quot;, &quot;output_2&quot;)                 .input(&quot;input_1&quot;, &quot;value_1&quot;)                 .build()

#### \_\_init\_\_

```python
def __init__(query: str | None = None,
             structured_output_schema: type[BaseModel] | None = None) -> None
```

Initialize the builder with the plan query.

**Arguments**:

- `query` _str_ - The original query given by the user.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the query.

#### step

```python
def step(
        task: str,
        tool_id: str | None = None,
        output: str | None = None,
        inputs: list[Variable] | None = None,
        condition: str | None = None,
        structured_output_schema: type[BaseModel] | None = None
) -> PlanBuilder
```

Add a step to the plan.

**Arguments**:

- `task` _str_ - The task to be completed by the step.
- `tool_id` _str | None_ - The ID of the tool used in this step, if applicable.
- `output` _str | None_ - The unique output ID for the result of this step.
- `inputs` _list[Variable] | None_ - The inputs to the step
- `condition` _str | None_ - A human readable condition which controls if the step should run
  or not.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the step. Will override the tool output schema if provided by calling step
  summarizer with structured response.
  

**Returns**:

- `PlanBuilder` - The builder instance with the new step added.

#### input

```python
def input(name: str,
          description: str | None = None,
          step_index: int | None = None) -> PlanBuilder
```

Add an input variable to the chosen step in the plan (default is the last step).

Inputs are outputs from previous steps.

**Arguments**:

- `name` _str_ - The name of the input.
- `description` _str | None_ - The description of the input.
- `step_index` _int | None_ - The index of the step to add the input to. If not provided,
  the input will be added to the last step.
  

**Returns**:

- `PlanBuilder` - The builder instance with the new input added.

#### plan\_input

```python
def plan_input(name: str, description: str) -> PlanBuilder
```

Add an input variable to the plan.

**Arguments**:

- `name` _str_ - The name of the input.
- `description` _str_ - The description of the input.
  

**Returns**:

- `PlanBuilder` - The builder instance with the new plan input added.

#### condition

```python
def condition(condition: str, step_index: int | None = None) -> PlanBuilder
```

Add a condition to the chosen step in the plan (default is the last step).

**Arguments**:

- `condition` _str_ - The condition to be added to the chosen step.
- `step_index` _int | None_ - The index of the step to add the condition to.
  If not provided, the condition will be added to the last step.
  

**Returns**:

- `PlanBuilder` - The builder instance with the new condition added.

#### build

```python
def build() -> Plan
```

Build the plan.

**Returns**:

- `Plan` - The built plan.

## Variable Objects

```python
class Variable(BaseModel)
```

A reference to an output of a step.

**Arguments**:

- `name` _str_ - The name of the output or plan input to reference, e.g. $best_offers.
- `description` _str_ - A description of the output or plan input.

#### pretty\_print

```python
def pretty_print() -> str
```

Return the pretty print representation of the variable.

**Returns**:

- `str` - A pretty print representation of the variable&#x27;s name, and description.

## PlanInput Objects

```python
class PlanInput(BaseModel)
```

An input to a plan.

**Arguments**:

- `name` _str_ - The name of the input, e.g. $api_key.
- `description` _str_ - A description of the input.

#### pretty\_print

```python
def pretty_print() -> str
```

Return the pretty print representation of the plan input.

**Returns**:

- `str` - A pretty print representation of the input&#x27;s name, and description.

## Step Objects

```python
class Step(BaseModel)
```

A step in a PlanRun.

A step represents a task in the run to be executed. It contains inputs (variables) and
outputs, and may reference a tool to complete the task.

**Arguments**:

- `task` _str_ - The task that needs to be completed by this step.
- `inputs` _list[Variable]_ - The input to the step, as a reference to an output of a previous
  step or a plan input
- `tool_id` _str | None_ - The ID of the tool used in this step, if applicable.
- `output` _str_ - The unique output ID for the result of this step.

#### pretty\_print

```python
def pretty_print() -> str
```

Return the pretty print representation of the step.

**Returns**:

- `str` - A pretty print representation of the step&#x27;s task, inputs, tool_id, and output.

## ReadOnlyStep Objects

```python
class ReadOnlyStep(Step)
```

A read-only copy of a step, passed to agents for reference.

This class creates an immutable representation of a step, which is used to ensure agents
do not modify the original plan during execution.

**Arguments**:

- `step` _Step_ - A step object from which to create a read-only version.

#### from\_step

```python
@classmethod
def from_step(cls, step: Step) -> ReadOnlyStep
```

Create a read-only step from a normal step.

**Arguments**:

- `step` _Step_ - The step to be converted to read-only.
  

**Returns**:

- `ReadOnlyStep` - A new read-only step.

## PlanContext Objects

```python
class PlanContext(BaseModel)
```

Context for a plan.

The plan context contains information about the original query and the tools available
for the planning agent to use when generating the plan.

**Arguments**:

- `query` _str_ - The original query given by the user.
- `tool_ids` _list[str]_ - A list of tool IDs available to the planning agent.

#### serialize\_tool\_ids

```python
@field_serializer("tool_ids")
def serialize_tool_ids(tool_ids: list[str]) -> list[str]
```

Serialize the tool_ids to a sorted list.

**Returns**:

- `list[str]` - The tool_ids as a sorted list.

## Plan Objects

```python
class Plan(BaseModel)
```

A plan represents a series of steps that an agent should follow to execute the query.

A plan defines the entire sequence of steps required to process a query and generate a result.
It also includes the context in which the plan was created.

**Arguments**:

- `id` _PlanUUID_ - A unique ID for the plan.
- `plan_context` _PlanContext_ - The context for when the plan was created.
- `steps` _list[Step]_ - The set of steps that make up the plan.
- `inputs` _list[PlanInput]_ - The inputs required by the plan.

#### \_\_str\_\_

```python
def __str__() -> str
```

Return the string representation of the plan.

**Returns**:

- `str` - A string representation of the plan&#x27;s ID, context, and steps.

#### from\_response

```python
@classmethod
def from_response(cls, response_json: dict) -> Plan
```

Create a plan from a response.

**Arguments**:

- `response_json` _dict_ - The response from the API.
  

**Returns**:

- `Plan` - The plan.

#### pretty\_print

```python
def pretty_print() -> str
```

Return the pretty print representation of the plan.

**Returns**:

- `str` - A pretty print representation of the plan&#x27;s ID, context, and steps.

#### validate\_plan

```python
@model_validator(mode="after")
def validate_plan() -> Self
```

Validate the plan.

Checks that all outputs + conditions are unique.

**Returns**:

- `Plan` - The validated plan.

## ReadOnlyPlan Objects

```python
class ReadOnlyPlan(Plan)
```

A read-only copy of a plan, passed to agents for reference.

This class provides a non-modifiable view of a plan instance,
ensuring that agents can access plan details without altering them.

#### from\_plan

```python
@classmethod
def from_plan(cls, plan: Plan) -> ReadOnlyPlan
```

Create a read-only plan from a normal plan.

**Arguments**:

- `plan` _Plan_ - The original plan instance to create a read-only copy from.
  

**Returns**:

- `ReadOnlyPlan` - A new read-only instance of the provided plan.
</file>

<file path="docs/SDK/portia/portia.md">
---
sidebar_label: portia
title: portia.portia
---

Portia classes that plan and execute runs for queries.

This module contains the core classes responsible for generating, managing, and executing plans
in response to queries. The `Portia` class serves as the main entry point, orchestrating the
planning and execution process. It uses various agents and tools to carry out tasks step by step,
saving the state of the run at each stage. It also handles error cases, clarification
requests, and run state transitions.

The `Portia` class provides methods to:

- Generate a plan for executing a query.
- Create and manage runs.
- Execute runs step by step, using agents to handle the execution of tasks.
- Resolve clarifications required during the execution of runs.
- Wait for runs to reach a state where they can be resumed.

Modules in this file work with different storage backends (memory, disk, cloud) and can handle
complex queries using various planning and execution agent configurations.

## RunContext Objects

```python
class RunContext(BaseModel)
```

Data that is returned from a step.

## Portia Objects

```python
class Portia()
```

Portia client is the top level abstraction and entrypoint for most programs using the SDK.

It is responsible for intermediating planning via PlanningAgents and
execution via ExecutionAgents.

#### \_\_init\_\_

```python
def __init__(config: Config | None = None,
             tools: ToolRegistry | list[Tool] | None = None,
             execution_hooks: ExecutionHooks | None = None,
             telemetry: BaseProductTelemetry | None = None) -> None
```

Initialize storage and tools.

**Arguments**:

- `config` _Config_ - The configuration to initialize the Portia client. If not provided, the
  default configuration will be used.
- `tools` _ToolRegistry | list[Tool]_ - The registry or list of tools to use. If not
  provided, the open source tool registry will be used, alongside the default tools
  from Portia cloud if a Portia API key is set.
- `execution_hooks` _ExecutionHooks | None_ - Hooks that can be used to modify or add
  extra functionality to the run of a plan.
- `telemetry` _BaseProductTelemetry | None_ - Anonymous telemetry service.

#### initialize\_end\_user

```python
def initialize_end_user(end_user: str | EndUser | None = None) -> EndUser
```

Handle initializing the end_user based on the provided type.

#### ainitialize\_end\_user

```python
async def ainitialize_end_user(
        end_user: str | EndUser | None = None) -> EndUser
```

Handle initializing the end_user based on the provided type.

#### run

```python
def run(query: str,
        tools: list[Tool] | list[str] | None = None,
        example_plans: Sequence[Plan | PlanUUID | str] | None = None,
        end_user: str | EndUser | None = None,
        plan_run_inputs: list[PlanInput] | list[dict[str, str]]
        | dict[str, str] | None = None,
        structured_output_schema: type[BaseModel] | None = None,
        use_cached_plan: bool = False) -> PlanRun
```

End-to-end function to generate a plan and then execute it.

This is the simplest way to plan and execute a query using the SDK.

**Arguments**:

- `query` _str_ - The query to be executed.
- `tools` _list[Tool] | list[str] | None_ - List of tools to use for the query.
  If not provided all tools in the registry will be used.
- `example_plans` _Sequence[Plan | PlanUUID | str] | None_ - Optional list of example
  plans or plan IDs. This can include Plan objects, PlanUUID objects,
  or plan ID strings (starting with &quot;plan-&quot;). Plan IDs will be loaded from
  storage. If not provided, a default set of example plans will be used.
- `end_user` _str | EndUser | None = None_ - The end user for this plan run.
  plan_run_inputs (list[PlanInput] | list[dict[str, str]] | dict[str, str] | None):
  Provides input values for the run. This can be a list of PlanInput objects, a list
  of dicts with keys &quot;name&quot;, &quot;description&quot; (optional) and &quot;value&quot;, or a dict of
  plan run input name to value.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the query. This is passed on to plan runs created from this plan but will not be
  stored with the plan itself if using cloud storage and must be re-attached to the
  plan run if using cloud storage.
- `use_cached_plan` _bool_ - Whether to use a cached plan if it exists.
  

**Returns**:

- `PlanRun` - The run resulting from executing the query.

#### arun

```python
async def arun(query: str,
               tools: list[Tool] | list[str] | None = None,
               example_plans: Sequence[Plan | PlanUUID | str] | None = None,
               end_user: str | EndUser | None = None,
               plan_run_inputs: list[PlanInput] | list[dict[str, str]]
               | dict[str, str] | None = None,
               structured_output_schema: type[BaseModel] | None = None,
               use_cached_plan: bool = False) -> PlanRun
```

End-to-end function to generate a plan and then execute it.

This is the simplest way to plan and execute a query using the SDK.

**Arguments**:

- `query` _str_ - The query to be executed.
- `tools` _list[Tool] | list[str] | None_ - List of tools to use for the query.
  If not provided all tools in the registry will be used.
- `example_plans` _Sequence[Plan | PlanUUID | str] | None_ - Optional list of example
  plans or plan IDs. This can include Plan objects, PlanUUID objects,
  or plan ID strings (starting with &quot;plan-&quot;). Plan IDs will be loaded from
  storage. If not provided, a default set of example plans will be used.
- `end_user` _str | EndUser | None = None_ - The end user for this plan run.
  plan_run_inputs (list[PlanInput] | list[dict[str, str]] | dict[str, str] | None):
  Provides input values for the run. This can be a list of PlanInput objects, a list
  of dicts with keys &quot;name&quot;, &quot;description&quot; (optional) and &quot;value&quot;, or a dict of
  plan run input name to value.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the query. This is passed on to plan runs created from this plan but will not be
  stored with the plan itself if using cloud storage and must be re-attached to the
  plan run if using cloud storage.
- `use_cached_plan` _bool_ - Whether to use a cached plan if it exists.
  

**Returns**:

- `PlanRun` - The run resulting from executing the query.

#### plan

```python
def plan(query: str,
         tools: list[Tool] | list[str] | None = None,
         example_plans: Sequence[Plan | PlanUUID | str] | None = None,
         end_user: str | EndUser | None = None,
         plan_inputs: list[PlanInput] | list[dict[str, str]] | list[str]
         | None = None,
         structured_output_schema: type[BaseModel] | None = None,
         use_cached_plan: bool = False) -> Plan
```

Plans how to do the query given the set of tools and any examples.

**Arguments**:

- `query` _str_ - The query to generate the plan for.
- `tools` _list[Tool] | list[str] | None_ - List of tools to use for the query.
  If not provided all tools in the registry will be used.
- `example_plans` _Sequence[Plan | PlanUUID | str] | None_ - Optional list of example
  plans or plan IDs.
  This can include Plan objects, PlanUUID objects, or plan ID strings
  (starting with &quot;plan-&quot;). Plan IDs will be loaded from storage.
  If not provided, a default set of example plans will be used.
- `end_user` _str | EndUser | None = None_ - The optional end user for this plan.
- `plan_inputs` _list[PlanInput] | list[dict[str, str]] | list[str] | None_ - Optional list
  of inputs required for the plan.
  This can be a list of Planinput objects, a list of dicts with keys &quot;name&quot; and
  &quot;description&quot; (optional), or a list of plan run input names. If a value is provided
  with a PlanInput object or in a dictionary, it will be ignored as values are only
  used when running the plan.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the query. This is passed on to plan runs created from this plan but will be
  not be stored with the plan itself if using cloud storage and must be re-attached
  to the plan run if using cloud storage.
- `use_cached_plan` _bool_ - Whether to use a cached plan if it exists.
  

**Returns**:

- `Plan` - The plan for executing the query.
  

**Raises**:

- `PlanError` - If there is an error while generating the plan.

#### aplan

```python
async def aplan(query: str,
                tools: list[Tool] | list[str] | None = None,
                example_plans: Sequence[Plan | PlanUUID | str] | None = None,
                end_user: str | EndUser | None = None,
                plan_inputs: list[PlanInput] | list[dict[str, str]] | list[str]
                | None = None,
                structured_output_schema: type[BaseModel] | None = None,
                use_cached_plan: bool = False) -> Plan
```

Plans how to do the query given the set of tools and any examples asynchronously.

**Arguments**:

- `query` _str_ - The query to generate the plan for.
- `tools` _list[Tool] | list[str] | None_ - List of tools to use for the query.
  If not provided all tools in the registry will be used.
- `example_plans` _list[Plan] | None_ - Optional list of example plans. If not
  provide a default set of example plans will be used.
- `end_user` _str | EndUser | None = None_ - The optional end user for this plan.
- `plan_inputs` _list[PlanInput] | list[dict[str, str]] | list[str] | None_ - Optional list
  of inputs required for the plan.
  This can be a list of Planinput objects, a list of dicts with keys &quot;name&quot; and
  &quot;description&quot; (optional), or a list of plan run input names. If a value is provided
  with a PlanInput object or in a dictionary, it will be ignored as values are only
  used when running the plan.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the query. This is passed on to plan runs created from this plan but will be
  not be stored with the plan itself if using cloud storage and must be re-attached
  to the plan run if using cloud storage.
- `use_cached_plan` _bool_ - Whether to use a cached plan if it exists.
  

**Returns**:

- `Plan` - The plan for executing the query.
  

**Raises**:

- `PlanError` - If there is an error while generating the plan.

#### run\_plan

```python
def run_plan(
        plan: Plan | PlanUUID | UUID | PlanV2,
        end_user: str | EndUser | None = None,
        plan_run_inputs: list[PlanInput]
    | list[dict[str, Serializable]]
    | dict[str, Serializable]
    | None = None,
        structured_output_schema: type[BaseModel] | None = None) -> PlanRun
```

Run a plan.

**Arguments**:

- `plan` _Plan | PlanUUID | UUID | PlanV2_ - The plan to run, or the ID of the plan to load from
  storage.
- `end_user` _str | EndUser | None = None_ - The end user to use.
  plan_run_inputs (list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None):
  Provides input values for the run. This can be a list of PlanInput objects, a list
  of dicts with keys &quot;name&quot;, &quot;description&quot; (optional) and &quot;value&quot;, or a dict of
  plan run input name to value.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the plan run. This is passed on to plan runs created from this plan but will be
  

**Returns**:

- `PlanRun` - The resulting PlanRun object.

#### arun\_plan

```python
async def arun_plan(
        plan: Plan | PlanUUID | UUID | PlanV2,
        end_user: str | EndUser | None = None,
        plan_run_inputs: list[PlanInput]
    | list[dict[str, Serializable]]
    | dict[str, Serializable]
    | None = None,
        structured_output_schema: type[BaseModel] | None = None) -> PlanRun
```

Run a plan asynchronously.

**Arguments**:

- `plan` _Plan | PlanUUID | UUID_ - The plan to run, or the ID of the plan to load from
  storage.
- `end_user` _str | EndUser | None = None_ - The end user to use.
  plan_run_inputs (list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None):
  Provides input values for the run. This can be a list of PlanInput objects, a list
  of dicts with keys &quot;name&quot;, &quot;description&quot; (optional) and &quot;value&quot;, or a dict of
  plan run input name to value.
- `structured_output_schema` _type[BaseModel] | None_ - The optional structured output schema
  for the plan run. This is passed on to plan runs created from this plan but will be
  

**Returns**:

- `PlanRun` - The resulting PlanRun object.

#### resume

```python
def resume(plan_run: PlanRun | None = None,
           plan_run_id: PlanRunUUID | str | None = None,
           plan: PlanV2 | None = None) -> PlanRun
```

Resume a PlanRun.

If a clarification handler was provided as part of the execution hooks, it will be used
to handle any clarifications that are raised during the execution of the plan run.
If no clarification handler was provided and a clarification is raised, the run will be
returned in the `NEED_CLARIFICATION` state. The clarification will then need to be handled
by the caller before the plan run is resumed.

**Arguments**:

- `plan_run` _PlanRun | None_ - The PlanRun to resume. Defaults to None.
- `plan_run_id` _RunUUID | str | None_ - The ID of the PlanRun to resume. Defaults to
  None.
- `plan` _PlanV2 | None_ - If using a plan built with the Plan Builder, the plan must be
  passed in here in order to resume.
  

**Returns**:

- `PlanRun` - The resulting PlanRun after execution.
  

**Raises**:

- `ValueError` - If neither plan_run nor plan_run_id is provided.
- `InvalidPlanRunStateError` - If the plan run is not in a valid state to be resumed.

#### aresume

```python
async def aresume(plan_run: PlanRun | None = None,
                  plan_run_id: PlanRunUUID | str | None = None,
                  plan: PlanV2 | None = None) -> PlanRun
```

Resume a PlanRun.

If a clarification handler was provided as part of the execution hooks, it will be used
to handle any clarifications that are raised during the execution of the plan run.
If no clarification handler was provided and a clarification is raised, the run will be
returned in the `NEED_CLARIFICATION` state. The clarification will then need to be handled
by the caller before the plan run is resumed.

**Arguments**:

- `plan_run` _PlanRun | None_ - The PlanRun to resume. Defaults to None.
- `plan_run_id` _RunUUID | str | None_ - The ID of the PlanRun to resume. Defaults to
  None.
- `plan` _PlanV2 | None_ - If using a plan built with the Plan Builder, the plan must be
  passed in here in order to resume.
  

**Returns**:

- `PlanRun` - The resulting PlanRun after execution.
  

**Raises**:

- `ValueError` - If neither plan_run nor plan_run_id is provided.
- `InvalidPlanRunStateError` - If the plan run is not in a valid state to be resumed.

#### execute\_plan\_run\_and\_handle\_clarifications

```python
def execute_plan_run_and_handle_clarifications(plan: Plan,
                                               plan_run: PlanRun) -> PlanRun
```

Execute a plan run and handle any clarifications that are raised.

#### aexecute\_plan\_run\_and\_handle\_clarifications

```python
async def aexecute_plan_run_and_handle_clarifications(
        plan: Plan, plan_run: PlanRun) -> PlanRun
```

Execute a plan run and handle any clarifications that are raised.

#### resolve\_clarification

```python
def resolve_clarification(clarification: Clarification, response: object,
                          plan_run: PlanRun) -> PlanRun
```

Resolve a clarification updating the run state as needed.

**Arguments**:

- `clarification` _Clarification_ - The clarification to resolve.
- `response` _object_ - The response to the clarification.
- `plan_run` _PlanRun | None_ - Optional - the plan run being updated.
  

**Returns**:

- `PlanRun` - The updated PlanRun.

#### error\_clarification

```python
def error_clarification(clarification: Clarification, error: object,
                        plan_run: PlanRun) -> PlanRun
```

Mark that there was an error handling the clarification.

#### wait\_for\_ready

```python
def wait_for_ready(plan_run: PlanRun,
                   max_retries: int = 6,
                   backoff_start_time_seconds: int = 7 * 60,
                   backoff_time_seconds: int = 2) -> PlanRun
```

Wait for the run to be in a state that it can be re-plan_run.

This is generally because there are outstanding clarifications that need to be resolved.

**Arguments**:

- `plan_run` _PlanRun_ - The PlanRun to wait for.
- `max_retries` _int_ - The maximum number of retries to wait for the run to be ready
  after the backoff period starts.
- `backoff_start_time_seconds` _int_ - The time after which the backoff period starts.
- `backoff_time_seconds` _int_ - The time to wait between retries after the backoff period
  starts.
  

**Returns**:

- `PlanRun` - The updated PlanRun once it is ready to be re-plan_run.
  

**Raises**:

- `InvalidRunStateError` - If the run cannot be waited for.

#### create\_plan\_run

```python
def create_plan_run(plan: Plan,
                    end_user: str | EndUser | None = None,
                    plan_run_inputs: list[PlanInput] | None = None) -> PlanRun
```

Create a PlanRun from a Plan.

**Arguments**:

- `plan` _Plan_ - The plan to create a plan run from.
- `end_user` _str | EndUser | None = None_ - The end user this plan run is for.
- `plan_run_inputs` _list[PlanInput] | None = None_ - The plan inputs for the
  plan run with their values.
  

**Returns**:

- `PlanRun` - The created PlanRun object.

#### acreate\_plan\_run

```python
async def acreate_plan_run(
        plan: Plan,
        end_user: str | EndUser | None = None,
        plan_run_inputs: list[PlanInput] | None = None) -> PlanRun
```

Create a PlanRun from a Plan.

**Arguments**:

- `plan` _Plan_ - The plan to create a plan run from.
- `end_user` _str | EndUser | None = None_ - The end user this plan run is for.
- `plan_run_inputs` _list[PlanInput] | None = None_ - The plan inputs for the
  plan run with their values.
  

**Returns**:

- `PlanRun` - The created PlanRun object.

#### get\_tool

```python
def get_tool(tool_id: str | None, plan_run: PlanRun) -> Tool | None
```

Get the tool for a step.

#### get\_agent\_for\_step

```python
def get_agent_for_step(step: Step, plan: Plan,
                       plan_run: PlanRun) -> BaseExecutionAgent
```

Get the appropriate agent for executing a given step.

**Arguments**:

- `step` _Step_ - The step for which the agent is needed.
- `plan` _Plan_ - The plan associated with the step.
- `plan_run` _PlanRun_ - The run associated with the step.
  

**Returns**:

- `BaseAgent` - The agent to execute the step.

#### run\_builder\_plan

```python
@traceable(name="Portia - Run Plan")
async def run_builder_plan(
        plan: PlanV2,
        end_user: EndUser,
        plan_run_inputs: list[PlanInput]
    | list[dict[str, Serializable]]
    | dict[str, Serializable]
    | None = None,
        structured_output_schema: type[BaseModel] | None = None) -> PlanRun
```

Run a Portia plan.

#### resume\_builder\_plan

```python
async def resume_builder_plan(plan: PlanV2,
                              plan_run: PlanRun,
                              end_user: EndUser | None = None,
                              legacy_plan: Plan | None = None) -> PlanRun
```

Resume a Portia plan.
</file>

<file path="docs/SDK/portia/storage.md">
---
sidebar_label: storage
title: portia.storage
---

Storage classes for managing the saving and retrieval of plans, runs, and tool calls.

This module defines a set of storage classes that provide different backends for saving, retrieving,
and managing plans, runs, and tool calls. These storage classes include both in-memory and
file-based storage, as well as integration with the Portia Cloud API. Each class is responsible
for handling interactions with its respective storage medium, including validating responses
and raising appropriate exceptions when necessary.

Classes:
    - Storage (Base Class): A base class that defines common interfaces for all storage types,
    ensuring consistent methods for saving and retrieving plans, runs, and tool calls.
    - InMemoryStorage: An in-memory implementation of the `Storage` class for storing plans,
    runs, and tool calls in a temporary, volatile storage medium.
    - FileStorage: A file-based implementation of the `Storage` class for storing plans, runs,
      and tool calls as local files in the filesystem.
    - PortiaCloudStorage: A cloud-based implementation of the `Storage` class that interacts with
    the Portia Cloud API to save and retrieve plans, runs, and tool call records.

Each storage class handles the following tasks:
    - Sending and receiving data to its respective storage medium - memory, file system, or API.
    - Validating responses from storage and raising errors when necessary.
    - Handling exceptions and re-raising them as custom `StorageError` exceptions to provide
    more informative error handling.

## PlanStorage Objects

```python
class PlanStorage(ABC)
```

Abstract base class for storing and retrieving plans.

Subclasses must implement the methods to save and retrieve plans.

**Methods**:

  save_plan(self, plan: Plan) -&gt; None:
  Save a plan.
  get_plan(self, plan_id: PlanUUID) -&gt; Plan:
  Get a plan by ID.
  plan_exists(self, plan_id: PlanUUID) -&gt; bool:
  Check if a plan exists without raising an error.

#### save\_plan

```python
@abstractmethod
def save_plan(plan: Plan) -> None
```

Save a plan.

**Arguments**:

- `plan` _Plan_ - The Plan object to save.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_plan

```python
@abstractmethod
def get_plan(plan_id: PlanUUID) -> Plan
```

Retrieve a plan by its ID.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to retrieve.
  

**Returns**:

- `Plan` - The Plan object associated with the provided plan_id.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_plan\_by\_query

```python
@abstractmethod
def get_plan_by_query(query: str) -> Plan
```

Get a plan by query.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### plan\_exists

```python
@abstractmethod
def plan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists without raising an error.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_similar\_plans

```python
def get_similar_plans(query: str,
                      threshold: float = 0.5,
                      limit: int = 10) -> list[Plan]
```

Get similar plans to the query.

**Arguments**:

- `query` _str_ - The query to get similar plans for.
- `threshold` _float_ - The threshold for similarity.
- `limit` _int_ - The maximum number of plans to return.
  

**Returns**:

- `list[Plan]` - The list of similar plans.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### asave\_plan

```python
async def asave_plan(plan: Plan) -> None
```

Save a plan asynchronously using threaded execution.

**Arguments**:

- `plan` _Plan_ - The Plan object to save.

#### aget\_plan

```python
async def aget_plan(plan_id: PlanUUID) -> Plan
```

Retrieve a plan by its ID asynchronously using threaded execution.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to retrieve.
  

**Returns**:

- `Plan` - The Plan object associated with the provided plan_id.

#### aget\_plan\_by\_query

```python
async def aget_plan_by_query(query: str) -> Plan
```

Get a plan by query asynchronously using threaded execution.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### aplan\_exists

```python
async def aplan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists without raising an error asynchronously using threaded execution.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.

#### aget\_similar\_plans

```python
async def aget_similar_plans(query: str,
                             threshold: float = 0.5,
                             limit: int = 10) -> list[Plan]
```

Get similar plans to the query asynchronously using threaded execution.

**Arguments**:

- `query` _str_ - The query to get similar plans for.
- `threshold` _float_ - The threshold for similarity.
- `limit` _int_ - The maximum number of plans to return.
  

**Returns**:

- `list[Plan]` - The list of similar plans.

## PlanRunListResponse Objects

```python
class PlanRunListResponse(BaseModel)
```

Response for the get_plan_runs operation. Can support pagination.

## RunStorage Objects

```python
class RunStorage(ABC)
```

Abstract base class for storing and retrieving runs.

Subclasses must implement the methods to save and retrieve PlanRuns.

**Methods**:

  save_plan_run(self, run: Run) -&gt; None:
  Save a PlanRun.
  get_plan_run(self, plan_run_id: PlanRunUUID) -&gt; PlanRun:
  Get PlanRun by ID.
  get_plan_runs(self, run_state: RunState | None = None, page=int | None = None)
  -&gt; PlanRunListResponse:
  Return runs that match the given run_state

#### save\_plan\_run

```python
@abstractmethod
def save_plan_run(plan_run: PlanRun) -> None
```

Save a PlanRun.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_plan\_run

```python
@abstractmethod
def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Retrieve PlanRun by its ID.

**Arguments**:

- `plan_run_id` _RunUUID_ - The UUID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object associated with the provided plan_run_id.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_plan\_runs

```python
@abstractmethod
def get_plan_runs(run_state: PlanRunState | None = None,
                  page: int | None = None) -> PlanRunListResponse
```

List runs by their state.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data
  

**Returns**:

- `list[Run]` - A list of Run objects that match the given state.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### asave\_plan\_run

```python
async def asave_plan_run(plan_run: PlanRun) -> None
```

Save a PlanRun asynchronously using threaded execution.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save.

#### aget\_plan\_run

```python
async def aget_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Retrieve PlanRun by its ID asynchronously using threaded execution.

**Arguments**:

- `plan_run_id` _RunUUID_ - The UUID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object associated with the provided plan_run_id.

#### aget\_plan\_runs

```python
async def aget_plan_runs(run_state: PlanRunState | None = None,
                         page: int | None = None) -> PlanRunListResponse
```

List runs by their state asynchronously using threaded execution.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data
  

**Returns**:

- `list[Run]` - A list of Run objects that match the given state.

## AdditionalStorage Objects

```python
class AdditionalStorage(ABC)
```

Abstract base class for additional storage.

Subclasses must implement the methods.

**Methods**:

  save_tool_call(self, tool_call: ToolCallRecord) -&gt; None:
  Save a tool_call.

#### save\_tool\_call

```python
@abstractmethod
def save_tool_call(tool_call: ToolCallRecord) -> None
```

Save a ToolCall.

**Arguments**:

- `tool_call` _ToolCallRecord_ - The ToolCallRecord object to save.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### save\_end\_user

```python
@abstractmethod
def save_end_user(end_user: EndUser) -> EndUser
```

Save an end user.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_end\_user

```python
@abstractmethod
def get_end_user(external_id: str) -> EndUser | None
```

Get an end user.

**Arguments**:

- `external_id` _str_ - The id of the end user to get.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### asave\_tool\_call

```python
async def asave_tool_call(tool_call: ToolCallRecord) -> None
```

Save a tool_call asynchronously using threaded execution.

**Arguments**:

- `tool_call` _ToolCallRecord_ - The ToolCallRecord object to save.

#### asave\_end\_user

```python
async def asave_end_user(end_user: EndUser) -> EndUser
```

Save an end user asynchronously using threaded execution.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save.

#### aget\_end\_user

```python
async def aget_end_user(external_id: str) -> EndUser | None
```

Get an end user asynchronously using threaded execution.

**Arguments**:

- `external_id` _str_ - The id of the end user to get.

## Storage Objects

```python
class Storage(PlanStorage, RunStorage, AdditionalStorage)
```

Combined base class for Plan Run + Additional storages.

## AgentMemory Objects

```python
class AgentMemory(ABC)
```

Abstract base class for storing items in agent memory.

#### save\_plan\_run\_output

```python
@abstractmethod
def save_plan_run_output(output_name: str, output: Output,
                         plan_run_id: PlanRunUUID) -> Output
```

Save an output from a plan run to agent memory.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRunUUID_ - The ID of the current plan run
  

**Returns**:

- `Output` - The Output object with value marked as stored in agent memory.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### get\_plan\_run\_output

```python
@abstractmethod
def get_plan_run_output(output_name: str,
                        plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from agent memory.

**Arguments**:

- `output_name` _str_ - The name of the output to retrieve
- `plan_run_id` _PlanRunUUID_ - The ID of the plan run
  

**Returns**:

- `Output` - The retrieved Output object with value filled in from agent memory.
  

**Raises**:

- `NotImplementedError` - If the method is not implemented.

#### asave\_plan\_run\_output

```python
async def asave_plan_run_output(output_name: str, output: Output,
                                plan_run_id: PlanRunUUID) -> Output
```

Save an output from a plan run to agent memory asynchronously using threaded execution.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRunUUID_ - The ID of the current plan run
  

**Returns**:

- `Output` - The Output object with value marked as stored in agent memory.

#### aget\_plan\_run\_output

```python
async def aget_plan_run_output(output_name: str,
                               plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from agent memory asynchronously using threaded execution.

**Arguments**:

- `output_name` _str_ - The name of the output to retrieve
- `plan_run_id` _PlanRunUUID_ - The ID of the plan run
  

**Returns**:

- `Output` - The retrieved Output object with value filled in from agent memory.

#### log\_tool\_call

```python
def log_tool_call(tool_call: ToolCallRecord) -> None
```

Log the tool call.

**Arguments**:

- `tool_call` _ToolCallRecord_ - The ToolCallRecord object to log.

## InMemoryStorage Objects

```python
class InMemoryStorage(PlanStorage, RunStorage, AdditionalStorage, AgentMemory)
```

Simple storage class that keeps plans + runs in memory.

Tool Calls are logged via the LogAdditionalStorage.

#### \_\_init\_\_

```python
def __init__() -> None
```

Initialize Storage.

#### save\_plan

```python
def save_plan(plan: Plan) -> None
```

Add plan to dict.

**Arguments**:

- `plan` _Plan_ - The Plan object to save.

#### get\_plan

```python
def get_plan(plan_id: PlanUUID) -> Plan
```

Get plan from dict.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to retrieve.
  

**Returns**:

- `Plan` - The Plan object associated with the provided plan_id.
  

**Raises**:

- `PlanNotFoundError` - If the plan is not found.

#### get\_plan\_by\_query

```python
def get_plan_by_query(query: str) -> Plan
```

Get a plan by query.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### plan\_exists

```python
def plan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists in memory.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.

#### save\_plan\_run

```python
def save_plan_run(plan_run: PlanRun) -> None
```

Add run to dict.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save.

#### get\_plan\_run

```python
def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Get run from dict.

**Arguments**:

- `plan_run_id` _PlanRunUUID_ - The UUID of the PlanRun to retrieve.
  

**Returns**:

- `PlanRun` - The PlanRun object associated with the provided plan_run_id.
  

**Raises**:

- `PlanRunNotFoundError` - If the PlanRun is not found.

#### get\_plan\_runs

```python
def get_plan_runs(run_state: PlanRunState | None = None,
                  page: int | None = None) -> PlanRunListResponse
```

Get run from dict.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data which is not used for in memory storage.
  

**Returns**:

- `list[Run]` - A list of Run objects that match the given state.

#### save\_plan\_run\_output

```python
def save_plan_run_output(output_name: str, output: Output,
                         plan_run_id: PlanRunUUID) -> Output
```

Save Output from a plan run to memory.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRunUUID_ - The ID of the current plan run

#### get\_plan\_run\_output

```python
def get_plan_run_output(output_name: str,
                        plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from memory.

**Arguments**:

- `output_name` _str_ - The name of the output to retrieve
- `plan_run_id` _PlanRunUUID_ - The ID of the plan run
  

**Returns**:

- `Output` - The retrieved Output object
  

**Raises**:

- `KeyError` - If the output is not found

#### save\_tool\_call

```python
def save_tool_call(tool_call: ToolCallRecord) -> None
```

Log the tool call.

#### save\_end\_user

```python
def save_end_user(end_user: EndUser) -> EndUser
```

Add end_user to dict.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save.

#### get\_end\_user

```python
def get_end_user(external_id: str) -> EndUser | None
```

Get end_user from dict or init a new one.

**Arguments**:

- `external_id` _str_ - The id of the end user object to get.

## DiskFileStorage Objects

```python
class DiskFileStorage(PlanStorage, RunStorage, AdditionalStorage, AgentMemory)
```

Disk-based implementation of the Storage interface.

Stores serialized Plan and Run objects as JSON files on disk.

#### \_\_init\_\_

```python
def __init__(storage_dir: str | None) -> None
```

Set storage dir.

**Arguments**:

- `storage_dir` _str | None_ - Optional directory for storing files.

#### save\_plan

```python
def save_plan(plan: Plan) -> None
```

Save a Plan object to the storage.

**Arguments**:

- `plan` _Plan_ - The Plan object to save.

#### get\_plan

```python
def get_plan(plan_id: PlanUUID) -> Plan
```

Retrieve a Plan object by its ID.

**Arguments**:

- `plan_id` _PlanUUID_ - The ID of the Plan to retrieve.
  

**Returns**:

- `Plan` - The retrieved Plan object.
  

**Raises**:

- `PlanNotFoundError` - If the Plan is not found or validation fails.

#### get\_plan\_by\_query

```python
def get_plan_by_query(query: str) -> Plan
```

Get a plan by query.

This method will return the first plan that matches the query. This is not always the most
recent plan.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### plan\_exists

```python
def plan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists on disk.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.

#### save\_plan\_run

```python
def save_plan_run(plan_run: PlanRun) -> None
```

Save PlanRun object to the storage.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save.

#### get\_plan\_run

```python
def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Retrieve PlanRun object by its ID.

**Arguments**:

- `plan_run_id` _RunUUID_ - The ID of the Run to retrieve.
  

**Returns**:

- `Run` - The retrieved Run object.
  

**Raises**:

- `RunNotFoundError` - If the Run is not found or validation fails.

#### get\_plan\_runs

```python
def get_plan_runs(run_state: PlanRunState | None = None,
                  page: int | None = None) -> PlanRunListResponse
```

Find all plan runs in storage that match state.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data which is not used for in memory storage.
  

**Returns**:

- `list[Run]` - A list of Run objects that match the given state.

#### save\_plan\_run\_output

```python
def save_plan_run_output(output_name: str, output: Output,
                         plan_run_id: PlanRunUUID) -> Output
```

Save Output from a plan run to agent memory on disk.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRunUUID_ - The ID of the current plan run

#### get\_plan\_run\_output

```python
def get_plan_run_output(output_name: str,
                        plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from agent memory on disk.

**Arguments**:

- `output_name` _str_ - The name of the output to retrieve
- `plan_run_id` _PlanRunUUID_ - The ID of the plan run
  

**Returns**:

- `Output` - The retrieved Output object
  

**Raises**:

- `FileNotFoundError` - If the output file is not found
- `ValidationError` - If the deserialization fails

#### save\_tool\_call

```python
def save_tool_call(tool_call: ToolCallRecord) -> None
```

Log the tool call.

#### save\_end\_user

```python
def save_end_user(end_user: EndUser) -> EndUser
```

Write end_user to dict.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save.

#### get\_end\_user

```python
def get_end_user(external_id: str) -> EndUser | None
```

Get end_user from dict or init a new one.

**Arguments**:

- `external_id` _str_ - The id of the end user object to get.

## PortiaCloudStorage Objects

```python
class PortiaCloudStorage(Storage, AgentMemory)
```

Save plans, runs and tool calls to portia cloud.

#### \_\_init\_\_

```python
def __init__(config: Config,
             cache_dir: str | None = None,
             max_cache_size: int = DEFAULT_MAX_CACHE_SIZE) -> None
```

Initialize the PortiaCloudStorage instance.

**Arguments**:

- `config` _Config_ - The configuration containing API details for Portia Cloud.
- `cache_dir` _str | None_ - Optional directory for local caching of outputs.
- `max_cache_size` _int_ - The maximum number of files to cache locally.

#### check\_response

```python
def check_response(response: httpx.Response) -> None
```

Validate the response from Portia API.

**Arguments**:

- `response` _httpx.Response_ - The response from the Portia API to check.
  

**Raises**:

- `StorageError` - If the response from the Portia API indicates an error.

#### save\_plan

```python
def save_plan(plan: Plan) -> None
```

Save a plan to Portia Cloud.

**Arguments**:

- `plan` _Plan_ - The Plan object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### asave\_plan

```python
async def asave_plan(plan: Plan) -> None
```

Save a plan to Portia Cloud.

**Arguments**:

- `plan` _Plan_ - The Plan object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### get\_plan

```python
def get_plan(plan_id: PlanUUID) -> Plan
```

Retrieve a plan from Portia Cloud.

**Arguments**:

- `plan_id` _PlanUUID_ - The ID of the plan to retrieve.
  

**Returns**:

- `Plan` - The Plan object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the plan does not exist.

#### aget\_plan

```python
async def aget_plan(plan_id: PlanUUID) -> Plan
```

Retrieve a plan from Portia Cloud.

**Arguments**:

- `plan_id` _PlanUUID_ - The ID of the plan to retrieve.
  

**Returns**:

- `Plan` - The Plan object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the plan does not exist.

#### get\_plan\_by\_query

```python
def get_plan_by_query(query: str) -> Plan
```

Get a plan by query.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### aget\_plan\_by\_query

```python
async def aget_plan_by_query(query: str) -> Plan
```

Get a plan by query asynchronously using threaded execution.

**Arguments**:

- `query` _str_ - The query to get a plan for.

#### plan\_exists

```python
def plan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists in Portia Cloud.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.

#### aplan\_exists

```python
async def aplan_exists(plan_id: PlanUUID) -> bool
```

Check if a plan exists in Portia Cloud.

**Arguments**:

- `plan_id` _PlanUUID_ - The UUID of the plan to check.
  

**Returns**:

- `bool` - True if the plan exists, False otherwise.

#### save\_plan\_run

```python
def save_plan_run(plan_run: PlanRun) -> None
```

Save PlanRun to Portia Cloud.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### asave\_plan\_run

```python
async def asave_plan_run(plan_run: PlanRun) -> None
```

Save PlanRun to Portia Cloud.

**Arguments**:

- `plan_run` _PlanRun_ - The Run object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### get\_plan\_run

```python
def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Retrieve PlanRun from Portia Cloud.

**Arguments**:

- `plan_run_id` _RunUUID_ - The ID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the run does not exist.

#### aget\_plan\_run

```python
async def aget_plan_run(plan_run_id: PlanRunUUID) -> PlanRun
```

Retrieve PlanRun from Portia Cloud.

**Arguments**:

- `plan_run_id` _RunUUID_ - The ID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the run does not exist.

#### get\_plan\_runs

```python
def get_plan_runs(run_state: PlanRunState | None = None,
                  page: int | None = None) -> PlanRunListResponse
```

Find all runs in storage that match state.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data which is not used for in memory storage.
  

**Returns**:

- `list[Run]` - A list of Run objects retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### aget\_plan\_runs

```python
async def aget_plan_runs(run_state: PlanRunState | None = None,
                         page: int | None = None) -> PlanRunListResponse
```

Find all runs in storage that match state.

**Arguments**:

- `run_state` _RunState | None_ - Optionally filter runs by their state.
- `page` _int | None_ - Optional pagination data which is not used for in memory storage.
  

**Returns**:

- `list[Run]` - A list of Run objects retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### save\_tool\_call

```python
def save_tool_call(tool_call: ToolCallRecord) -> None
```

Save a tool call to Portia Cloud.

This method attempts to save the tool call to Portia Cloud but will not raise exceptions
if the request fails. Instead, it logs the error and continues execution.

**Arguments**:

- `tool_call` _ToolCallRecord_ - The ToolCallRecord object to save to the cloud.

#### asave\_tool\_call

```python
async def asave_tool_call(tool_call: ToolCallRecord) -> None
```

Save a tool call to Portia Cloud.

This method attempts to save the tool call to Portia Cloud but will not raise exceptions
if the request fails. Instead, it logs the error and continues execution.

**Arguments**:

- `tool_call` _ToolCallRecord_ - The ToolCallRecord object to save to the cloud.

#### save\_plan\_run\_output

```python
def save_plan_run_output(output_name: str, output: Output,
                         plan_run_id: PlanRunUUID) -> Output
```

Save Output from a plan run to Portia Cloud.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRun_ - The if of the current plan run
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### asave\_plan\_run\_output

```python
async def asave_plan_run_output(output_name: str, output: Output,
                                plan_run_id: PlanRunUUID) -> Output
```

Save Output from a plan run to Portia Cloud.

**Arguments**:

- `output_name` _str_ - The name of the output within the plan
- `output` _Output_ - The Output object to save
- `plan_run_id` _PlanRun_ - The if of the current plan run
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### get\_plan\_run\_output

```python
def get_plan_run_output(output_name: str,
                        plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from Portia Cloud.

**Arguments**:

- `output_name` - The name of the output to get from memory
- `plan_run_id` _RunUUID_ - The ID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the run does not exist.

#### aget\_plan\_run\_output

```python
async def aget_plan_run_output(output_name: str,
                               plan_run_id: PlanRunUUID) -> LocalDataValue
```

Retrieve an Output from Portia Cloud.

**Arguments**:

- `output_name` - The name of the output to get from memory
- `plan_run_id` _RunUUID_ - The ID of the run to retrieve.
  

**Returns**:

- `Run` - The Run object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the run does not exist.

#### get\_similar\_plans

```python
def get_similar_plans(query: str,
                      threshold: float = 0.5,
                      limit: int = 5) -> list[Plan]
```

Get similar plans to the query.

**Arguments**:

- `query` _str_ - The query to get similar plans for.
- `threshold` _float_ - The threshold for similarity.
- `limit` _int_ - The maximum number of plans to return.
  

**Returns**:

- `list[Plan]` - The list of similar plans.

#### aget\_similar\_plans

```python
async def aget_similar_plans(query: str,
                             threshold: float = 0.5,
                             limit: int = 5) -> list[Plan]
```

Get similar plans to the query.

**Arguments**:

- `query` _str_ - The query to get similar plans for.
- `threshold` _float_ - The threshold for similarity.
- `limit` _int_ - The maximum number of plans to return.
  

**Returns**:

- `list[Plan]` - The list of similar plans.

#### save\_end\_user

```python
def save_end_user(end_user: EndUser) -> EndUser
```

Save an end_user to Portia Cloud.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### asave\_end\_user

```python
async def asave_end_user(end_user: EndUser) -> EndUser
```

Save an end_user to Portia Cloud.

**Arguments**:

- `end_user` _EndUser_ - The EndUser object to save to the cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails.

#### get\_end\_user

```python
def get_end_user(external_id: str) -> EndUser
```

Retrieve an end user from Portia Cloud.

**Arguments**:

- `external_id` _str_ - The ID of the end user to retrieve.
  

**Returns**:

- `EndUser` - The EndUser object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the plan does not exist.

#### aget\_end\_user

```python
async def aget_end_user(external_id: str) -> EndUser | None
```

Retrieve an end user from Portia Cloud.

**Arguments**:

- `external_id` _str_ - The ID of the end user to retrieve.
  

**Returns**:

- `EndUser` - The EndUser object retrieved from Portia Cloud.
  

**Raises**:

- `StorageError` - If the request to Portia Cloud fails or the plan does not exist.
</file>

<file path="docs/SDK/portia/token_check.md">
---
sidebar_label: token_check
title: portia.token_check
---

Token counting utilities with fallback for offline environments.

#### estimate\_tokens

```python
def estimate_tokens(text: str) -> int
```

Estimate the number of tokens in a string using character-based estimation.

We used to do a proper count using tiktoken, but that loads encodings from the internet at
runtime, which doens&#x27;t work in environments where we don&#x27;t have internet access / where network
access is locked down. As our current usages only require an estimate, this suffices for now.

#### exceeds\_context\_threshold

```python
def exceeds_context_threshold(value: Any,
                              model: GenerativeModel,
                              threshold_percentage: float = 1) -> bool
```

Check if a value is under a given threshold percentage of a model&#x27;s context window size.

**Arguments**:

- `value` - The value to check (will be converted to string for token estimation)
- `model` - The generative model to get context window size from
- `threshold_percentage` - A percentage threshold to apply. For example, 0.9 means that this will
  return True if the value exceeds 90% of the context window size.
  

**Returns**:

- `bool` - True if the estimated tokens are less than the threshold, False otherwise
</file>

<file path="docs/SDK/portia/tool_call.md">
---
sidebar_label: tool_call
title: portia.tool_call
---

Tool Call module contains classes that record the outcome of a single tool call.

The `ToolCallStatus` enum defines the various states a tool call can be in, such
as in progress, successful, requiring clarification, or failing.

The `ToolCallRecord` class is a Pydantic model used to capture details about a
specific tool call, including its status, input, output, and associated metadata.

## ToolCallStatus Objects

```python
class ToolCallStatus(PortiaEnum)
```

The status of the tool call.

**Attributes**:

- `IN_PROGRESS` - The tool is currently in progress.
- `NEED_CLARIFICATION` - The tool raise a clarification.
- `SUCCESS` - The tool executed successfully.
- `FAILED` - The tool raised an error.

## ToolCallRecord Objects

```python
class ToolCallRecord(BaseModel)
```

Model that records the details of an individual tool call.

This class captures all relevant information about a single tool call
within a PlanRun including metadata, input and output data, and status.

**Attributes**:

- `tool_name` _str_ - The name of the tool being called.
- `plan_run_id` _RunUUID_ - The unique identifier of the run to which this tool call
  belongs.
- `step` _int_ - The step number of the tool call in the PlanRun.
- `end_user_id` _str | None_ - The ID of the end user, if applicable. Can be None.
- `status` _ToolCallStatus_ - The current status of the tool call (e.g., IN_PROGRESS, SUCCESS).
- `input` _Any_ - The input data passed to the tool call.
- `output` _Any_ - The output data returned from the tool call.
- `latency_seconds` _float_ - The latency in seconds for the tool call to complete.

#### serialize\_input

```python
def serialize_input() -> Any
```

Handle serialization of inputs.

#### serialize\_output

```python
def serialize_output() -> Any
```

Handle serialization of outputs.
</file>

<file path="docs/SDK/portia/tool_decorator.md">
---
sidebar_label: tool_decorator
title: portia.tool_decorator
---

Tool decorator for creating tools from functions.

#### tool

```python
def tool(fn: Callable[..., T]) -> type[Tool[T]]
```

Convert a function into a Tool class.

This decorator automatically creates a Tool subclass from a function by:
- Using the function&#x27;s docstring as the tool description
- Creating an ID and name based on the function name
- Generating input schema from function parameters and type hints
- Determining output schema from return type annotation

**Example**:

  @tool
  def add_numbers(a: int, b: int) -&gt; int:
  &quot;&quot;&quot;Add two numbers together.&quot;&quot;&quot;
  return a + b
  

**Arguments**:

- `fn` - The function to convert to a Tool class
  

**Returns**:

  A Tool subclass that wraps the original function
  

**Raises**:

- `ValueError` - If the function has invalid signature or return type
</file>

<file path="docs/SDK/portia/tool_registry.md">
---
sidebar_label: tool_registry
title: portia.tool_registry
---

A ToolRegistry represents a source of tools.

This module defines various implementations of `ToolRegistry`, which is responsible for managing
and interacting with tools. It provides interfaces for registering, retrieving, and listing tools.
The `ToolRegistry` can also support aggregation of multiple registries and searching for tools
based on queries.

Classes:
    ToolRegistry: The base interface for managing tools.
    AggregatedToolRegistry: A registry that aggregates multiple tool registries.
    InMemoryToolRegistry: A simple in-memory implementation of `ToolRegistry`.
    PortiaToolRegistry: A tool registry that interacts with the Portia API to manage tools.
    MCPToolRegistry: A tool registry that interacts with a locally running MCP server.

## ToolRegistry Objects

```python
class ToolRegistry()
```

ToolRegistry is the base class for managing tools.

This class implements the essential methods for interacting with tool registries, including
registering, retrieving, and listing tools. Specific tool registries can override these methods
and provide additional functionality.

**Methods**:

- `with_tool(tool` - Tool, *, overwrite: bool = False) -&gt; None:
  Inserts a new tool.
- `replace_tool(tool` - Tool) -&gt; None:
  Replaces a tool with a new tool in the current registry.
  NB. This is a shortcut for `with_tool(tool, overwrite=True)`.
- `get_tool(tool_id` - str) -&gt; Tool:
  Retrieves a tool by its ID.
  get_tools() -&gt; list[Tool]:
  Retrieves all tools in the registry.
- `match_tools(query` - str | None = None, tool_ids: list[str] | None = None) -&gt; list[Tool]:
  Optionally, retrieve tools that match a given query and tool_ids.
- `filter_tools(predicate` - Callable[[Tool], bool]) -&gt; ToolRegistry:
  Create a new tool registry with only the tools that match the predicate. Useful to
  implement tool exclusions.
  with_tool_description(
- `tool_id` - str,
- `updated_description` - str,
  *,
- `overwrite` - bool = False,
  ) -&gt; ToolRegistry:
  Extend or override the description of a tool in the registry.

#### \_\_init\_\_

```python
def __init__(tools: dict[str, Tool] | Sequence[Tool] | None = None) -> None
```

Initialize the tool registry with a sequence or dictionary of tools.

**Arguments**:

- `tools` _dict[str, Tool] | Sequence[Tool]_ - A sequence of tools or a
  dictionary of tool IDs to tools.

#### with\_tool

```python
def with_tool(tool: Tool, *, overwrite: bool = False) -> None
```

Update a tool based on tool ID or inserts a new tool.

**Arguments**:

- `tool` _Tool_ - The tool to be added or updated.
- `overwrite` _bool_ - Whether to overwrite an existing tool with the same ID.
  

**Returns**:

- `None` - The tool registry is updated in place.

#### replace\_tool

```python
def replace_tool(tool: Tool) -> None
```

Replace a tool with a new tool.

**Arguments**:

- `tool` _Tool_ - The tool to replace the existing tool with.
  

**Returns**:

- `None` - The tool registry is updated in place.

#### get\_tool

```python
def get_tool(tool_id: str) -> Tool
```

Retrieve a tool&#x27;s information.

**Arguments**:

- `tool_id` _str_ - The ID of the tool to retrieve.
  

**Returns**:

- `Tool` - The requested tool.
  

**Raises**:

- `ToolNotFoundError` - If the tool with the given ID does not exist.

#### get\_tools

```python
def get_tools() -> list[Tool]
```

Get all tools registered with the registry.

**Returns**:

- `list[Tool]` - A list of all tools in the registry.

#### match\_tools

```python
def match_tools(query: str | None = None,
                tool_ids: list[str] | None = None) -> list[Tool]
```

Provide a set of tools that match a given query and tool_ids.

**Arguments**:

- `query` _str | None_ - The query to match tools against.
- `tool_ids` _list[str] | None_ - The list of tool ids to match.
  

**Returns**:

- `list[Tool]` - A list of tools matching the query.
  
  This method is useful to implement tool filtering whereby only a selection of tools are
  passed to the PlanningAgent based on the query.
  This method is optional to implement and will default to providing all tools.

#### filter\_tools

```python
def filter_tools(predicate: Callable[[Tool], bool]) -> ToolRegistry
```

Filter the tools in the registry based on a predicate.

**Arguments**:

- `predicate` _Callable[[Tool], bool]_ - A predicate to filter the tools.
  

**Returns**:

- `Self` - A new ToolRegistry with the filtered tools.

#### with\_tool\_description

```python
def with_tool_description(tool_id: str,
                          updated_description: str,
                          *,
                          overwrite: bool = False) -> ToolRegistry
```

Update a tool with an extension or override of the tool description.

**Arguments**:

- `tool_id` _str_ - The id of the tool to update.
- `updated_description` _str_ - The tool description to update. If `overwrite` is False, this
  will extend the existing tool description, otherwise, the entire tool description
  will be updated.
- `overwrite` _bool_ - Whether to update or extend the existing tool description.
  

**Returns**:

- `Self` - The tool registry is updated in place and returned.
  
  Particularly useful for customising tools in MCP servers for usecases. A deep copy is made
  of the underlying tool such that the tool description is only updated within this registry.
  Logs a warning if the tool is not found.

#### \_\_add\_\_

```python
def __add__(other: ToolRegistry | list[Tool]) -> ToolRegistry
```

Return an aggregated tool registry combining two registries or a registry and tool list.

Tool IDs must be unique across the two registries otherwise an error will be thrown.

**Arguments**:

- `other` _ToolRegistry_ - Another tool registry to be combined.
  

**Returns**:

- `AggregatedToolRegistry` - A new tool registry containing tools from both registries.

#### \_\_radd\_\_

```python
def __radd__(other: ToolRegistry | list[Tool]) -> ToolRegistry
```

Return an aggregated tool registry combining two registries or a registry and tool list.

Tool IDs must be unique across the two registries otherwise an error will be thrown.

**Arguments**:

- `other` _ToolRegistry_ - Another tool registry to be combined.
  

**Returns**:

- `ToolRegistry` - A new tool registry containing tools from both registries.

#### \_\_iter\_\_

```python
def __iter__() -> Iterator[Tool]
```

Iterate over the tools in the registry.

#### \_\_len\_\_

```python
def __len__() -> int
```

Return the number of tools in the registry.

#### \_\_contains\_\_

```python
def __contains__(tool_id: str) -> bool
```

Check if a tool is in the registry.

## InMemoryToolRegistry Objects

```python
class InMemoryToolRegistry(ToolRegistry)
```

Provides a simple in-memory tool registry.

This class stores tools in memory, allowing for quick access without persistence.

Warning: This registry is DEPRECATED. Use ToolRegistry instead.

#### from\_local\_tools

```python
@classmethod
def from_local_tools(cls, tools: Sequence[Tool]) -> InMemoryToolRegistry
```

Easily create a local tool registry from a sequence of tools.

**Arguments**:

- `tools` _Sequence[Tool]_ - A sequence of tools to initialize the registry.
  

**Returns**:

- `InMemoryToolRegistry` - A new in-memory tool registry.

## PortiaToolRegistry Objects

```python
class PortiaToolRegistry(ToolRegistry)
```

Provides access to Portia tools.

This class interacts with the Portia API to retrieve and manage tools.

#### \_\_init\_\_

```python
def __init__(config: Config | None = None,
             client: httpx.Client | None = None,
             tools: dict[str, Tool] | Sequence[Tool] | None = None) -> None
```

Initialize the PortiaToolRegistry with the given configuration.

**Arguments**:

- `config` _Config | None_ - The configuration containing the API key and endpoint.
- `client` _httpx.Client | None_ - An optional httpx client to use. If not provided, a new
  client will be created.
- `tools` _dict[str, Tool] | None_ - A dictionary of tool IDs to tools to create the
  registry with. If not provided, all tools will be loaded from the Portia API.

#### with\_default\_tool\_filter

```python
def with_default_tool_filter() -> PortiaToolRegistry
```

Create a PortiaToolRegistry with a default tool filter.

## McpToolRegistry Objects

```python
class McpToolRegistry(ToolRegistry)
```

Provides access to tools within a Model Context Protocol (MCP) server.

See https://modelcontextprotocol.io/introduction for more information on MCP.

#### from\_sse\_connection

```python
@classmethod
def from_sse_connection(
        cls,
        server_name: str,
        url: str,
        headers: dict[str, Any] | None = None,
        timeout: float = 5,
        sse_read_timeout: float = 60 * 5,
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using an SSE connection (Sync version).

#### from\_sse\_connection\_async

```python
@classmethod
async def from_sse_connection_async(
        cls,
        server_name: str,
        url: str,
        headers: dict[str, Any] | None = None,
        timeout: float = 5,
        sse_read_timeout: float = 60 * 5,
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using an SSE connection (Async version).

#### from\_stdio\_connection

```python
@classmethod
def from_stdio_connection(
        cls,
        server_name: str,
        command: str,
        args: list[str] | None = None,
        env: dict[str, str] | None = None,
        encoding: str = "utf-8",
        encoding_error_handler: Literal["strict", "ignore",
                                        "replace"] = "strict",
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using a stdio connection (Sync version).

#### from\_stdio\_connection\_raw

```python
@classmethod
def from_stdio_connection_raw(
        cls,
        config: str | dict[str, Any],
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using a stdio connection from a string.

Parses commonly used mcp client config formats.

**Arguments**:

- `config` - The string or dict to parse.
- `tool_list_read_timeout` - The timeout for the request.
- `tool_call_timeout_seconds` - The timeout for the tool call.
  

**Returns**:

  A McpToolRegistry.

#### from\_stdio\_connection\_async

```python
@classmethod
async def from_stdio_connection_async(
        cls,
        server_name: str,
        command: str,
        args: list[str] | None = None,
        env: dict[str, str] | None = None,
        encoding: str = "utf-8",
        encoding_error_handler: Literal["strict", "ignore",
                                        "replace"] = "strict",
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using a stdio connection (Async version).

#### from\_streamable\_http\_connection

```python
@classmethod
def from_streamable_http_connection(
        cls,
        server_name: str,
        url: str,
        headers: dict[str, Any] | None = None,
        timeout: float = 30,
        sse_read_timeout: float = 60 * 5,
        *,
        terminate_on_close: bool = True,
        auth: httpx.Auth | None = None,
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using a StreamableHTTP connection (Sync version).

#### from\_streamable\_http\_connection\_async

```python
@classmethod
async def from_streamable_http_connection_async(
        cls,
        server_name: str,
        url: str,
        headers: dict[str, Any] | None = None,
        timeout: float = 30,
        sse_read_timeout: float = 60 * 5,
        *,
        terminate_on_close: bool = True,
        auth: httpx.Auth | None = None,
        tool_list_read_timeout: float | None = None,
        tool_call_timeout_seconds: float | None = None) -> McpToolRegistry
```

Create a new MCPToolRegistry using a StreamableHTTP connection (Async version).

## DefaultToolRegistry Objects

```python
class DefaultToolRegistry(ToolRegistry)
```

A registry providing a default set of tools.

This includes the following tools:
- All open source tools that don&#x27;t require API keys
- Search, map, extract, and crawl tools if you have a Tavily API key
- Weather tool if you have an OpenWeatherMap API key
- Portia cloud tools if you have a Portia cloud API key

#### \_\_init\_\_

```python
def __init__(config: Config) -> None
```

Initialize the default tool registry with the given configuration.

## GeneratedBaseModel Objects

```python
class GeneratedBaseModel(BaseModel)
```

BaseModel that is generated from a JSON schema.

Handles serialization of fields that must omit None values: fields that are not required in
the JSON schema, but that are not nullable. Pydantic has no concept of an omissible field,
so we must for it to be nullable and then make sure we don&#x27;t serialize None values.

#### \_\_init\_subclass\_\_

```python
def __init_subclass__(cls) -> None
```

Ensure omissible fields are isolated between models.

#### serialize

```python
@model_serializer(mode="wrap")
def serialize(handler: SerializerFunctionWrapHandler) -> dict[str, Any]
```

Serialize the model to a dictionary, excluding fields for which we must omit None.

#### extend\_exclude\_unset\_fields

```python
@classmethod
def extend_exclude_unset_fields(cls, fields: list[str]) -> None
```

Extend the list of fields to exclude from serialization.

#### generate\_pydantic\_model\_from\_json\_schema

```python
def generate_pydantic_model_from_json_schema(
        model_name: str, json_schema: dict[str, Any]) -> type[BaseModel]
```

Generate a Pydantic model based on a JSON schema.

**Arguments**:

- `model_name` _str_ - The name of the Pydantic model.
- `json_schema` _dict[str, Any]_ - The schema to generate the model from.
  

**Returns**:

- `type[BaseModel]` - The generated Pydantic model class.
</file>

<file path="docs/SDK/portia/tool_wrapper.md">
---
sidebar_label: tool_wrapper
title: portia.tool_wrapper
---

Tool Wrapper that intercepts run calls and records them.

This module contains the `ToolCallWrapper` class, which wraps around an existing tool and records
information about the tool&#x27;s execution, such as input, output, latency, and status. The recorded
data is stored in `AdditionalStorage` for later use.

Classes:
    ToolCallWrapper: A wrapper that intercepts tool calls, records execution data, and stores it.

## ToolCallWrapper Objects

```python
class ToolCallWrapper(Tool)
```

Tool Wrapper that records calls to its child tool and sends them to the AdditionalStorage.

This class is a wrapper around a child tool. It captures the input and output, measures latency,
and records the status of the execution. The results are then stored in the provided
`AdditionalStorage`.

**Attributes**:

- `model_config` _ConfigDict_ - Pydantic configuration that allows arbitrary types.
- `_child_tool` _Tool_ - The child tool to be wrapped and executed.
- `_storage` _AdditionalStorage_ - Storage mechanism to save tool call records.
- `_plan_run` _PlanRun_ - The run context for the current execution.

#### \_\_init\_\_

```python
def __init__(child_tool: Tool, storage: AdditionalStorage,
             plan_run: PlanRun) -> None
```

Initialize parent fields using child_tool&#x27;s attributes.

**Arguments**:

- `child_tool` _Tool_ - The child tool to be wrapped.
- `storage` _AdditionalStorage_ - The storage to save execution records.
- `plan_run` _PlanRun_ - The PlanRun to execute.

#### ready

```python
def ready(ctx: ToolRunContext) -> ReadyResponse
```

Check if the child tool is ready and return ReadyResponse.

#### run

```python
def run(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> Any | Clarification
```

Run the child tool and store the outcome.

This method executes the child tool with the provided arguments, records the input,
output, latency, and status of the execution, and stores the details in `AdditionalStorage`.

**Arguments**:

- `ctx` _ToolRunContext_ - The context containing user data and metadata.
- `*args` _Any_ - Positional arguments for the child tool.
- `**kwargs` _Any_ - Keyword arguments for the child tool.
  

**Returns**:

  Any | Clarification: The output of the child tool or a clarification request.
  

**Raises**:

- `Exception` - If an error occurs during execution, the exception is logged, and the
  status is set to `FAILED`.
</file>

<file path="docs/SDK/portia/tool.md">
---
sidebar_label: tool
title: portia.tool
---

Tools module.

This module defines an abstract base class for tools, providing a structure for creating custom
tools that can integrate with external systems. It includes an implementation of a base `Tool` class
that defines common attributes and behaviors, such as a unique ID and name. Child classes should
implement the `run` method to define the specific logic for interacting with the external systems
or performing actions.

The module also contains `PortiaRemoteTool`, a subclass of `Tool`, which implements the logic to
interact with Portia Cloud, including handling API responses and tool errors.

The tools in this module are designed to be extendable, allowing users to create their own tools
while relying on common functionality provided by the base class.

## ToolRunContext Objects

```python
class ToolRunContext(BaseModel)
```

Context passed to tools when running.

**Attributes**:

- `plan_run(PlanRun)` - The run the tool run is part of.
- `plan(Plan)` - The plan the tool run is part of.
- `config(Config)` - The config for the SDK as a whole.
- `clarifications(ClarificationListType)` - Relevant clarifications for this tool plan_run.

## ReadyResponse Objects

```python
class ReadyResponse(BaseModel)
```

Response from the /ready endpoint.

## Tool Objects

```python
class Tool(BaseModel, Generic[SERIALIZABLE_TYPE_VAR])
```

Abstract base class for a tool.

This class serves as the blueprint for all tools. Child classes must implement the `run` method.

**Attributes**:

- `id` _str_ - A unique identifier for the tool.
  This must be unique as collisions in a tool registry will lead to errors.
- `name` _str_ - The name of the tool. The name is informational only but useful for debugging.
- `description` _str_ - Purpose of the tool and usage.
  This is important information for the planning_agent module to know when and
  how to use this tool.
- `args_schema` _type[BaseModel]_ - The schema defining the expected input arguments for the tool.
  We use Pydantic models to define these types.
- `output_schema` _tuple[str, str]_ - A tuple containing the type and description of the tool&#x27;s
  output. To maximize the advantages of using an agentic approach this doesn&#x27;t need to be
  tightly defined. Instead it should give just a high level overview of the type and
  contents of the tools output.
- `should_summarize` _bool_ - Indicates whether the tool&#x27;s output should be automatically summarized
  by the summarizer agent. For some tools summarization is useful (for example: a tool
  that fetches the latest news) whereas other tools it&#x27;s not (for example: a tool
  that fetches raw price data).

#### ready

```python
def ready(ctx: ToolRunContext) -> ReadyResponse
```

Check whether the tool can be plan_run.

This method can be implemented by subclasses to allow checking if the tool can be plan_run.
It may run any authentication logic or other required checks before returning its status.
If left unimplemented will always return true.

**Arguments**:

- `ctx` _ToolRunContext_ - Co
  ntext of the tool run
  

**Returns**:

- `ReadyResponse` - Whether the tool is ready to run and any clarifications that need to be
  resolved

#### run

```python
@abstractmethod
def run(ctx: ToolRunContext, *args: Any,
        **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | Clarification
```

Run the tool.

This method must be implemented by subclasses to define the tool&#x27;s specific behavior.

**Arguments**:

- `ctx` _ToolRunContext_ - Context of the tool execution
- `args` _Any_ - The arguments passed to the tool for execution.
- `kwargs` _Any_ - The keyword arguments passed to the tool for execution.
  

**Returns**:

- `Any` - The result of the tool&#x27;s execution which can be any serializable type
  or a clarification.

#### arun

```python
async def arun(ctx: ToolRunContext, *args: Any,
               **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | Clarification
```

Async run the tool.

**Arguments**:

- `ctx` _ToolRunContext_ - The context for the tool.
- `*args` _Any_ - Additional positional arguments for the tool function.
- `**kwargs` _Any_ - Additional keyword arguments for the tool function.
  

**Returns**:

  SERIALIZABLE_TYPE_VAR | Clarification: The result of the tool&#x27;s execution which can be
  any serializable type or a clarification.

#### check\_description\_length

```python
@model_validator(mode="after")
def check_description_length() -> Self
```

Check that the description is less than 16384 characters.

OpenAI has a maximum function description length of 16384 characters. This validator
ensures that the tool description does not exceed this limit.

**Returns**:

- `Self` - The current instance of the tool.
  

**Raises**:

- `InvalidToolDescriptionError` - If the description exceeds the maximum length.

#### check\_run\_method\_signature

```python
@model_validator(mode="after")
def check_run_method_signature() -> Self
```

Ensure the run method signature matches the args_schema.

#### to\_langchain

```python
def to_langchain(ctx: ToolRunContext, sync: bool = True) -> StructuredTool
```

Return a LangChain representation of this tool.

This function provides a LangChain-compatible version of the tool. The response format is
the default one without including artifacts. The ExecutionContext is baked into the
StructuredTool via a partial run function.

**Arguments**:

- `ctx` _ToolRunContext_ - The context for the tool.
- `sync` _bool_ - Whether to use the sync or async version of the tool.
  

**Returns**:

- `StructuredTool` - The LangChain-compatible representation of the tool, including the
  tool&#x27;s name, description, and argument schema, with the execution context baked
  into the function.

#### to\_langchain\_with\_artifact

```python
def to_langchain_with_artifact(ctx: ToolRunContext,
                               sync: bool = True) -> StructuredTool
```

Return a LangChain representation of this tool with content and artifact.

This function provides a LangChain-compatible version of the tool, where the response format
includes both the content and the artifact. The ToolRunContext is baked into the
StructuredTool via a partial run function for capturing output directly.

**Arguments**:

- `ctx` _ToolRunContext_ - The context for the tool.
- `sync` _bool_ - Whether to use the sync or async version of the tool.
  

**Returns**:

- `StructuredTool` - The LangChain-compatible representation of the tool, including the
  tool&#x27;s name, description, argument schema, and the ability to return both content
  and artifact.

#### args\_json\_schema

```python
def args_json_schema() -> dict[str, Any]
```

Return the json_schema for the tool args.

This function retrieves the JSON schema for the tool&#x27;s arguments, which defines the expected
input structure.

**Returns**:

  dict[str, Any]: The JSON schema representing the tool&#x27;s arguments.

#### \_\_str\_\_

```python
def __str__() -> str
```

Return the string representation.

This method generates a string representation of the tool, including its ID, name,
description, argument schema, and output schema.

**Returns**:

- `str` - A string representation of the tool.

#### serialize\_args\_schema

```python
@field_serializer("args_schema")
def serialize_args_schema(value: type[BaseModel]) -> str
```

Serialize the args_schema by returning its class name.

This function serializes the arguments schema by returning the class name of the schema.

**Arguments**:

- `value` _type[BaseModel]_ - The argument schema class.
  

**Returns**:

- `str` - The class name of the argument schema.

#### pretty

```python
def pretty() -> str
```

Return a pretty string representation of the tool.

## PortiaRemoteTool Objects

```python
class PortiaRemoteTool(Tool, Generic[SERIALIZABLE_TYPE_VAR])
```

Tool that passes run execution to Portia Cloud.

#### parse\_response

```python
def parse_response(ctx: ToolRunContext, response: dict[str, Any]) -> Output
```

Parse a JSON response into domain models or errors.

This method handles the response from the Portia Cloud API, converting it into domain
specific models. It also handles errors, including `ToolSoftError` and `ToolHardError`,
as well as clarifications of different types.

**Arguments**:

- `ctx` _ToolRunContext_ - Context of the environment
- `response` _dict[str, Any]_ - The JSON response returned by the Portia Cloud API.
  

**Returns**:

- `Output` - The parsed output wrapped in an `Output` object.
  

**Raises**:

- `ToolSoftError` - If a soft error is encountered in the response.
- `ToolHardError` - If a hard error is encountered in the response.

#### ready

```python
def ready(ctx: ToolRunContext) -> ReadyResponse
```

Check if the remote tool is ready by calling the /ready endpoint.

**Arguments**:

- `ctx` _ToolRunContext_ - Context of the environment
  

**Returns**:

- `ReadyResponse` - Whether the tool is ready to run and any clarifications that
  need to be resolved

#### run

```python
def run(ctx: ToolRunContext, *args: Any,
        **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | None | Clarification
```

Invoke the run endpoint and handle the response.

This method sends the execution request to the Portia Cloud API, passing the arguments and
execution context. It then processes the response by calling `parse_response`. Errors
during the request or parsing are raised as `ToolHardError`.

**Arguments**:

- `ctx` _ToolRunContext_ - The context of the execution, including end user ID, run ID
  and additional data.
- `*args` _Any_ - The positional arguments for the tool.
- `**kwargs` _Any_ - The keyword arguments for the tool.
  

**Returns**:

  SERIALIZABLE_TYPE_VAR | None | Clarification: The result of the run execution, which
  could either be a serialized value, None, or a `Clarification` object.
  

**Raises**:

- `ToolHardError` - If the request fails or there is an error parsing the response.

#### batch\_ready\_check

```python
@classmethod
def batch_ready_check(cls, config: Config, tool_ids: set[str],
                      tool_run_context: ToolRunContext) -> ReadyResponse
```

Batch check readiness for Portia cloud tools.

**Arguments**:

- `config` _Config_ - The config for the SDK as a whole.
- `tool_ids` _set[str]_ - The list of tool IDs to check readiness for.
- `tool_run_context` _ToolRunContext_ - The context of the execution.
  

**Returns**:

- `ReadyResponse` - The readiness response for the tools.

## PortiaMcpTool Objects

```python
class PortiaMcpTool(Tool[str])
```

A Portia Tool wrapper for an MCP server-based tool.

#### run

```python
def run(_: ToolRunContext, **kwargs: Any) -> str
```

Invoke the tool by dispatching to the MCP server.

**Arguments**:

- `_` - The tool run context
- `**kwargs` - The arguments to pass to the MCP tool invocation
  

**Returns**:

- `str` - The result of the tool call

#### arun

```python
async def arun(_: ToolRunContext, **kwargs: Any) -> str
```

Invoke the tool by dispatching to the MCP server asynchronously.

#### call\_remote\_mcp\_tool

```python
async def call_remote_mcp_tool(name: str,
                               arguments: dict | None = None) -> str
```

Call a tool using the MCP session.

There are issues with the implementation of the mcp client which mean that the
`read_timeout_seconds` still waits for a response from the server before raising
a timeout, which is entirely defeating the purpose of the timeout on our side.

This method implements a custom timeout using `asyncio.wait`, allowing us to
raise the correct exception when the deadline is reached.

#### flatten\_exceptions

```python
def flatten_exceptions(exc_group: BaseExceptionGroup[Any],
                       exc_type: type[ExceptionT]) -> list[ExceptionT]
```

Flatten an ExceptionGroup into a list of exceptions of a given type.
</file>

<file path="docs/SDK/portia/version.md">
---
sidebar_label: version
title: portia.version
---

Version utilities for Portia SDK.

#### get\_version

```python
def get_version() -> str
```

Get the current version of the Portia SDK.

This function works both when the package is installed as a dependency
and when run directly from source. When run from source, it attempts
to read the version from pyproject.toml.

**Returns**:

- `str` - The current version of the Portia SDK
</file>

<file path="docs/SDK/example_builder.md">
---
sidebar_label: example_builder
title: example_builder
---

A simple example of using the PlanBuilderV2.

## CommodityPriceWithCurrency Objects

```python
class CommodityPriceWithCurrency(BaseModel)
```

Price of a commodity.

## FinalOutput Objects

```python
class FinalOutput(BaseModel)
```

Final output of the plan.
</file>

<file path="docs/SDK/sidebar.json">
{
  "items": [
    {
      "items": [
        "SDK/portia/builder/conditionals",
        "SDK/portia/builder/plan_builder_v2",
        "SDK/portia/builder/plan_v2",
        "SDK/portia/builder/reference",
        "SDK/portia/builder/step_v2"
      ],
      "label": "portia.builder",
      "type": "category"
    },
    {
      "items": [
        {
          "items": [
            "SDK/portia/execution_agents/utils/final_output_summarizer",
            "SDK/portia/execution_agents/utils/step_summarizer"
          ],
          "label": "portia.execution_agents.utils",
          "type": "category"
        },
        "SDK/portia/execution_agents/base_execution_agent",
        "SDK/portia/execution_agents/clarification_tool",
        "SDK/portia/execution_agents/conditional_evaluation_agent",
        "SDK/portia/execution_agents/context",
        "SDK/portia/execution_agents/default_execution_agent",
        "SDK/portia/execution_agents/execution_utils",
        "SDK/portia/execution_agents/memory_extraction",
        "SDK/portia/execution_agents/one_shot_agent",
        "SDK/portia/execution_agents/output"
      ],
      "label": "portia.execution_agents",
      "type": "category"
    },
    {
      "items": [
        "SDK/portia/introspection_agents/default_introspection_agent",
        "SDK/portia/introspection_agents/introspection_agent"
      ],
      "label": "portia.introspection_agents",
      "type": "category"
    },
    {
      "items": [
        "SDK/portia/open_source_tools/browser_tool",
        "SDK/portia/open_source_tools/calculator_tool",
        "SDK/portia/open_source_tools/crawl_tool",
        "SDK/portia/open_source_tools/extract_tool",
        "SDK/portia/open_source_tools/image_understanding_tool",
        "SDK/portia/open_source_tools/llm_tool",
        "SDK/portia/open_source_tools/local_file_reader_tool",
        "SDK/portia/open_source_tools/local_file_writer_tool",
        "SDK/portia/open_source_tools/map_tool",
        "SDK/portia/open_source_tools/pdf_reader_tool",
        "SDK/portia/open_source_tools/search_tool",
        "SDK/portia/open_source_tools/weather"
      ],
      "label": "portia.open_source_tools",
      "type": "category"
    },
    {
      "items": [
        "SDK/portia/planning_agents/base_planning_agent",
        "SDK/portia/planning_agents/context",
        "SDK/portia/planning_agents/default_planning_agent"
      ],
      "label": "portia.planning_agents",
      "type": "category"
    },
    {
      "items": [
        "SDK/portia/telemetry/telemetry_service",
        "SDK/portia/telemetry/views"
      ],
      "label": "portia.telemetry",
      "type": "category"
    },
    "SDK/portia/clarification",
    "SDK/portia/clarification_handler",
    "SDK/portia/cloud",
    "SDK/portia/config",
    "SDK/portia/end_user",
    "SDK/portia/errors",
    "SDK/portia/execution_hooks",
    "SDK/portia/gemini_langsmith_wrapper",
    "SDK/portia/logger",
    "SDK/portia/mcp_session",
    "SDK/portia/model",
    "SDK/portia/plan",
    "SDK/portia/plan_run",
    "SDK/portia/portia",
    "SDK/portia/storage",
    "SDK/portia/token_check",
    "SDK/portia/tool",
    "SDK/portia/tool_call",
    "SDK/portia/tool_decorator",
    "SDK/portia/tool_registry",
    "SDK/portia/tool_wrapper",
    "SDK/portia/version"
  ],
  "label": "portia",
  "type": "category"
}
</file>

<file path="docs/.spelling">
# markdown-spellcheck spelling configuration file
# Format - lines beginning # are comments
# global dictionary is at the start, file overrides afterwards
# one word per line, to define a file override use ' - filename'
# where filename is relative to this configuration file
</file>

<file path="src/clientModules/posthog.ts">
import ExecutionEnvironment from "@docusaurus/ExecutionEnvironment";
import Cookies from "js-cookie";
import posthog from "posthog-js";
⋮----
export const getEssentialCookies = () =>
export const getNonEssentialCookies = () =>
⋮----
export const onRouteUpdate = (
</file>

<file path="src/components/ItemList.tsx">
import React from "react";
import { CardLayout } from "@site/src/theme/DocCard";
import { Item } from "@site/src/lib/tools";
</file>

<file path="src/components/ToolRoot.tsx">
import React, { useState, useEffect, useMemo } from "react";
import Fuse from "fuse.js";
import { allToolsAndMcpServers, getToolCategories, getTools, McpServer, Tool, ToolCategory } from "@site/src/lib/tools";
import { ItemList } from "./ItemList";
const ToolCategoryItems: React.FC<
⋮----
const filteredLabel = (toolOrMcp: Tool | McpServer) =>
⋮----
onChange=
</file>

<file path="src/css/custom.css">
:root {
[data-theme='dark'] {
a {
table {
.menu__list-item-collapsible .menu__link {
.menu__link {
.menu__link--active {
.navbar__item {
.navbar__link--active {
[data-theme='dark'] .prism-code,
⋮----
[data-theme='dark'] .token.comment,
.theme-code-block {
.theme-code-block .clean-btn {
.tabs__item {
.footer {
.footer-dark {
.header-github-link:hover {
.header-github-link::before {
[data-theme='dark'] .header-github-link::before {
[class*="docs-doc-id-product"][class*="Portia tool catalogue"] h4 {
[data-theme='dark'] [class*="docs-doc-id-product"][class*="Portia tool catalogue"]~* h4 {
</file>

<file path="src/lib/tools.ts">
import sidebars from "@site/sidebars";
export type Tool = {
  id: string;
  label: string;
  title: string;
  type: "doc";
  customProps: {
    type: "tool";
    description: string;
    category: string;
    categoryLabel: string;
    vendorLabel: string;
  };
};
export type McpServer = {
  id: string;
  label: string;
  title: string;
  type: "doc";
  customProps: {
    type: "mcp-server";
    description: string;
    categoryLabel: string;
  };
};
export type Item = ToolCategory | Tool | McpServer;
export type ToolCategory = {
  label: string;
  type: "category";
  items: Array<Item>;
  link?: {
    type: string;
    id: string;
  };
  customProps: {
    type: "category";
    description: string;
  };
};
⋮----
const getLeaves = (sidebar) =>
export const getItems = (category: string) =>
⋮----
const findCategory = (sidebar) =>
⋮----
export const getToolCategories = (): ToolCategory[]
</file>

<file path="src/pages/examples/redoc.jsx">
function ClientOnly() {
const get_redoc_url = (current_url) => {
⋮----
url: get_redoc_url(window.location.href),
</file>

<file path="src/theme/DocCard/index.tsx">
import React, {type ReactNode} from 'react';
import DocCard from '@theme-original/DocCard';
import type DocCardType from '@theme/DocCard';
import type {WrapperProps} from '@docusaurus/types';
import clsx from 'clsx';
import Link from '@docusaurus/Link';
import styles from './styles.module.css';
import Heading from '@theme/Heading';
type Props = WrapperProps<typeof DocCardType>;
function CardContainer({
  href,
  children,
}: {
  href: string;
  children: ReactNode;
}): JSX.Element
⋮----
className=
</file>

<file path="src/theme/DocCard/styles.module.css">
.cardContainer {
.cardContainer:hover {
.cardContainer *:last-child {
.cardTitle {
.cardDescription {
</file>

<file path="src/theme/DocCardList/index.js">
export default function DocCardListWrapper(props) {
</file>

<file path="src/theme/NotFound/Content/index.js">
export default function NotFoundContent({ className }) {
⋮----
<main className={clsx("container margin-vert--xl", className)}>
</file>

<file path="src/theme/NotFound/index.js">
export default function Index() {
const title = translate({
</file>

<file path="static/api/swagger.yaml">
---
swagger: '2.0'
info:
  title: Portia API
  description: API documentation for the Portia API
  contact:
    email: hello@portialabs.ai
  version: v1
host: localhost:8080
schemes:
- http
basePath: "/api/v0"
consumes:
- application/json
produces:
- application/json
securityDefinitions:
  OAuth2:
    type: oauth2
    flow: accessCode
    authorizationUrl: https://login.porita.dev/oauth/authorize
    tokenUrl: https://login.porita.dev/oauth/token
    scopes: {}
  API-Key:
    type: apiKey
    name: Authorization
    in: header
    description: 'Format: Api-Key VALUE'
security:
- API-Key: []
- OAuth2: []
paths:
  "/applications/":
    get:
      operationId: applications_list
      summary: List
      description: ''
      parameters:
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            type: array
            items:
              "$ref": "#/definitions/Application"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Applications
      security:
      - OAuth2: []
      - API-Key: []
    parameters: []
  "/clients/":
    get:
      operationId: clients_list
      summary: List
      description: ''
      parameters:
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            type: array
            items:
              "$ref": "#/definitions/Client"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Clients
      security:
      - OAuth2: []
      - API-Key: []
    parameters: []
  "/organizations/":
    get:
      operationId: organizations_list
      summary: List
      description: List organizations that caller is a member of.
      parameters: []
      responses:
        '200':
          description: ''
          schema:
            type: array
            items:
              "$ref": "#/definitions/Organization"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Organizations
      security:
      - Bearer: []
      - API-Key: []
    post:
      operationId: organizations_create
      summary: Create
      description: Create a new organization.
      parameters:
      - name: data
        in: body
        required: true
        schema:
          "$ref": "#/definitions/CreateOrganization"
      responses:
        '201':
          description: ''
          schema:
            "$ref": "#/definitions/Organization"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Organizations
      security:
      - Bearer: []
      - API-Key: []
    parameters: []
  "/organizations/members/":
    get:
      operationId: organizations_members_list
      summary: List
      description: List all members of a specified organization.
      parameters:
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            type: array
            items:
              "$ref": "#/definitions/User"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Organization Membership
      security:
      - Bearer: []
      - API-Key: []
    post:
      operationId: organizations_members_create
      summary: Create
      description: Create a new organization.
      parameters:
      - name: data
        in: body
        required: true
        schema:
          "$ref": "#/definitions/CreateOrganizationMembership"
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '201':
          description: ''
          schema:
            "$ref": "#/definitions/OrganizationMembership"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - Organization Membership
      security:
      - Bearer: []
      - API-Key: []
    parameters: []
  "/user_api_keys/":
    get:
      operationId: user_api_keys_list
      summary: List
      description: ''
      parameters:
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            type: array
            items:
              "$ref": "#/definitions/UserAPIKey"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - User API Keys
      security:
      - OAuth2: []
      - API-Key: []
    post:
      operationId: user_api_keys_create
      summary: Create
      description: ''
      parameters:
      - name: data
        in: body
        required: true
        schema:
          "$ref": "#/definitions/CreateUserAPIKey"
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '201':
          description: ''
          schema:
            "$ref": "#/definitions/UserAPIKeyWithKey"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - User API Keys
      security:
      - OAuth2: []
      - API-Key: []
    parameters: []
  "/user_api_keys/{id}/":
    get:
      operationId: user_api_keys_read
      summary: Retrieve
      description: ''
      parameters:
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            "$ref": "#/definitions/UserAPIKey"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - User API Keys
      security:
      - OAuth2: []
      - API-Key: []
    put:
      operationId: user_api_keys_update
      summary: Update
      description: ''
      parameters:
      - name: data
        in: body
        required: true
        schema:
          "$ref": "#/definitions/UserAPIKey"
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            "$ref": "#/definitions/UserAPIKey"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - User API Keys
      security:
      - OAuth2: []
      - API-Key: []
    patch:
      operationId: user_api_keys_partial_update
      summary: Partial Update
      description: ''
      parameters:
      - name: data
        in: body
        required: true
        schema:
          "$ref": "#/definitions/UserAPIKey"
      - name: x-portia-org-id
        in: header
        description: ID of the organization the request is for.
        type: header
      responses:
        '200':
          description: ''
          schema:
            "$ref": "#/definitions/UserAPIKey"
        '400':
          description: Bad request
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '400'
              message: Bad request
        '401':
          description: Unauthorized
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '401'
              message: Unauthorized
        '409':
          description: Conflict
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '409'
              message: Conflict with the current state of the target resource
        '500':
          description: Internal Server Error
          schema:
            description: Error Schema
            type: object
            properties:
              status_code:
                description: Status code of the error response
                type: string
              message:
                description: Error message
                type: string
          examples:
            application/json:
              status_code: '500'
              message: Internal Server Error
      tags:
      - User API Keys
      security:
      - OAuth2: []
      - API-Key: []
    parameters:
    - name: id
      in: path
      description: A unique value identifying this API key.
      required: true
      type: string
definitions:
  Application:
    required:
    - name
    - client_name
    - scopes
    - tools
    type: object
    properties:
      name:
        title: Name
        type: string
        minLength: 1
      client_name:
        title: Client name
        type: string
        minLength: 1
      scopes:
        type: array
        items:
          type: string
          minLength: 1
      tools:
        type: array
        items:
          type: object
          additionalProperties:
            type: string
            x-nullable: true
  Client:
    required:
    - name
    - applications
    type: object
    properties:
      name:
        title: Name
        type: string
        minLength: 1
      applications:
        type: array
        items:
          "$ref": "#/definitions/Application"
  Organization:
    required:
    - display_name
    type: object
    properties:
      id:
        title: Id
        type: string
        format: uuid
        readOnly: true
      name:
        title: Name
        type: string
        format: slug
        pattern: "^[-a-zA-Z0-9_]+$"
        readOnly: true
        minLength: 1
      display_name:
        title: Display name
        type: string
        minLength: 1
      created:
        title: Created
        type: string
        format: date-time
        readOnly: true
      updated:
        title: Updated
        type: string
        format: date-time
        readOnly: true
  CreateOrganization:
    required:
    - name
    type: object
    properties:
      name:
        title: Name
        type: string
        format: slug
        pattern: "^[-a-zA-Z0-9_]+$"
        minLength: 1
      display_name:
        title: Display name
        type: string
        minLength: 1
        x-nullable: true
  User:
    type: object
    properties:
      id:
        title: ID
        type: integer
        readOnly: true
      email:
        title: Email address
        type: string
        format: email
        maxLength: 254
      first_name:
        title: First name
        type: string
        maxLength: 150
      last_name:
        title: Last name
        type: string
        maxLength: 150
      is_active:
        title: Active
        description: Designates whether this user should be treated as active. Unselect
          this instead of deleting accounts.
        type: boolean
      last_login:
        title: Last login
        type: string
        format: date-time
        x-nullable: true
  CreateOrganizationMembership:
    required:
    - email
    type: object
    properties:
      email:
        title: Email
        type: string
        minLength: 1
  OrganizationMembership:
    required:
    - user
    - org
    type: object
    properties:
      id:
        title: Id
        type: string
        format: uuid
        readOnly: true
      created:
        title: Created
        type: string
        format: date-time
        readOnly: true
      updated:
        title: Updated
        type: string
        format: date-time
        readOnly: true
      user:
        title: User
        type: integer
      org:
        title: Org
        type: string
        format: uuid
  UserAPIKey:
    required:
    - organization
    type: object
    properties:
      id:
        title: Id
        type: string
        readOnly: true
        minLength: 1
      prefix:
        title: Prefix
        type: string
        readOnly: true
        minLength: 1
      hashed_key:
        title: Hashed key
        type: string
        readOnly: true
        minLength: 1
      created:
        title: Created
        type: string
        format: date-time
        readOnly: true
      name:
        title: Name
        description: A free-form name for the API key. Need not be unique. 50 characters
          max.
        type: string
        maxLength: 50
        minLength: 1
      revoked:
        title: Revoked
        description: If the API key is revoked, clients cannot use it anymore. (This
          cannot be undone.)
        type: boolean
      expiry_date:
        title: Expires
        description: Once API key expires, clients cannot use it anymore.
        type: string
        format: date-time
        x-nullable: true
      user:
        title: User
        type: integer
        readOnly: true
      organization:
        title: Organization
        type: string
        format: uuid
  CreateUserAPIKey:
    type: object
    properties:
      name:
        title: Name
        description: A free-form name for the API key. Need not be unique. 50 characters
          max.
        type: string
        maxLength: 50
        minLength: 1
  UserAPIKeyWithKey:
    required:
    - api_key
    - key
    type: object
    properties:
      api_key:
        "$ref": "#/definitions/UserAPIKey"
      key:
        title: Key
        type: string
        minLength: 1
tags:
- name: Tools
  description: Tools are interfaces that an agent, chain, or LLM can use tointeract
    with the world.
  externalDocs:
    url: https://python.langchain.com/v0.1/docs/modules/tools
x-tagGroups:
- name: Tools
  tags:
  - Tools
</file>

<file path="tests/test_code_examples.py">
mock_registry_module = MagicMock()
⋮----
IMPORTS_TO_MOCK = {
TEST_CONTAINERS = {
⋮----
def test_docstrings(example: CodeExample, eval_example: EvalExample)
⋮----
# and load that code in before the current example.
dependent_examples = _get_all_dependencies(example)
⋮----
# Skip any tests that have skip=true as a tag
⋮----
# Bring up any test containers specified for the example
test_containers = [
container_contexts = [
# We mock out some imports that we use in docs that don't actually exist
original_import = __import__
contexts = [
⋮----
visited = set()
example_id = None
⋮----
example_id = tag.split("id=")[1]
⋮----
depends_on_tag = None
⋮----
depends_on_tag = tag
⋮----
dependency_ids = depends_on_tag.split("depends_on=")[1].split(",")
dependency_ids = [dep_id.strip() for dep_id in dependency_ids]
all_dependencies = []
⋮----
dep_example = _get_example_by_id(dep_id)
nested_dependencies = _get_all_dependencies(dep_example, visited.copy())
⋮----
def _get_example_by_id(id: str) -> CodeExample
⋮----
def mock_input(prompt: str) -> str
</file>

<file path=".env.example">
PORTIA_API_KEY=
OPENAI_API_KEY=
TAVILY_API_KEY=
OPENWEATHERMAP_API_KEY=
MISTRAL_API_KEY=
ANTHROPIC_API_KEY=
</file>

<file path=".gitignore">
# Dependencies
/node_modules

# Production
/build

# Generated files
.docusaurus
.cache-loader

# Misc
.DS_Store
.env.local
.env.development.local
.env.test.local
.env.production.local
.env

npm-debug.log*
yarn-debug.log*
yarn-error.log*

# uv
dist/
*.pyc
__pycache__/
.pytest_cache/
.coverage
htmlcov/
.python-version
uv.lock

demo_runs/

.portia
</file>

<file path="babel.config.js">
presets: [require.resolve('@docusaurus/core/lib/babel/preset')],
</file>

<file path="docusaurus.config.js">
plugins: [require.resolve("docusaurus-lunr-search"), "docusaurus2-dotenv-2"],
⋮----
customCss: require.resolve("./src/css/custom.css"),
⋮----
copyright: `Copyright © ${new Date().getFullYear()} Portia AI.`,
</file>

<file path="package.json">
{
  "name": "service-docs-public",
  "version": "0.0.0",
  "private": true,
  "scripts": {
    "docusaurus": "docusaurus",
    "start": "docusaurus start",
    "build": "docusaurus build",
    "swizzle": "docusaurus swizzle",
    "deploy": "docusaurus deploy",
    "clear": "docusaurus clear",
    "serve": "docusaurus serve",
    "write-translations": "docusaurus write-translations",
    "write-heading-ids": "docusaurus write-heading-ids",
    "typecheck": "tsc"
  },
  "dependencies": {
    "@docusaurus/core": "^3.7.0",
    "@docusaurus/plugin-content-pages": "^3.7.0",
    "@docusaurus/preset-classic": "^3.7.0",
    "@docusaurus/theme-mermaid": "^3.7.0",
    "clsx": "^1.2.1",
    "docusaurus-lunr-search": "^3.3.1",
    "docusaurus-theme-redoc": "^2.1.3",
    "docusaurus2-dotenv-2": "^1.4.1",
    "fuse.js": "^7.1.0",
    "js-cookie": "^3.0.5",
    "posthog-js": "^1.233.1",
    "prism-react-renderer": "^2.4.1",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "redocusaurus": "^2.0.0"
  },
  "devDependencies": {
    "@docusaurus/module-type-aliases": "^3.7.0",
    "@tsconfig/docusaurus": "^1.0.5",
    "@types/js-cookie": "^3.0.6",
    "typescript": "^4.7.4"
  },
  "browserslist": {
    "production": [
      ">0.5%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "engines": {
    "node": ">=16.14"
  },
  "packageManager": "yarn@1.22.22+sha512.a6b2f7906b721bba3d67d4aff083df04dad64c399707841b7acf00f6b133b7ac24255f2652fa22ae3534329dc6180534e98d17432037ff6fd140556e2bb3137e"
}
</file>

<file path="pyproject.toml">
[project]
name = "docs-test"
version = "0.1.0"
description = ""
authors = []
requires-python = ">=3.11,<3.14"
dependencies = [
    "pytest-examples>=0.0.15,<0.0.16",
    "portia-sdk-python[all]",
    "pytest-xdist>=3.7.0,<4",
    "testcontainers>=4.10.0,<5",
]

[dependency-groups]
dev = ["pytest>=7.4.0,<8"]

[tool.uv]
package = false

[tool.uv.sources]
portia-sdk-python = { git = "https://github.com/portiaAI/portia-sdk-python.git", rev = "081df8923f4b11b8b7667fb6b5dede5ef9760ed8" }

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
</file>

<file path="README.md">
We use [docusaurus](https://docusaurus.io) to generate our docs. Docusaurus is a static website generator that runs under Node.js. We use a [Node.js](https://nodejs.org) project management tool called [yarn](https://yarnpkg.com) to install Docusaurus and to manage project dependencies.

## Getting Started

### Prerequisites
If you do not have Node.js and yarn installed on your system, install them first.

### Installation and Running
1. Install dependencies:
   ```bash
   yarn install
   ```

2. Start the development server:
   ```bash
   yarn start
   ```

3. (Optional) To run on a different port, prefix the command with `PORT=3002` (or some other number):
   ```bash
   PORT=3002 yarn start
   ```

## Code Examples
Code examples in the docs are tested automatically using [pytest-examples](https://github.com/pydantic/pytest-examples).

To run the tests, use `uv run pytest`. For this to work, you'll need to ensure you create a **.env** file in the root of the project with the
variables listed in **.env.example**.

We ensure that all snippets of code in the repo are testing. In order to do this, we have a few tricks:
* If you start your code block with ```python depends_on=example1```, then we will look for a code snippet in the repo that has ```python id=example1` and load that code in first, allowing you to depend on that code.
* You can also use this behaviour to put in invisible setup code - simple put a code block inside HTML comment tags ([example](https://github.com/portiaAI/docs/pull/131/files#diff-4417e9ac8a583e918ba4d264eed6a2bf9850a0cb2b501919534f901d5622bfb3R225)) and then depend on that code block
* You can bring up supported test containers needed for running the test putting ```python  test_containers=redis...```
* We mock out some a few things that aren't available at test running time - e.g. imports that aren't available publicly or input() calls. See `tests/test_code_examples.py` for details.
* If you absolutely must skip a test (e.g. it's a code snippet that we're not expecting people to run), you can start your code block with ```python skip=true skip_reason=...```
</file>

<file path="sidebars.js">

</file>

<file path="tsconfig.json">
{
  // This file is not used in compilation. It is here just for a nice editor experience.
  "extends": "@tsconfig/docusaurus/tsconfig.json",
  "compilerOptions": {
    "baseUrl": ".",
    "module": "Node16",
  }
}
</file>

</files>

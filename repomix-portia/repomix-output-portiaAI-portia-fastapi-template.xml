This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ‚ãÆ---- delimiter), security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ‚ãÆ---- delimiter
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    ci.yml
app/
  api/
    __init__.py
    health.py
    run.py
  schemas/
    __init__.py
    health.py
    run.py
  services/
    __init__.py
    portia_service.py
  __init__.py
  config.py
  exceptions.py
  main.py
tests/
  __init__.py
  conftest.py
  test_api_health.py
  test_api_run.py
  test_config.py
  test_exceptions.py
  test_main.py
  test_schemas.py
  test_services.py
.gitignore
docker-compose.yml
Dockerfile
LICENSE
pyproject.toml
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/ci.yml">
name: CI
on:
  push:
    branches: [ main ]
  pull_request:
    types: [opened, synchronize, reopened]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Install uv
      uses: astral-sh/setup-uv@v6
    - name: Cache uv dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/uv
        key: ${{ runner.os }}-uv-${{ hashFiles('**/uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-uv-
    - name: Install dependencies
      run: |
        uv sync --dev
    - name: Lint with ruff
      run: |
        uv run ruff check .
    - name: Check formatting with ruff
      run: |
        uv run ruff format --check .
    - name: Run tests with coverage
      run: |
        uv run pytest tests/ --cov=app --cov-report=xml --cov-report=term-missing
</file>

<file path="app/api/__init__.py">

</file>

<file path="app/api/health.py">
logger = logging.getLogger(__name__)
router = APIRouter()
‚ãÆ----
async def health_check() -> HealthResponse
</file>

<file path="app/api/run.py">
logger = logging.getLogger(__name__)
router = APIRouter()
‚ãÆ----
result = await PortiaService.get_instance().run_query(
‚ãÆ----
async def get_available_tools() -> list[str]
‚ãÆ----
portia = PortiaService.get_instance()
</file>

<file path="app/schemas/__init__.py">

</file>

<file path="app/schemas/health.py">
class HealthResponse(BaseModel)
‚ãÆ----
status: str = Field(..., description="Application status")
version: str = Field(..., description="Application version")
model_config = {"json_schema_extra": {"examples": [{"status": "healthy", "version": "0.1.0"}]}}
</file>

<file path="app/schemas/run.py">
class RunRequest(BaseModel)
‚ãÆ----
query: str = Field(
tools: list[str] = Field(
model_config = {
class RunResponse(BaseModel)
‚ãÆ----
success: bool = Field(..., description="Whether the execution was successful")
result: Any | None = Field(default=None, description="The result of the execution")
error: str | None = Field(default=None, description="Error message if execution failed")
execution_time: float | None = Field(default=None, description="Execution time in seconds")
</file>

<file path="app/services/__init__.py">

</file>

<file path="app/services/portia_service.py">
logger = logging.getLogger(__name__)
class PortiaService
‚ãÆ----
_instance: ClassVar["PortiaService | None"] = None
def __new__(cls) -> "PortiaService"
‚ãÆ----
@classmethod
    def get_instance(cls) -> "PortiaService"
def __init__(self) -> None
def _get_portia_instance(self, tools: set[str]) -> Portia
‚ãÆ----
available_tools_map = self._get_available_tools_map()
‚ãÆ----
async def run_query(self, query: str, tools: list[str]) -> dict
‚ãÆ----
portia_instance = self._get_portia_instance(set(tools))
start_time = time.time()
‚ãÆ----
loop = asyncio.get_running_loop()
plan_run = await loop.run_in_executor(self._executor, portia_instance.run, query, tools)
result = plan_run.outputs.final_output
execution_time = round(time.time() - start_time, 2)
‚ãÆ----
execution_time = time.time() - start_time
‚ãÆ----
def available_tool_ids(self) -> list[str]
def _get_available_tools_map(self) -> dict[str, Tool]
‚ãÆ----
available_tools = DefaultToolRegistry(config=self._config).get_tools()
</file>

<file path="app/__init__.py">
__version__ = "0.1.0"
</file>

<file path="app/config.py">
def _get_version_from_pyproject() -> str
‚ãÆ----
pyproject_path = Path(__file__).parent.parent / "pyproject.toml"
‚ãÆ----
data = tomllib.load(f)
‚ãÆ----
class PortiaConfigSettings(BaseSettings)
‚ãÆ----
openai_api_key: str | None = Field(default=None, description="OpenAI API key")
anthropic_api_key: str | None = Field(default=None, description="Anthropic API key")
mistralai_api_key: str | None = Field(default=None, description="MistralAI API key")
google_api_key: str | None = Field(default=None, description="Google Generative AI API key")
azure_openai_api_key: str | None = Field(default=None, description="Azure OpenAI API key")
portia_api_key: str | None = Field(default=None, description="Portia API key")
portia_api_endpoint: str | None = Field(default=None, description="Portia API endpoint")
portia_dashboard_url: str | None = Field(default=None, description="Portia Dashboard URL")
azure_openai_endpoint: str | None = Field(default=None, description="Azure OpenAI endpoint")
ollama_base_url: str | None = Field(default=None, description="Ollama base URL")
llm_provider: str | None = Field(default=None, description="LLM provider")
llm_redis_cache_url: str | None = Field(
default_model: str | None = Field(default=None, description="Default generative model")
planning_model: str | None = Field(default=None, description="Planning agent model")
execution_model: str | None = Field(default=None, description="Execution agent model")
introspection_model: str | None = Field(default=None, description="Introspection agent model")
summarizer_model: str | None = Field(default=None, description="Summarizer agent model")
storage_class: str | None = Field(
storage_dir: str | None = Field(default=None, description="Storage directory for DISK storage")
default_log_level: str | None = Field(default=None, description="Default log level")
default_log_sink: str | None = Field(default=None, description="Default log sink")
json_log_serialize: bool | None = Field(default=None, description="JSON serialize logs")
planning_agent_type: str | None = Field(default=None, description="Planning agent type")
execution_agent_type: str | None = Field(default=None, description="Execution agent type")
large_output_threshold_tokens: int | None = Field(
feature_flags: dict[str, bool] | None = Field(default=None, description="Feature flags")
argument_clarifications_enabled: bool | None = Field(
model_config = SettingsConfigDict(env_prefix="PORTIA_CONFIG_")
def to_portia_config(self) -> PortiaConfig
‚ãÆ----
config_data = self.model_dump(exclude_none=True)
‚ãÆ----
class Settings(BaseSettings)
‚ãÆ----
app_name: str = Field(default="Portia FastAPI Example", description="Application name")
debug: bool = Field(default=False, description="Debug mode")
host: str = Field(default="127.0.0.1", description="Server host")
port: int = Field(default=8000, description="Server port")
max_workers: int = Field(
allowed_domains: list[str] = Field(
portia_config: PortiaConfigSettings = Field(
log_level: str = Field(default="INFO", description="Logging level")
application_version: str = Field(
model_config = SettingsConfigDict(env_nested_delimiter="__")
def get_portia_config(self) -> PortiaConfig
settings = Settings()
‚ãÆ----
logger = logging.getLogger(__name__)
def get_app_config() -> dict[str, Any]
</file>

<file path="app/exceptions.py">
class InvalidToolsError(Exception)
‚ãÆ----
def __init__(self, invalid_tools: list[str], available_tools: list[str]) -> None
</file>

<file path="app/main.py">
logger = logging.getLogger(__name__)
‚ãÆ----
@asynccontextmanager
async def lifespan(_: FastAPI) -> AsyncGenerator[None, None]
app_config = get_app_config()
app = FastAPI(
‚ãÆ----
@app.get("/", summary="Root endpoint", description="Welcome message")
async def root() -> dict[str, str]
</file>

<file path="tests/__init__.py">

</file>

<file path="tests/conftest.py">
@pytest.fixture
def client() -> TestClient
‚ãÆ----
@pytest.fixture
def mock_portia_service() -> Generator[Mock, None, None]
‚ãÆ----
mock_service = Mock()
async def mock_run_query(*args, **kwargs)
‚ãÆ----
@pytest.fixture
def sample_run_request() -> dict[str, Any]
‚ãÆ----
@pytest.fixture
def sample_successful_run_result() -> dict[str, Any]
‚ãÆ----
@pytest.fixture
def sample_failed_run_result() -> dict[str, Any]
‚ãÆ----
@pytest.fixture
def sample_available_tools() -> list[str]
</file>

<file path="tests/test_api_health.py">
@pytest.mark.unit
def test_health_check_success(client: TestClient) -> None
‚ãÆ----
response = client.get("/health")
‚ãÆ----
data = response.json()
‚ãÆ----
@pytest.mark.unit
def test_health_check_response_schema(client: TestClient) -> None
</file>

<file path="tests/test_api_run.py">
response = client.post("/run", json=sample_run_request)
‚ãÆ----
data = response.json()
‚ãÆ----
invalid_tools = ["invalid_tool"]
available_tools = ["calculator_tool", "weather_tool"]
‚ãÆ----
@pytest.mark.unit
def test_run_query_invalid_request_empty_query(client: TestClient) -> None
‚ãÆ----
invalid_request = {"query": "", "tools": ["calculator_tool"]}
response = client.post("/run", json=invalid_request)
‚ãÆ----
@pytest.mark.unit
def test_run_query_invalid_request_missing_query(client: TestClient) -> None
‚ãÆ----
invalid_request = {"tools": ["calculator_tool"]}
‚ãÆ----
@pytest.mark.unit
def test_run_query_invalid_request_missing_tools(client: TestClient) -> None
‚ãÆ----
invalid_request = {"query": "What is 2+2?"}
‚ãÆ----
response = client.get("/tools")
</file>

<file path="tests/test_config.py">
@pytest.mark.unit
class TestSettings
‚ãÆ----
def test_settings_defaults(self) -> None
‚ãÆ----
settings = Settings()
‚ãÆ----
def test_settings_custom_values(self) -> None
‚ãÆ----
custom_settings = Settings(
‚ãÆ----
def test_settings_environment_variables(self) -> None
def test_portia_config_conversion(self) -> None
‚ãÆ----
portia_config = settings.get_portia_config()
‚ãÆ----
@pytest.mark.unit
def test_get_version_from_pyproject() -> None
‚ãÆ----
mock_toml_content = b'[project]\nversion = "1.0.0"\n'
‚ãÆ----
version = _get_version_from_pyproject()
‚ãÆ----
mock_toml_content = b'[project]\nname = "test"\n'
‚ãÆ----
@pytest.mark.unit
def test_get_app_config() -> None
‚ãÆ----
config = get_app_config()
‚ãÆ----
@pytest.mark.unit
def test_logging_configuration() -> None
‚ãÆ----
logger = logging.getLogger("app.config")
‚ãÆ----
test_settings = Settings(log_level="DEBUG")
‚ãÆ----
test_settings = Settings(log_level="ERROR")
</file>

<file path="tests/test_exceptions.py">
@pytest.mark.unit
class TestInvalidToolsError
‚ãÆ----
def test_invalid_tools_error_creation(self) -> None
‚ãÆ----
invalid_tools = ["invalid_tool1", "invalid_tool2"]
available_tools = ["valid_tool1", "valid_tool2", "valid_tool3"]
error = InvalidToolsError(invalid_tools, available_tools)
‚ãÆ----
def test_invalid_tools_error_message(self) -> None
‚ãÆ----
invalid_tools = ["tool1"]
available_tools = ["tool2", "tool3"]
‚ãÆ----
message = str(error)
‚ãÆ----
def test_invalid_tools_error_empty_invalid_tools(self) -> None
‚ãÆ----
invalid_tools: list[str] = []
available_tools = ["tool1", "tool2"]
‚ãÆ----
def test_invalid_tools_error_empty_available_tools(self) -> None
‚ãÆ----
available_tools: list[str] = []
‚ãÆ----
def test_invalid_tools_error_single_tool(self) -> None
‚ãÆ----
invalid_tools = ["single_tool"]
available_tools = ["available_tool"]
‚ãÆ----
def test_invalid_tools_error_inheritance(self) -> None
‚ãÆ----
available_tools = ["tool2"]
</file>

<file path="tests/test_main.py">
@pytest.mark.unit
def test_root_endpoint(client: TestClient) -> None
‚ãÆ----
response = client.get("/")
‚ãÆ----
data = response.json()
‚ãÆ----
@pytest.mark.unit
def test_root_endpoint_schema(client: TestClient) -> None
‚ãÆ----
@pytest.mark.unit
def test_docs_endpoint_accessible(client: TestClient) -> None
‚ãÆ----
response = client.get("/docs")
‚ãÆ----
@pytest.mark.unit
def test_openapi_endpoint_accessible(client: TestClient) -> None
‚ãÆ----
response = client.get("/openapi.json")
</file>

<file path="tests/test_schemas.py">
@pytest.mark.unit
class TestHealthResponse
‚ãÆ----
def test_health_response_valid(self) -> None
‚ãÆ----
response = HealthResponse(status="healthy", version="1.0.0")
‚ãÆ----
def test_health_response_missing_status(self) -> None
def test_health_response_missing_version(self) -> None
‚ãÆ----
@pytest.mark.unit
class TestRunRequest
‚ãÆ----
def test_run_request_valid(self) -> None
‚ãÆ----
request = RunRequest(query="What is 2+2?", tools=["calculator_tool"])
‚ãÆ----
def test_run_request_empty_query(self) -> None
def test_run_request_missing_query(self) -> None
def test_run_request_missing_tools(self) -> None
def test_run_request_multiple_tools(self) -> None
‚ãÆ----
request = RunRequest(
‚ãÆ----
def test_run_request_empty_tools_list(self) -> None
‚ãÆ----
request = RunRequest(query="What is 2+2?", tools=[])
‚ãÆ----
@pytest.mark.unit
class TestRunResponse
‚ãÆ----
def test_run_response_success(self) -> None
‚ãÆ----
response = RunResponse(success=True, result={"value": "4.0"}, execution_time=2.5)
‚ãÆ----
def test_run_response_failure(self) -> None
‚ãÆ----
response = RunResponse(success=False, error="Test error message", execution_time=1.2)
‚ãÆ----
def test_run_response_minimal(self) -> None
‚ãÆ----
response = RunResponse(success=True)
‚ãÆ----
def test_run_response_missing_success(self) -> None
def test_run_response_complex_result(self) -> None
‚ãÆ----
complex_result = {
response = RunResponse(success=True, result=complex_result, execution_time=3.7)
</file>

<file path="tests/test_services.py">
@pytest.mark.unit
class TestPortiaService
‚ãÆ----
def setup_method(self) -> None
def _create_mock_config(self) -> Mock
‚ãÆ----
mock_config = Mock()
‚ãÆ----
mock_config_instance = self._create_mock_config()
‚ãÆ----
mock_tool = Mock()
‚ãÆ----
service1 = PortiaService()
service2 = PortiaService()
service3 = PortiaService.get_instance()
‚ãÆ----
service = PortiaService()
‚ãÆ----
mock_tool1 = Mock()
‚ãÆ----
mock_tool2 = Mock()
‚ãÆ----
tool_ids = service.available_tool_ids()
‚ãÆ----
mock_portia_instance = Mock()
‚ãÆ----
tools = {"test_tool"}
result = service._get_portia_instance(tools)
‚ãÆ----
invalid_tools = {"invalid_tool"}
‚ãÆ----
mock_plan_run = Mock()
‚ãÆ----
result = await service.run_query("test query", ["test_tool"])
‚ãÆ----
result1 = service._get_portia_instance(tools)
result2 = service._get_portia_instance(tools)
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/
</file>

<file path="docker-compose.yml">
services:
  portia-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - portia-network
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - portia-network
    command: redis-server --appendonly yes
    profiles:
      - cache
networks:
  portia-network:
    driver: bridge
volumes:
  redis_data:
</file>

<file path="Dockerfile">
# Use Python 3.11 slim image for smaller size
FROM python:3.11-slim as base

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install uv for faster dependency resolution
RUN pip install uv

# Create a non-root user
RUN useradd --create-home --shell /bin/bash app

# Set working directory
WORKDIR /app

# Copy dependency files
COPY pyproject.toml uv.lock ./

# Install dependencies using uv
RUN uv sync

# Copy application code
COPY app/ ./app/

# Change ownership to app user
RUN chown -R app:app /app

# Switch to non-root user
USER app

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application
CMD ["uv", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Portia AI

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="pyproject.toml">
[project]
name = "portia-python-fastapi-example"
version = "0.1.0"
description = "FastAPI example with Portia SDK integration for agentic workflows"
readme = "README.md"
requires-python = ">=3.11"
license = { file = "LICENSE" }
dependencies = [
    "fastapi[standard]>=0.115.14",
    "uvicorn[standard]>=0.34.0",
    "pydantic>=2.10.0",
    "pydantic-settings>=2.7.0",
    "portia-sdk-python>=0.2.0",
    "python-multipart>=0.0.7",
    "python-dotenv>=1.0.0",
]

[project.scripts]
portia-fastapi = "app.cli:main"

[dependency-groups]
dev = [
    "ruff>=0.12.2",
    "pytest>=8.0.0",
    "httpx>=0.28.0",
    "pytest-asyncio>=0.24.0",
    "pytest-cov>=4.0.0",
]

[tool.ruff]
line-length=100

[tool.ruff.lint]
select = ["ALL"]
ignore = [
  "COM812",  # Disables checks for trailing commas as they are fixed by the formatted and running both is not recommended.
  "D203",    # Disables checks for having a blank line before a class docstring. We instead have no-blank-line-before-class (D211) enabled.
  "D213",    # Disables checks for multi-line docstrings not starting on the first line. We instead have multi-line-summary-first-line (D212) enabled.
  "EM101",   # Disables checks for missing exception message arguments. We prefer single-line exception statements for simplicity and terseness.
  "EM102",   # Disables checks for f-string usage in exception messages. We prefer single-line exception statements with f-strings for simplicity and terseness.
  "G004",
  "TRY003",  # Disables checks for long error messages. We prefer to provide as much context to users as possible but want to avoid a proliferation of error classes.
]

[tool.ruff.lint.per-file-ignores]
"**/tests/*" = [
  "S101",    # Disables check for asserts. Asserts in test cases can be useful.
  "PLR2004", # Disables magic number checks. Its normal to assert using magic numbers for things like array length.
  "INP001",  # Disables checks for implicit namespace packages. Tests are not part of the package.
]

[tool.ruff.lint.flake8-type-checking]
runtime-evaluated-base-classes = [
  "pydantic.BaseModel", # Tells ruff that BaseModel instances need to be evaluated at runtime.
]

[tool.ruff.lint.flake8-annotations]
allow-star-arg-any = true  # Allows **kwargs: Any in type signatures.

[tool.ruff.lint.pylint]
max-args = 10

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "-v --tb=short --strict-markers"
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "slow: Slow tests",
    "asyncio: Async tests",
]
asyncio_mode = "auto"
</file>

<file path="README.md">
# Portia FastAPI Example

A well-structured FastAPI application integrated with the Portia SDK for building agentic workflows. This project demonstrates FastAPI best practices including proper async handling, Pydantic settings management, and clean architecture.

## Features

- üöÄ **FastAPI** with async support and modern Python features
- üîß **Portia SDK** integration for agentic workflows
- ‚öôÔ∏è **Pydantic Settings** for configuration management
- üìä **Structured logging** with configurable levels
- üîç **Health checks** and monitoring endpoints
- üìö **Auto-generated OpenAPI documentation**
- üê≥ **Production-ready** with proper error handling and Docker support
- ‚ö° **UV** for fast dependency management and project tooling
- üßµ **Threaded execution** for non-blocking Portia SDK operations
- üê≥ **Docker Compose** with Redis caching support

## Project Structure

```
portia-python-fastapi-example/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI application setup
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Pydantic settings and configuration
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py           # Custom exceptions
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py           # Health check endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run.py              # Main API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py           # Health check schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run.py              # Run endpoint schemas
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ portia_service.py   # Portia SDK integration
‚îú‚îÄ‚îÄ pyproject.toml              # Project configuration
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```

## Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd portia-python-fastapi-example
   ```

2. **Install [UV](https://docs.astral.sh/uv/) (if not already installed):**
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

3. **Install dependencies:**
   ```bash
   uv sync
   ```

## Environment Setup

1. **Set up environment variables:**
   Create a `.env` file in the root directory with at least one api key:
   ```env
   # LLM Settings (at least one is required)
   PORTIA_CONFIG__OPENAI_API_KEY="your-openai-api-key"
   PORTIA_CONFIG__ANTHROPIC_API_KEY="your-anthropic-api-key"
   PORTIA_CONFIG__PORTIA_API_KEY="your-portia-api-key"
   ```

## Usage

### Running the Application
This will start the FastAPI server locally in dev mode.

```bash
uv run fastapi dev main.py
```

### Using Docker

#### Option 1: Docker Compose (Recommended)

1. **Create environment configuration:**
   Create a `.env` file in the project root with your API keys:
   ```env
   # =============================================================================
   # LLM API Keys (At least one is required)
   # =============================================================================

   # OpenAI API Key
   OPENAI_API_KEY=your-openai-api-key-here

   # Anthropic API Key
   ANTHROPIC_API_KEY=your-anthropic-api-key-here

   # MistralAI API Key
   MISTRALAI_API_KEY=your-mistralai-api-key-here

   # Google Generative AI API Key
   GOOGLE_API_KEY=your-google-api-key-here

   # Azure OpenAI Configuration
   AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

   # Portia API Key (optional)
   PORTIA_API_KEY=your-portia-api-key-here

   # =============================================================================
   # Application Configuration (Optional)
   # =============================================================================

   # Server Configuration
   HOST=127.0.0.1
   PORT=8000
   MAX_WORKERS=4

   # Portia Configuration
   PORTIA_CONFIG__LLM_PROVIDER=openai
   PORTIA_CONFIG__DEFAULT_MODEL=openai/gpt-4o
   PORTIA_CONFIG__STORAGE_CLASS=MEMORY
   ```

2. **Run with Docker Compose:**
   ```bash
   # Run the main application
   docker compose up -d

   # Run with Redis cache (optional)
   docker compose --profile cache up -d

   # View logs
   docker compose logs -f portia-api

   # Stop services
   docker compose down
   ```

3. **Access the application:**
   - API: http://localhost:8000
   - Docs: http://localhost:8000/docs
   - Redis (if enabled): localhost:6379

#### Option 2: Docker Build and Run

1. **Build the docker image:**
    ```bash
    docker build -t portia-fastapi-example .
    ```

2. **Run the docker image:**
    ```bash
    docker run -p 8000:8000 \
      -e PORTIA_CONFIG__OPENAI_API_KEY="your-openai-key" \
      -e DEBUG="false" \
      portia-fastapi-example
    ```

#### Docker Environment Variables

The Docker setup supports all configuration options via environment variables:

| Environment Variable | Default | Description                                      |
| -------------------- | ------- | ------------------------------------------------ |
| `HOST`               | 0.0.0.0 | Server host                                      |
| `PORT`               | 8000    | Server port                                      |
| `DEBUG`              | false   | Debug mode                                       |
| `LOG_LEVEL`          | INFO    | Logging level                                    |
| `MAX_WORKERS`        | 4       | Thread pool size for Portia execution            |
| `ALLOWED_DOMAINS`    | *       | CORS allowed domains                             |
| `PORTIA_CONFIG__*`   |         | Portia configuration (see Portia Config section) |

#### Production Deployment

For production, consider:

1. **Enable Redis caching:**
   ```bash
   docker compose --profile cache up -d
   ```
   Then set: `PORTIA_CONFIG__LLM_REDIS_CACHE_URL=redis://redis:6379`

2. **Adjust worker threads based on your load:**
   ```env
   MAX_WORKERS=8  # Increase for higher concurrency
   ```

3. **Use proper logging:**
   ```env
   LOG_LEVEL=INFO
   PORTIA_CONFIG__JSON_LOG_SERIALIZE=true
   ```

### API Documentation

Once the application is running, you can access:

- **Interactive Swagger UI API docs**: http://localhost:8000/docs
- **API docs (ReDoc)**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

## API Endpoints

### GET /

Welcome endpoint that returns basic application information.

**Response:**
```json
{
  "message": "Welcome to Portia FastAPI Example",
  "version": "0.1.0",
  "docs_url": "/docs"
}
```

### POST /run

Execute a query using the Portia SDK.

**Request:**
```json
{
  "query": "What is 2+2?",
  "tools": ["calculator_tool"]
}
```

**Response:**
```json
{
  "success": true,
  "result": {
    "value": "4.0",
    "summary": "The query asked for the result of 2+2, and the expression was evaluated to give the output 4.0."
  },
  "error": null,
  "execution_time": 2.5
}
```

### GET /tools

Get available tools from the Portia SDK.

**Response:**
```json
["calculator_tool", "search_tool", "weather_tool"]
```

### GET /health

Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "version": "0.1.0"
}
```

## Configuration

The application uses Pydantic Settings for configuration management. Settings can be configured via:

1. **Environment variables**
2. **`.env` file**
3. **Default values**

### Available Settings

| Setting                            | Default                  | Description                           |
| ---------------------------------- | ------------------------ | ------------------------------------- |
| `APP_NAME`                         | "Portia FastAPI Example" | Application name                      |
| `APPLICATION_VERSION`              | "0.1.0"                  | Application version                   |
| `DEBUG`                            | `false`                  | Debug mode                            |
| `HOST`                             | "127.0.0.1"              | Server host                           |
| `PORT`                             | 8000                     | Server port                           |
| `MAX_WORKERS`                      | 4                        | Thread pool size for Portia execution |
| `ALLOWED_DOMAINS`                  | `["*"]`                  | CORS allowed domains                  |
| `PORTIA_CONFIG__PORTIA_API_KEY`    | `None`                   | Portia API key (optional)             |
| `PORTIA_CONFIG__OPENAI_API_KEY`    | `None`                   | OpenAI API key                        |
| `PORTIA_CONFIG__ANTHROPIC_API_KEY` | `None`                   | Anthropic API key                     |
| `LOG_LEVEL`                        | "INFO"                   | Logging level                         |

## Performance & Concurrency

This application includes several performance optimizations:

### **Threaded Portia Execution**
Portia SDK operations run in a dedicated thread pool to prevent blocking the FastAPI event loop:

```python
# Configured via MAX_WORKERS environment variable (default: 4)
loop = asyncio.get_running_loop()
plan_run = await loop.run_in_executor(
    self._executor, portia_instance.run, query, tools
)
```

### **Benefits:**
- ‚úÖ **Non-blocking**: FastAPI can handle other requests while Portia runs
- ‚úÖ **Configurable concurrency**: Adjust `MAX_WORKERS` based on your needs
- ‚úÖ **Better resource utilization**: Prevents thread starvation
- ‚úÖ **Scalable**: Maintains responsiveness under load

### **LLM Response Caching**
Optional Redis integration for caching LLM responses:

```bash
# Enable Redis caching
docker compose --profile cache up -d
```

Set `PORTIA_CONFIG__LLM_REDIS_CACHE_URL=redis://redis:6379` to enable caching.

## Development

### Architecture

The application follows a clean architecture pattern:

- **API Layer** (`app/api/`): FastAPI route handlers
- **Service Layer** (`app/services/`): Business logic and external integrations
- **Schema Layer** (`app/schemas/`): Pydantic models for request/response validation
- **Configuration** (`app/config.py`): Application settings management
- **Exception Handling** (`app/exceptions.py`): Custom exceptions

### Running Tests

```bash
# Install dev dependencies (included with uv sync)
uv sync --group dev

# Run tests
uv run pytest

# Run tests with coverage
uv run pytest --cov=app
```

### Code Quality

This project uses `ruff` for linting and formatting:

```bash
# Run linting
uv run ruff check .

# Run formatting
uv run ruff format .
```

### CI/CD

This project includes a GitHub Actions workflow (`.github/workflows/ci.yml`) for testing in the CI pipeline as well.

The workflow is triggered on:
- Push to `main` branch
- Pull requests to `main` branch

To run the same checks locally:

```bash
# Run all CI checks
uv run ruff check .
uv run ruff format --check .
uv run pytest tests/ -v

# Run tests with coverage
uv run pytest tests/ --cov=app --cov-report=term-missing
```

### Adding New Endpoints

1. Create schemas in `app/schemas/`
2. Add business logic in `app/services/`
3. Create API routes in `app/api/`
4. Include the router in `app/main.py`

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

## License

This project is licensed under the terms specified in the LICENSE file.

## Links

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Portia SDK Documentation](https://docs.portialabs.ai/)
- [Pydantic Settings](https://docs.pydantic.dev/latest/usage/settings/)
</file>

</files>
